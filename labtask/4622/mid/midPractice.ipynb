{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Need numpy, sklearn, matplotlib, pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "# splits the dataset into 70:30 or 80:20 train-test ratio\n",
    "from sklearn.model_selection import train_test_split\n",
    "# need this when no dataset is provided.\n",
    "from sklearn import datasets\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The linear regression class needs a learning rate, a iterations number, a bias value, some weight."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the class LinearRegression\n",
    "\n",
    "\n",
    "class LinearRegression:\n",
    "\n",
    "  def __init__(self, learning_rate=0.001, number_of_iterations=100):\n",
    "    self.lr = learning_rate  # alpha\n",
    "    self.n_iters = number_of_iterations  # m\n",
    "    self.weights = None\n",
    "    self.bias = None\n",
    "\n",
    "  def fit(self, X, y):\n",
    "    # gradient_descent algorithm\n",
    "    # init params\n",
    "    n_samples, n_features = X.shape  # samples -> Numbers_of_m/records, features-> Numbers_of_thetas\n",
    "    self.bias = 0\n",
    "    self.weights = np.zeros(n_features)  # zeroing out the thetas\n",
    "\n",
    "    # iterative gradient descent\n",
    "    for _ in range(self.n_iters):\n",
    "      # np.dot => does matrix multiplication (or atleast thats what we need to know rn)\n",
    "      y_predicted = np.dot(X, self.weights) + self.bias\n",
    "\n",
    "      dw = (1 / n_samples) * np.dot(X.T, (y_predicted, y))\n",
    "      db = (1 / n_samples) * np.sum(y_predicted - y)\n",
    "      if (db == 0 and dw == 0):\n",
    "        break\n",
    "      self.weights -= self.lr * dw\n",
    "      self.bias -= self.lr * db\n",
    "\n",
    "  def predict(self, X):\n",
    "    return np.dot(X, self.weights) + self.bias\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y = datasets.make_regression(n_samples=100,n_features=1,noise=20,random_state=7)\n",
    "# here make regression creates a randoly generated regression problem for us where rando_state is the seed.\n",
    "# n_samples is the records ie m\n",
    "# and n_features is the theta\n",
    "\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=7)\n",
    "# train test split splits the data into train and test sizes. Either provide test_size or train_size.\n",
    "\n",
    "print(X.shape,y.shape,X_train.shape,X_test.shape,y_train.shape,y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig= plt.figure(figsize=(8,6)) # figsize determines the size of the plt here 8x6 inches\n",
    "plt.scatter(X[:,0],y,color='b',marker='o',s=30)\n",
    "# scatter plot takes x axis and y axis values/arrays and colors, marker_types and marker_size.\n",
    "# X[:,0] means if X is a multidimensional array take only the element on the first column and return an array\n",
    "# : - this is a shorthand notation that means \"select all indices along this dimension\". In this case, it selects all rows of 0th column.\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor = LinearRegression(learning_rate=0.1)\n",
    "regressor.fit(X_train,y_train)\n",
    "predicted_value= regressor.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse(y_true,y_test):\n",
    "  # mean square error\n",
    "  return np.mean((y_true-y_test)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mse(y_test,predicted_value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drawRegressionLine(X_train,X_test,y_train,y_test,y_predicted):\n",
    "  cmap= plt.get_cmap('viridis')\n",
    "  fig= plt.figure(figsize=(8,6))\n",
    "  m1= plt.scatter(X_train,y_train,color=cmap(0.9),s=10)\n",
    "  m2 = plt.scatter(X_test,y_test,color=cmap(0.5),s=10)\n",
    "  plt.plot(X_test,y_predicted,color='black',linewidth=2,label='Prediction')\n",
    "  plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drawRegressionLine(X_train,X_test,y_train,y_test,predicted_value)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
