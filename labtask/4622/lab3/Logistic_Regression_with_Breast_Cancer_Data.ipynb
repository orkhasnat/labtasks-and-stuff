{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v9WE55jG7Jc-"
      },
      "outputs": [],
      "source": [
        "!gdown -q 11Cxt5om7r7xuWEhMWlmljX-PHag9adZq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 787
        },
        "id": "VGCSI3nK8rMV",
        "outputId": "b3e9d30b-a4c0-4b31-ff3e-f260a20470b8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          id diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
              "0     842302         M        17.99         10.38          122.80     1001.0   \n",
              "1     842517         M        20.57         17.77          132.90     1326.0   \n",
              "2   84300903         M        19.69         21.25          130.00     1203.0   \n",
              "3   84348301         M        11.42         20.38           77.58      386.1   \n",
              "4   84358402         M        20.29         14.34          135.10     1297.0   \n",
              "5     843786         M        12.45         15.70           82.57      477.1   \n",
              "6     844359         M        18.25         19.98          119.60     1040.0   \n",
              "7   84458202         M        13.71         20.83           90.20      577.9   \n",
              "8     844981         M        13.00         21.82           87.50      519.8   \n",
              "9   84501001         M        12.46         24.04           83.97      475.9   \n",
              "10    845636         M        16.02         23.24          102.70      797.8   \n",
              "11  84610002         M        15.78         17.89          103.60      781.0   \n",
              "12    846226         M        19.17         24.80          132.40     1123.0   \n",
              "13    846381         M        15.85         23.95          103.70      782.7   \n",
              "14  84667401         M        13.73         22.61           93.60      578.3   \n",
              "15  84799002         M        14.54         27.54           96.73      658.8   \n",
              "16    848406         M        14.68         20.13           94.74      684.5   \n",
              "17  84862001         M        16.13         20.68          108.10      798.8   \n",
              "18    849014         M        19.81         22.15          130.00     1260.0   \n",
              "19   8510426         B        13.54         14.36           87.46      566.3   \n",
              "\n",
              "    smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
              "0           0.11840           0.27760         0.30010              0.14710   \n",
              "1           0.08474           0.07864         0.08690              0.07017   \n",
              "2           0.10960           0.15990         0.19740              0.12790   \n",
              "3           0.14250           0.28390         0.24140              0.10520   \n",
              "4           0.10030           0.13280         0.19800              0.10430   \n",
              "5           0.12780           0.17000         0.15780              0.08089   \n",
              "6           0.09463           0.10900         0.11270              0.07400   \n",
              "7           0.11890           0.16450         0.09366              0.05985   \n",
              "8           0.12730           0.19320         0.18590              0.09353   \n",
              "9           0.11860           0.23960         0.22730              0.08543   \n",
              "10          0.08206           0.06669         0.03299              0.03323   \n",
              "11          0.09710           0.12920         0.09954              0.06606   \n",
              "12          0.09740           0.24580         0.20650              0.11180   \n",
              "13          0.08401           0.10020         0.09938              0.05364   \n",
              "14          0.11310           0.22930         0.21280              0.08025   \n",
              "15          0.11390           0.15950         0.16390              0.07364   \n",
              "16          0.09867           0.07200         0.07395              0.05259   \n",
              "17          0.11700           0.20220         0.17220              0.10280   \n",
              "18          0.09831           0.10270         0.14790              0.09498   \n",
              "19          0.09779           0.08129         0.06664              0.04781   \n",
              "\n",
              "    ...  texture_worst  perimeter_worst  area_worst  smoothness_worst  \\\n",
              "0   ...          17.33           184.60      2019.0            0.1622   \n",
              "1   ...          23.41           158.80      1956.0            0.1238   \n",
              "2   ...          25.53           152.50      1709.0            0.1444   \n",
              "3   ...          26.50            98.87       567.7            0.2098   \n",
              "4   ...          16.67           152.20      1575.0            0.1374   \n",
              "5   ...          23.75           103.40       741.6            0.1791   \n",
              "6   ...          27.66           153.20      1606.0            0.1442   \n",
              "7   ...          28.14           110.60       897.0            0.1654   \n",
              "8   ...          30.73           106.20       739.3            0.1703   \n",
              "9   ...          40.68            97.65       711.4            0.1853   \n",
              "10  ...          33.88           123.80      1150.0            0.1181   \n",
              "11  ...          27.28           136.50      1299.0            0.1396   \n",
              "12  ...          29.94           151.70      1332.0            0.1037   \n",
              "13  ...          27.66           112.00       876.5            0.1131   \n",
              "14  ...          32.01           108.80       697.7            0.1651   \n",
              "15  ...          37.13           124.10       943.2            0.1678   \n",
              "16  ...          30.88           123.40      1138.0            0.1464   \n",
              "17  ...          31.48           136.80      1315.0            0.1789   \n",
              "18  ...          30.88           186.80      2398.0            0.1512   \n",
              "19  ...          19.26            99.70       711.2            0.1440   \n",
              "\n",
              "    compactness_worst  concavity_worst  concave points_worst  symmetry_worst  \\\n",
              "0              0.6656           0.7119               0.26540          0.4601   \n",
              "1              0.1866           0.2416               0.18600          0.2750   \n",
              "2              0.4245           0.4504               0.24300          0.3613   \n",
              "3              0.8663           0.6869               0.25750          0.6638   \n",
              "4              0.2050           0.4000               0.16250          0.2364   \n",
              "5              0.5249           0.5355               0.17410          0.3985   \n",
              "6              0.2576           0.3784               0.19320          0.3063   \n",
              "7              0.3682           0.2678               0.15560          0.3196   \n",
              "8              0.5401           0.5390               0.20600          0.4378   \n",
              "9              1.0580           1.1050               0.22100          0.4366   \n",
              "10             0.1551           0.1459               0.09975          0.2948   \n",
              "11             0.5609           0.3965               0.18100          0.3792   \n",
              "12             0.3903           0.3639               0.17670          0.3176   \n",
              "13             0.1924           0.2322               0.11190          0.2809   \n",
              "14             0.7725           0.6943               0.22080          0.3596   \n",
              "15             0.6577           0.7026               0.17120          0.4218   \n",
              "16             0.1871           0.2914               0.16090          0.3029   \n",
              "17             0.4233           0.4784               0.20730          0.3706   \n",
              "18             0.3150           0.5372               0.23880          0.2768   \n",
              "19             0.1773           0.2390               0.12880          0.2977   \n",
              "\n",
              "    fractal_dimension_worst  Unnamed: 32  \n",
              "0                   0.11890          NaN  \n",
              "1                   0.08902          NaN  \n",
              "2                   0.08758          NaN  \n",
              "3                   0.17300          NaN  \n",
              "4                   0.07678          NaN  \n",
              "5                   0.12440          NaN  \n",
              "6                   0.08368          NaN  \n",
              "7                   0.11510          NaN  \n",
              "8                   0.10720          NaN  \n",
              "9                   0.20750          NaN  \n",
              "10                  0.08452          NaN  \n",
              "11                  0.10480          NaN  \n",
              "12                  0.10230          NaN  \n",
              "13                  0.06287          NaN  \n",
              "14                  0.14310          NaN  \n",
              "15                  0.13410          NaN  \n",
              "16                  0.08216          NaN  \n",
              "17                  0.11420          NaN  \n",
              "18                  0.07615          NaN  \n",
              "19                  0.07259          NaN  \n",
              "\n",
              "[20 rows x 33 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-32b811e7-79b6-4ce8-9c19-df161bb83049\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>diagnosis</th>\n",
              "      <th>radius_mean</th>\n",
              "      <th>texture_mean</th>\n",
              "      <th>perimeter_mean</th>\n",
              "      <th>area_mean</th>\n",
              "      <th>smoothness_mean</th>\n",
              "      <th>compactness_mean</th>\n",
              "      <th>concavity_mean</th>\n",
              "      <th>concave points_mean</th>\n",
              "      <th>...</th>\n",
              "      <th>texture_worst</th>\n",
              "      <th>perimeter_worst</th>\n",
              "      <th>area_worst</th>\n",
              "      <th>smoothness_worst</th>\n",
              "      <th>compactness_worst</th>\n",
              "      <th>concavity_worst</th>\n",
              "      <th>concave points_worst</th>\n",
              "      <th>symmetry_worst</th>\n",
              "      <th>fractal_dimension_worst</th>\n",
              "      <th>Unnamed: 32</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>842302</td>\n",
              "      <td>M</td>\n",
              "      <td>17.99</td>\n",
              "      <td>10.38</td>\n",
              "      <td>122.80</td>\n",
              "      <td>1001.0</td>\n",
              "      <td>0.11840</td>\n",
              "      <td>0.27760</td>\n",
              "      <td>0.30010</td>\n",
              "      <td>0.14710</td>\n",
              "      <td>...</td>\n",
              "      <td>17.33</td>\n",
              "      <td>184.60</td>\n",
              "      <td>2019.0</td>\n",
              "      <td>0.1622</td>\n",
              "      <td>0.6656</td>\n",
              "      <td>0.7119</td>\n",
              "      <td>0.26540</td>\n",
              "      <td>0.4601</td>\n",
              "      <td>0.11890</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>842517</td>\n",
              "      <td>M</td>\n",
              "      <td>20.57</td>\n",
              "      <td>17.77</td>\n",
              "      <td>132.90</td>\n",
              "      <td>1326.0</td>\n",
              "      <td>0.08474</td>\n",
              "      <td>0.07864</td>\n",
              "      <td>0.08690</td>\n",
              "      <td>0.07017</td>\n",
              "      <td>...</td>\n",
              "      <td>23.41</td>\n",
              "      <td>158.80</td>\n",
              "      <td>1956.0</td>\n",
              "      <td>0.1238</td>\n",
              "      <td>0.1866</td>\n",
              "      <td>0.2416</td>\n",
              "      <td>0.18600</td>\n",
              "      <td>0.2750</td>\n",
              "      <td>0.08902</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>84300903</td>\n",
              "      <td>M</td>\n",
              "      <td>19.69</td>\n",
              "      <td>21.25</td>\n",
              "      <td>130.00</td>\n",
              "      <td>1203.0</td>\n",
              "      <td>0.10960</td>\n",
              "      <td>0.15990</td>\n",
              "      <td>0.19740</td>\n",
              "      <td>0.12790</td>\n",
              "      <td>...</td>\n",
              "      <td>25.53</td>\n",
              "      <td>152.50</td>\n",
              "      <td>1709.0</td>\n",
              "      <td>0.1444</td>\n",
              "      <td>0.4245</td>\n",
              "      <td>0.4504</td>\n",
              "      <td>0.24300</td>\n",
              "      <td>0.3613</td>\n",
              "      <td>0.08758</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>84348301</td>\n",
              "      <td>M</td>\n",
              "      <td>11.42</td>\n",
              "      <td>20.38</td>\n",
              "      <td>77.58</td>\n",
              "      <td>386.1</td>\n",
              "      <td>0.14250</td>\n",
              "      <td>0.28390</td>\n",
              "      <td>0.24140</td>\n",
              "      <td>0.10520</td>\n",
              "      <td>...</td>\n",
              "      <td>26.50</td>\n",
              "      <td>98.87</td>\n",
              "      <td>567.7</td>\n",
              "      <td>0.2098</td>\n",
              "      <td>0.8663</td>\n",
              "      <td>0.6869</td>\n",
              "      <td>0.25750</td>\n",
              "      <td>0.6638</td>\n",
              "      <td>0.17300</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>84358402</td>\n",
              "      <td>M</td>\n",
              "      <td>20.29</td>\n",
              "      <td>14.34</td>\n",
              "      <td>135.10</td>\n",
              "      <td>1297.0</td>\n",
              "      <td>0.10030</td>\n",
              "      <td>0.13280</td>\n",
              "      <td>0.19800</td>\n",
              "      <td>0.10430</td>\n",
              "      <td>...</td>\n",
              "      <td>16.67</td>\n",
              "      <td>152.20</td>\n",
              "      <td>1575.0</td>\n",
              "      <td>0.1374</td>\n",
              "      <td>0.2050</td>\n",
              "      <td>0.4000</td>\n",
              "      <td>0.16250</td>\n",
              "      <td>0.2364</td>\n",
              "      <td>0.07678</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>843786</td>\n",
              "      <td>M</td>\n",
              "      <td>12.45</td>\n",
              "      <td>15.70</td>\n",
              "      <td>82.57</td>\n",
              "      <td>477.1</td>\n",
              "      <td>0.12780</td>\n",
              "      <td>0.17000</td>\n",
              "      <td>0.15780</td>\n",
              "      <td>0.08089</td>\n",
              "      <td>...</td>\n",
              "      <td>23.75</td>\n",
              "      <td>103.40</td>\n",
              "      <td>741.6</td>\n",
              "      <td>0.1791</td>\n",
              "      <td>0.5249</td>\n",
              "      <td>0.5355</td>\n",
              "      <td>0.17410</td>\n",
              "      <td>0.3985</td>\n",
              "      <td>0.12440</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>844359</td>\n",
              "      <td>M</td>\n",
              "      <td>18.25</td>\n",
              "      <td>19.98</td>\n",
              "      <td>119.60</td>\n",
              "      <td>1040.0</td>\n",
              "      <td>0.09463</td>\n",
              "      <td>0.10900</td>\n",
              "      <td>0.11270</td>\n",
              "      <td>0.07400</td>\n",
              "      <td>...</td>\n",
              "      <td>27.66</td>\n",
              "      <td>153.20</td>\n",
              "      <td>1606.0</td>\n",
              "      <td>0.1442</td>\n",
              "      <td>0.2576</td>\n",
              "      <td>0.3784</td>\n",
              "      <td>0.19320</td>\n",
              "      <td>0.3063</td>\n",
              "      <td>0.08368</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>84458202</td>\n",
              "      <td>M</td>\n",
              "      <td>13.71</td>\n",
              "      <td>20.83</td>\n",
              "      <td>90.20</td>\n",
              "      <td>577.9</td>\n",
              "      <td>0.11890</td>\n",
              "      <td>0.16450</td>\n",
              "      <td>0.09366</td>\n",
              "      <td>0.05985</td>\n",
              "      <td>...</td>\n",
              "      <td>28.14</td>\n",
              "      <td>110.60</td>\n",
              "      <td>897.0</td>\n",
              "      <td>0.1654</td>\n",
              "      <td>0.3682</td>\n",
              "      <td>0.2678</td>\n",
              "      <td>0.15560</td>\n",
              "      <td>0.3196</td>\n",
              "      <td>0.11510</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>844981</td>\n",
              "      <td>M</td>\n",
              "      <td>13.00</td>\n",
              "      <td>21.82</td>\n",
              "      <td>87.50</td>\n",
              "      <td>519.8</td>\n",
              "      <td>0.12730</td>\n",
              "      <td>0.19320</td>\n",
              "      <td>0.18590</td>\n",
              "      <td>0.09353</td>\n",
              "      <td>...</td>\n",
              "      <td>30.73</td>\n",
              "      <td>106.20</td>\n",
              "      <td>739.3</td>\n",
              "      <td>0.1703</td>\n",
              "      <td>0.5401</td>\n",
              "      <td>0.5390</td>\n",
              "      <td>0.20600</td>\n",
              "      <td>0.4378</td>\n",
              "      <td>0.10720</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>84501001</td>\n",
              "      <td>M</td>\n",
              "      <td>12.46</td>\n",
              "      <td>24.04</td>\n",
              "      <td>83.97</td>\n",
              "      <td>475.9</td>\n",
              "      <td>0.11860</td>\n",
              "      <td>0.23960</td>\n",
              "      <td>0.22730</td>\n",
              "      <td>0.08543</td>\n",
              "      <td>...</td>\n",
              "      <td>40.68</td>\n",
              "      <td>97.65</td>\n",
              "      <td>711.4</td>\n",
              "      <td>0.1853</td>\n",
              "      <td>1.0580</td>\n",
              "      <td>1.1050</td>\n",
              "      <td>0.22100</td>\n",
              "      <td>0.4366</td>\n",
              "      <td>0.20750</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>845636</td>\n",
              "      <td>M</td>\n",
              "      <td>16.02</td>\n",
              "      <td>23.24</td>\n",
              "      <td>102.70</td>\n",
              "      <td>797.8</td>\n",
              "      <td>0.08206</td>\n",
              "      <td>0.06669</td>\n",
              "      <td>0.03299</td>\n",
              "      <td>0.03323</td>\n",
              "      <td>...</td>\n",
              "      <td>33.88</td>\n",
              "      <td>123.80</td>\n",
              "      <td>1150.0</td>\n",
              "      <td>0.1181</td>\n",
              "      <td>0.1551</td>\n",
              "      <td>0.1459</td>\n",
              "      <td>0.09975</td>\n",
              "      <td>0.2948</td>\n",
              "      <td>0.08452</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>84610002</td>\n",
              "      <td>M</td>\n",
              "      <td>15.78</td>\n",
              "      <td>17.89</td>\n",
              "      <td>103.60</td>\n",
              "      <td>781.0</td>\n",
              "      <td>0.09710</td>\n",
              "      <td>0.12920</td>\n",
              "      <td>0.09954</td>\n",
              "      <td>0.06606</td>\n",
              "      <td>...</td>\n",
              "      <td>27.28</td>\n",
              "      <td>136.50</td>\n",
              "      <td>1299.0</td>\n",
              "      <td>0.1396</td>\n",
              "      <td>0.5609</td>\n",
              "      <td>0.3965</td>\n",
              "      <td>0.18100</td>\n",
              "      <td>0.3792</td>\n",
              "      <td>0.10480</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>846226</td>\n",
              "      <td>M</td>\n",
              "      <td>19.17</td>\n",
              "      <td>24.80</td>\n",
              "      <td>132.40</td>\n",
              "      <td>1123.0</td>\n",
              "      <td>0.09740</td>\n",
              "      <td>0.24580</td>\n",
              "      <td>0.20650</td>\n",
              "      <td>0.11180</td>\n",
              "      <td>...</td>\n",
              "      <td>29.94</td>\n",
              "      <td>151.70</td>\n",
              "      <td>1332.0</td>\n",
              "      <td>0.1037</td>\n",
              "      <td>0.3903</td>\n",
              "      <td>0.3639</td>\n",
              "      <td>0.17670</td>\n",
              "      <td>0.3176</td>\n",
              "      <td>0.10230</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>846381</td>\n",
              "      <td>M</td>\n",
              "      <td>15.85</td>\n",
              "      <td>23.95</td>\n",
              "      <td>103.70</td>\n",
              "      <td>782.7</td>\n",
              "      <td>0.08401</td>\n",
              "      <td>0.10020</td>\n",
              "      <td>0.09938</td>\n",
              "      <td>0.05364</td>\n",
              "      <td>...</td>\n",
              "      <td>27.66</td>\n",
              "      <td>112.00</td>\n",
              "      <td>876.5</td>\n",
              "      <td>0.1131</td>\n",
              "      <td>0.1924</td>\n",
              "      <td>0.2322</td>\n",
              "      <td>0.11190</td>\n",
              "      <td>0.2809</td>\n",
              "      <td>0.06287</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>84667401</td>\n",
              "      <td>M</td>\n",
              "      <td>13.73</td>\n",
              "      <td>22.61</td>\n",
              "      <td>93.60</td>\n",
              "      <td>578.3</td>\n",
              "      <td>0.11310</td>\n",
              "      <td>0.22930</td>\n",
              "      <td>0.21280</td>\n",
              "      <td>0.08025</td>\n",
              "      <td>...</td>\n",
              "      <td>32.01</td>\n",
              "      <td>108.80</td>\n",
              "      <td>697.7</td>\n",
              "      <td>0.1651</td>\n",
              "      <td>0.7725</td>\n",
              "      <td>0.6943</td>\n",
              "      <td>0.22080</td>\n",
              "      <td>0.3596</td>\n",
              "      <td>0.14310</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>84799002</td>\n",
              "      <td>M</td>\n",
              "      <td>14.54</td>\n",
              "      <td>27.54</td>\n",
              "      <td>96.73</td>\n",
              "      <td>658.8</td>\n",
              "      <td>0.11390</td>\n",
              "      <td>0.15950</td>\n",
              "      <td>0.16390</td>\n",
              "      <td>0.07364</td>\n",
              "      <td>...</td>\n",
              "      <td>37.13</td>\n",
              "      <td>124.10</td>\n",
              "      <td>943.2</td>\n",
              "      <td>0.1678</td>\n",
              "      <td>0.6577</td>\n",
              "      <td>0.7026</td>\n",
              "      <td>0.17120</td>\n",
              "      <td>0.4218</td>\n",
              "      <td>0.13410</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>848406</td>\n",
              "      <td>M</td>\n",
              "      <td>14.68</td>\n",
              "      <td>20.13</td>\n",
              "      <td>94.74</td>\n",
              "      <td>684.5</td>\n",
              "      <td>0.09867</td>\n",
              "      <td>0.07200</td>\n",
              "      <td>0.07395</td>\n",
              "      <td>0.05259</td>\n",
              "      <td>...</td>\n",
              "      <td>30.88</td>\n",
              "      <td>123.40</td>\n",
              "      <td>1138.0</td>\n",
              "      <td>0.1464</td>\n",
              "      <td>0.1871</td>\n",
              "      <td>0.2914</td>\n",
              "      <td>0.16090</td>\n",
              "      <td>0.3029</td>\n",
              "      <td>0.08216</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>84862001</td>\n",
              "      <td>M</td>\n",
              "      <td>16.13</td>\n",
              "      <td>20.68</td>\n",
              "      <td>108.10</td>\n",
              "      <td>798.8</td>\n",
              "      <td>0.11700</td>\n",
              "      <td>0.20220</td>\n",
              "      <td>0.17220</td>\n",
              "      <td>0.10280</td>\n",
              "      <td>...</td>\n",
              "      <td>31.48</td>\n",
              "      <td>136.80</td>\n",
              "      <td>1315.0</td>\n",
              "      <td>0.1789</td>\n",
              "      <td>0.4233</td>\n",
              "      <td>0.4784</td>\n",
              "      <td>0.20730</td>\n",
              "      <td>0.3706</td>\n",
              "      <td>0.11420</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>849014</td>\n",
              "      <td>M</td>\n",
              "      <td>19.81</td>\n",
              "      <td>22.15</td>\n",
              "      <td>130.00</td>\n",
              "      <td>1260.0</td>\n",
              "      <td>0.09831</td>\n",
              "      <td>0.10270</td>\n",
              "      <td>0.14790</td>\n",
              "      <td>0.09498</td>\n",
              "      <td>...</td>\n",
              "      <td>30.88</td>\n",
              "      <td>186.80</td>\n",
              "      <td>2398.0</td>\n",
              "      <td>0.1512</td>\n",
              "      <td>0.3150</td>\n",
              "      <td>0.5372</td>\n",
              "      <td>0.23880</td>\n",
              "      <td>0.2768</td>\n",
              "      <td>0.07615</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>8510426</td>\n",
              "      <td>B</td>\n",
              "      <td>13.54</td>\n",
              "      <td>14.36</td>\n",
              "      <td>87.46</td>\n",
              "      <td>566.3</td>\n",
              "      <td>0.09779</td>\n",
              "      <td>0.08129</td>\n",
              "      <td>0.06664</td>\n",
              "      <td>0.04781</td>\n",
              "      <td>...</td>\n",
              "      <td>19.26</td>\n",
              "      <td>99.70</td>\n",
              "      <td>711.2</td>\n",
              "      <td>0.1440</td>\n",
              "      <td>0.1773</td>\n",
              "      <td>0.2390</td>\n",
              "      <td>0.12880</td>\n",
              "      <td>0.2977</td>\n",
              "      <td>0.07259</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>20 rows Ã— 33 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-32b811e7-79b6-4ce8-9c19-df161bb83049')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-32b811e7-79b6-4ce8-9c19-df161bb83049 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-32b811e7-79b6-4ce8-9c19-df161bb83049');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "# Reading the Libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Reading the Data\n",
        "data = pd.read_csv('/content/data.csv')\n",
        "data.head(20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y_ibXW4C81ut",
        "outputId": "976d6e37-9f84-4df6-ff96-81878f4fc9e3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(569, 33)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "data.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tdBW9oWI9THG"
      },
      "source": [
        "Let's have a look at the health of the data itself. This function `info()` in the pandas library is very helpful to understand the basic properties of the data itself. If there is any missing values in the dataset can be known right from here so that they can be taken care of before fitting into a model for training and testing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_jfSJWnA9Ne4",
        "outputId": "1266c737-3a39-42aa-a402-6c16d0bedff1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 569 entries, 0 to 568\n",
            "Data columns (total 33 columns):\n",
            " #   Column                   Non-Null Count  Dtype  \n",
            "---  ------                   --------------  -----  \n",
            " 0   id                       569 non-null    int64  \n",
            " 1   diagnosis                569 non-null    object \n",
            " 2   radius_mean              569 non-null    float64\n",
            " 3   texture_mean             569 non-null    float64\n",
            " 4   perimeter_mean           569 non-null    float64\n",
            " 5   area_mean                569 non-null    float64\n",
            " 6   smoothness_mean          569 non-null    float64\n",
            " 7   compactness_mean         569 non-null    float64\n",
            " 8   concavity_mean           569 non-null    float64\n",
            " 9   concave points_mean      569 non-null    float64\n",
            " 10  symmetry_mean            569 non-null    float64\n",
            " 11  fractal_dimension_mean   569 non-null    float64\n",
            " 12  radius_se                569 non-null    float64\n",
            " 13  texture_se               569 non-null    float64\n",
            " 14  perimeter_se             569 non-null    float64\n",
            " 15  area_se                  569 non-null    float64\n",
            " 16  smoothness_se            569 non-null    float64\n",
            " 17  compactness_se           569 non-null    float64\n",
            " 18  concavity_se             569 non-null    float64\n",
            " 19  concave points_se        569 non-null    float64\n",
            " 20  symmetry_se              569 non-null    float64\n",
            " 21  fractal_dimension_se     569 non-null    float64\n",
            " 22  radius_worst             569 non-null    float64\n",
            " 23  texture_worst            569 non-null    float64\n",
            " 24  perimeter_worst          569 non-null    float64\n",
            " 25  area_worst               569 non-null    float64\n",
            " 26  smoothness_worst         569 non-null    float64\n",
            " 27  compactness_worst        569 non-null    float64\n",
            " 28  concavity_worst          569 non-null    float64\n",
            " 29  concave points_worst     569 non-null    float64\n",
            " 30  symmetry_worst           569 non-null    float64\n",
            " 31  fractal_dimension_worst  569 non-null    float64\n",
            " 32  Unnamed: 32              0 non-null      float64\n",
            "dtypes: float64(31), int64(1), object(1)\n",
            "memory usage: 146.8+ KB\n"
          ]
        }
      ],
      "source": [
        "data.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HjOY15HG91SL"
      },
      "source": [
        "**There are 3 things that take my attention.**\n",
        "\n",
        "\n",
        "1.   There is an `id` that cannot be used for classificaiton\n",
        "2.   `Diagnosis` column in the data is our class label\n",
        "3.   `Unnamed: 32` feature includes `NaN` so we do not need it.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GTIUc3w99O5M",
        "outputId": "3a6c878e-3744-40b0-b07c-debd6f24a1cc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['id', 'diagnosis', 'radius_mean', 'texture_mean', 'perimeter_mean',\n",
            "       'area_mean', 'smoothness_mean', 'compactness_mean', 'concavity_mean',\n",
            "       'concave points_mean', 'symmetry_mean', 'fractal_dimension_mean',\n",
            "       'radius_se', 'texture_se', 'perimeter_se', 'area_se', 'smoothness_se',\n",
            "       'compactness_se', 'concavity_se', 'concave points_se', 'symmetry_se',\n",
            "       'fractal_dimension_se', 'radius_worst', 'texture_worst',\n",
            "       'perimeter_worst', 'area_worst', 'smoothness_worst',\n",
            "       'compactness_worst', 'concavity_worst', 'concave points_worst',\n",
            "       'symmetry_worst', 'fractal_dimension_worst', 'Unnamed: 32'],\n",
            "      dtype='object')\n",
            "33\n"
          ]
        }
      ],
      "source": [
        "col = data.columns       \n",
        "print(col)\n",
        "print(len(col))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.drop(['Unnamed: 32',\"id\"], axis=1, inplace=True)\n",
        "data.diagnosis = [1 if each == \"M\" else 0 for each in data.diagnosis]\n",
        "y_data = data.diagnosis.values\n",
        "x_data = data.drop(['diagnosis'], axis=1)\n",
        "x_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 505
        },
        "id": "4XX5jyKV3x1d",
        "outputId": "fe8b6065-6616-42b5-f0cb-56788d3475f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     radius_mean  texture_mean  perimeter_mean  area_mean  smoothness_mean  \\\n",
              "0          17.99         10.38          122.80     1001.0          0.11840   \n",
              "1          20.57         17.77          132.90     1326.0          0.08474   \n",
              "2          19.69         21.25          130.00     1203.0          0.10960   \n",
              "3          11.42         20.38           77.58      386.1          0.14250   \n",
              "4          20.29         14.34          135.10     1297.0          0.10030   \n",
              "..           ...           ...             ...        ...              ...   \n",
              "564        21.56         22.39          142.00     1479.0          0.11100   \n",
              "565        20.13         28.25          131.20     1261.0          0.09780   \n",
              "566        16.60         28.08          108.30      858.1          0.08455   \n",
              "567        20.60         29.33          140.10     1265.0          0.11780   \n",
              "568         7.76         24.54           47.92      181.0          0.05263   \n",
              "\n",
              "     compactness_mean  concavity_mean  concave points_mean  symmetry_mean  \\\n",
              "0             0.27760         0.30010              0.14710         0.2419   \n",
              "1             0.07864         0.08690              0.07017         0.1812   \n",
              "2             0.15990         0.19740              0.12790         0.2069   \n",
              "3             0.28390         0.24140              0.10520         0.2597   \n",
              "4             0.13280         0.19800              0.10430         0.1809   \n",
              "..                ...             ...                  ...            ...   \n",
              "564           0.11590         0.24390              0.13890         0.1726   \n",
              "565           0.10340         0.14400              0.09791         0.1752   \n",
              "566           0.10230         0.09251              0.05302         0.1590   \n",
              "567           0.27700         0.35140              0.15200         0.2397   \n",
              "568           0.04362         0.00000              0.00000         0.1587   \n",
              "\n",
              "     fractal_dimension_mean  ...  radius_worst  texture_worst  \\\n",
              "0                   0.07871  ...        25.380          17.33   \n",
              "1                   0.05667  ...        24.990          23.41   \n",
              "2                   0.05999  ...        23.570          25.53   \n",
              "3                   0.09744  ...        14.910          26.50   \n",
              "4                   0.05883  ...        22.540          16.67   \n",
              "..                      ...  ...           ...            ...   \n",
              "564                 0.05623  ...        25.450          26.40   \n",
              "565                 0.05533  ...        23.690          38.25   \n",
              "566                 0.05648  ...        18.980          34.12   \n",
              "567                 0.07016  ...        25.740          39.42   \n",
              "568                 0.05884  ...         9.456          30.37   \n",
              "\n",
              "     perimeter_worst  area_worst  smoothness_worst  compactness_worst  \\\n",
              "0             184.60      2019.0           0.16220            0.66560   \n",
              "1             158.80      1956.0           0.12380            0.18660   \n",
              "2             152.50      1709.0           0.14440            0.42450   \n",
              "3              98.87       567.7           0.20980            0.86630   \n",
              "4             152.20      1575.0           0.13740            0.20500   \n",
              "..               ...         ...               ...                ...   \n",
              "564           166.10      2027.0           0.14100            0.21130   \n",
              "565           155.00      1731.0           0.11660            0.19220   \n",
              "566           126.70      1124.0           0.11390            0.30940   \n",
              "567           184.60      1821.0           0.16500            0.86810   \n",
              "568            59.16       268.6           0.08996            0.06444   \n",
              "\n",
              "     concavity_worst  concave points_worst  symmetry_worst  \\\n",
              "0             0.7119                0.2654          0.4601   \n",
              "1             0.2416                0.1860          0.2750   \n",
              "2             0.4504                0.2430          0.3613   \n",
              "3             0.6869                0.2575          0.6638   \n",
              "4             0.4000                0.1625          0.2364   \n",
              "..               ...                   ...             ...   \n",
              "564           0.4107                0.2216          0.2060   \n",
              "565           0.3215                0.1628          0.2572   \n",
              "566           0.3403                0.1418          0.2218   \n",
              "567           0.9387                0.2650          0.4087   \n",
              "568           0.0000                0.0000          0.2871   \n",
              "\n",
              "     fractal_dimension_worst  \n",
              "0                    0.11890  \n",
              "1                    0.08902  \n",
              "2                    0.08758  \n",
              "3                    0.17300  \n",
              "4                    0.07678  \n",
              "..                       ...  \n",
              "564                  0.07115  \n",
              "565                  0.06637  \n",
              "566                  0.07820  \n",
              "567                  0.12400  \n",
              "568                  0.07039  \n",
              "\n",
              "[569 rows x 30 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a7775b4e-12cb-41c1-aea9-89c3aff24769\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>radius_mean</th>\n",
              "      <th>texture_mean</th>\n",
              "      <th>perimeter_mean</th>\n",
              "      <th>area_mean</th>\n",
              "      <th>smoothness_mean</th>\n",
              "      <th>compactness_mean</th>\n",
              "      <th>concavity_mean</th>\n",
              "      <th>concave points_mean</th>\n",
              "      <th>symmetry_mean</th>\n",
              "      <th>fractal_dimension_mean</th>\n",
              "      <th>...</th>\n",
              "      <th>radius_worst</th>\n",
              "      <th>texture_worst</th>\n",
              "      <th>perimeter_worst</th>\n",
              "      <th>area_worst</th>\n",
              "      <th>smoothness_worst</th>\n",
              "      <th>compactness_worst</th>\n",
              "      <th>concavity_worst</th>\n",
              "      <th>concave points_worst</th>\n",
              "      <th>symmetry_worst</th>\n",
              "      <th>fractal_dimension_worst</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>17.99</td>\n",
              "      <td>10.38</td>\n",
              "      <td>122.80</td>\n",
              "      <td>1001.0</td>\n",
              "      <td>0.11840</td>\n",
              "      <td>0.27760</td>\n",
              "      <td>0.30010</td>\n",
              "      <td>0.14710</td>\n",
              "      <td>0.2419</td>\n",
              "      <td>0.07871</td>\n",
              "      <td>...</td>\n",
              "      <td>25.380</td>\n",
              "      <td>17.33</td>\n",
              "      <td>184.60</td>\n",
              "      <td>2019.0</td>\n",
              "      <td>0.16220</td>\n",
              "      <td>0.66560</td>\n",
              "      <td>0.7119</td>\n",
              "      <td>0.2654</td>\n",
              "      <td>0.4601</td>\n",
              "      <td>0.11890</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>20.57</td>\n",
              "      <td>17.77</td>\n",
              "      <td>132.90</td>\n",
              "      <td>1326.0</td>\n",
              "      <td>0.08474</td>\n",
              "      <td>0.07864</td>\n",
              "      <td>0.08690</td>\n",
              "      <td>0.07017</td>\n",
              "      <td>0.1812</td>\n",
              "      <td>0.05667</td>\n",
              "      <td>...</td>\n",
              "      <td>24.990</td>\n",
              "      <td>23.41</td>\n",
              "      <td>158.80</td>\n",
              "      <td>1956.0</td>\n",
              "      <td>0.12380</td>\n",
              "      <td>0.18660</td>\n",
              "      <td>0.2416</td>\n",
              "      <td>0.1860</td>\n",
              "      <td>0.2750</td>\n",
              "      <td>0.08902</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>19.69</td>\n",
              "      <td>21.25</td>\n",
              "      <td>130.00</td>\n",
              "      <td>1203.0</td>\n",
              "      <td>0.10960</td>\n",
              "      <td>0.15990</td>\n",
              "      <td>0.19740</td>\n",
              "      <td>0.12790</td>\n",
              "      <td>0.2069</td>\n",
              "      <td>0.05999</td>\n",
              "      <td>...</td>\n",
              "      <td>23.570</td>\n",
              "      <td>25.53</td>\n",
              "      <td>152.50</td>\n",
              "      <td>1709.0</td>\n",
              "      <td>0.14440</td>\n",
              "      <td>0.42450</td>\n",
              "      <td>0.4504</td>\n",
              "      <td>0.2430</td>\n",
              "      <td>0.3613</td>\n",
              "      <td>0.08758</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>11.42</td>\n",
              "      <td>20.38</td>\n",
              "      <td>77.58</td>\n",
              "      <td>386.1</td>\n",
              "      <td>0.14250</td>\n",
              "      <td>0.28390</td>\n",
              "      <td>0.24140</td>\n",
              "      <td>0.10520</td>\n",
              "      <td>0.2597</td>\n",
              "      <td>0.09744</td>\n",
              "      <td>...</td>\n",
              "      <td>14.910</td>\n",
              "      <td>26.50</td>\n",
              "      <td>98.87</td>\n",
              "      <td>567.7</td>\n",
              "      <td>0.20980</td>\n",
              "      <td>0.86630</td>\n",
              "      <td>0.6869</td>\n",
              "      <td>0.2575</td>\n",
              "      <td>0.6638</td>\n",
              "      <td>0.17300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>20.29</td>\n",
              "      <td>14.34</td>\n",
              "      <td>135.10</td>\n",
              "      <td>1297.0</td>\n",
              "      <td>0.10030</td>\n",
              "      <td>0.13280</td>\n",
              "      <td>0.19800</td>\n",
              "      <td>0.10430</td>\n",
              "      <td>0.1809</td>\n",
              "      <td>0.05883</td>\n",
              "      <td>...</td>\n",
              "      <td>22.540</td>\n",
              "      <td>16.67</td>\n",
              "      <td>152.20</td>\n",
              "      <td>1575.0</td>\n",
              "      <td>0.13740</td>\n",
              "      <td>0.20500</td>\n",
              "      <td>0.4000</td>\n",
              "      <td>0.1625</td>\n",
              "      <td>0.2364</td>\n",
              "      <td>0.07678</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>564</th>\n",
              "      <td>21.56</td>\n",
              "      <td>22.39</td>\n",
              "      <td>142.00</td>\n",
              "      <td>1479.0</td>\n",
              "      <td>0.11100</td>\n",
              "      <td>0.11590</td>\n",
              "      <td>0.24390</td>\n",
              "      <td>0.13890</td>\n",
              "      <td>0.1726</td>\n",
              "      <td>0.05623</td>\n",
              "      <td>...</td>\n",
              "      <td>25.450</td>\n",
              "      <td>26.40</td>\n",
              "      <td>166.10</td>\n",
              "      <td>2027.0</td>\n",
              "      <td>0.14100</td>\n",
              "      <td>0.21130</td>\n",
              "      <td>0.4107</td>\n",
              "      <td>0.2216</td>\n",
              "      <td>0.2060</td>\n",
              "      <td>0.07115</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>565</th>\n",
              "      <td>20.13</td>\n",
              "      <td>28.25</td>\n",
              "      <td>131.20</td>\n",
              "      <td>1261.0</td>\n",
              "      <td>0.09780</td>\n",
              "      <td>0.10340</td>\n",
              "      <td>0.14400</td>\n",
              "      <td>0.09791</td>\n",
              "      <td>0.1752</td>\n",
              "      <td>0.05533</td>\n",
              "      <td>...</td>\n",
              "      <td>23.690</td>\n",
              "      <td>38.25</td>\n",
              "      <td>155.00</td>\n",
              "      <td>1731.0</td>\n",
              "      <td>0.11660</td>\n",
              "      <td>0.19220</td>\n",
              "      <td>0.3215</td>\n",
              "      <td>0.1628</td>\n",
              "      <td>0.2572</td>\n",
              "      <td>0.06637</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>566</th>\n",
              "      <td>16.60</td>\n",
              "      <td>28.08</td>\n",
              "      <td>108.30</td>\n",
              "      <td>858.1</td>\n",
              "      <td>0.08455</td>\n",
              "      <td>0.10230</td>\n",
              "      <td>0.09251</td>\n",
              "      <td>0.05302</td>\n",
              "      <td>0.1590</td>\n",
              "      <td>0.05648</td>\n",
              "      <td>...</td>\n",
              "      <td>18.980</td>\n",
              "      <td>34.12</td>\n",
              "      <td>126.70</td>\n",
              "      <td>1124.0</td>\n",
              "      <td>0.11390</td>\n",
              "      <td>0.30940</td>\n",
              "      <td>0.3403</td>\n",
              "      <td>0.1418</td>\n",
              "      <td>0.2218</td>\n",
              "      <td>0.07820</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>567</th>\n",
              "      <td>20.60</td>\n",
              "      <td>29.33</td>\n",
              "      <td>140.10</td>\n",
              "      <td>1265.0</td>\n",
              "      <td>0.11780</td>\n",
              "      <td>0.27700</td>\n",
              "      <td>0.35140</td>\n",
              "      <td>0.15200</td>\n",
              "      <td>0.2397</td>\n",
              "      <td>0.07016</td>\n",
              "      <td>...</td>\n",
              "      <td>25.740</td>\n",
              "      <td>39.42</td>\n",
              "      <td>184.60</td>\n",
              "      <td>1821.0</td>\n",
              "      <td>0.16500</td>\n",
              "      <td>0.86810</td>\n",
              "      <td>0.9387</td>\n",
              "      <td>0.2650</td>\n",
              "      <td>0.4087</td>\n",
              "      <td>0.12400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>568</th>\n",
              "      <td>7.76</td>\n",
              "      <td>24.54</td>\n",
              "      <td>47.92</td>\n",
              "      <td>181.0</td>\n",
              "      <td>0.05263</td>\n",
              "      <td>0.04362</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.1587</td>\n",
              "      <td>0.05884</td>\n",
              "      <td>...</td>\n",
              "      <td>9.456</td>\n",
              "      <td>30.37</td>\n",
              "      <td>59.16</td>\n",
              "      <td>268.6</td>\n",
              "      <td>0.08996</td>\n",
              "      <td>0.06444</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.2871</td>\n",
              "      <td>0.07039</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>569 rows Ã— 30 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a7775b4e-12cb-41c1-aea9-89c3aff24769')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a7775b4e-12cb-41c1-aea9-89c3aff24769 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a7775b4e-12cb-41c1-aea9-89c3aff24769');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vru4S1lE-hiL",
        "outputId": "71b1451d-d011-445e-eec9-87004b70e369"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 0 1 1 1 1 1 1 1 1 0 1 0 0 0 0 0 1 1 0 1 1 0 0 0 0 1 0 1 1 0 0 0 0 1 0 1 1\n",
            " 0 1 0 1 1 0 0 0 1 1 0 1 1 1 0 0 0 1 0 0 1 1 0 0 0 1 1 0 0 0 0 1 0 0 1 0 0\n",
            " 0 0 0 0 0 0 1 1 1 0 1 1 0 0 0 1 1 0 1 0 1 1 0 1 1 0 0 1 0 0 1 0 0 0 0 1 0\n",
            " 0 0 0 0 0 0 0 0 1 0 0 0 0 1 1 0 1 0 0 1 1 0 0 1 1 0 0 0 0 1 0 0 1 1 1 0 1\n",
            " 0 1 0 0 0 1 0 0 1 1 0 1 1 1 1 0 1 1 1 0 1 0 1 0 0 1 0 1 1 1 1 0 0 1 1 0 0\n",
            " 0 1 0 0 0 0 0 1 1 0 0 1 0 0 1 1 0 1 0 0 0 0 1 0 0 0 0 0 1 0 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 0 0 0 0 0 0 1 0 1 0 0 1 0 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 1 0 0 0 0 1 1 1 0 0\n",
            " 0 0 1 0 1 0 1 0 0 0 1 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 1 1 0 1 1\n",
            " 1 0 1 1 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 1 0 0 1 1 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
            " 0 1 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 1 0 1 0 0 0 0 0 1 0 0\n",
            " 1 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0\n",
            " 0 0 0 0 0 0 1 0 1 0 0 1 0 0 0 0 0 1 1 0 1 0 1 0 0 0 0 0 1 0 0 1 0 1 0 1 1\n",
            " 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 1 1 1 1 1 1 0]\n",
            "(569,)\n"
          ]
        }
      ],
      "source": [
        "print(y_data)\n",
        "print(y_data.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nYbDRo8_-vxx"
      },
      "source": [
        "Okay, now we have the features but **what do they mean**, or actually **how much do we need to know about these features**. The answer is that we do not need to know the meaning of these features. However, to imagine in our mind, we should know something like variance, standard deviation, number of the sample (count), or max-min values. This type of information helps to understand what is going on in data. For example, this question appears in my mind that the `area_mean` feature's max value is `2500` and `smoothness_mean` features' max `0.16340`. Therefore **do we need standardization or normalization before visualization, feature selection, feature extraction, or classification**? The answer is yes and no not surprising ha :) Anyway, let us go step by step and start with visualization."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0tTS_GMEAFx8"
      },
      "source": [
        "**Normalization**<br>\n",
        "Normalization refers to rescaling real-valued numeric attributes into a `0 to 1` range. Data normalization is used in machine learning to make model training less sensitive to the scale of features.\n",
        "\n",
        "You can either implement the conversion process with basic python or use `MinMaxScaler()` function from the `sklearn` library."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FFyNfjuG-iGp"
      },
      "outputs": [],
      "source": [
        "# Using transformer from sklearn library\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "scalar = MinMaxScaler()\n",
        "output = scalar.fit_transform(x_data)\n",
        "\n",
        "# Manual Implementation of the normalization process\n",
        "X_data = (x_data -np.min(x_data))/ (np.max(x_data)-np.min(x_data)).values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 505
        },
        "id": "KD0pJrjdAjQK",
        "outputId": "b72a3b3a-8572-47b2-e804-0c99a705e95a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     radius_mean  texture_mean  perimeter_mean  area_mean  smoothness_mean  \\\n",
              "0       0.521037      0.022658        0.545989   0.363733         0.593753   \n",
              "1       0.643144      0.272574        0.615783   0.501591         0.289880   \n",
              "2       0.601496      0.390260        0.595743   0.449417         0.514309   \n",
              "3       0.210090      0.360839        0.233501   0.102906         0.811321   \n",
              "4       0.629893      0.156578        0.630986   0.489290         0.430351   \n",
              "..           ...           ...             ...        ...              ...   \n",
              "564     0.690000      0.428813        0.678668   0.566490         0.526948   \n",
              "565     0.622320      0.626987        0.604036   0.474019         0.407782   \n",
              "566     0.455251      0.621238        0.445788   0.303118         0.288165   \n",
              "567     0.644564      0.663510        0.665538   0.475716         0.588336   \n",
              "568     0.036869      0.501522        0.028540   0.015907         0.000000   \n",
              "\n",
              "     compactness_mean  concavity_mean  concave points_mean  symmetry_mean  \\\n",
              "0            0.792037        0.703140             0.731113       0.686364   \n",
              "1            0.181768        0.203608             0.348757       0.379798   \n",
              "2            0.431017        0.462512             0.635686       0.509596   \n",
              "3            0.811361        0.565604             0.522863       0.776263   \n",
              "4            0.347893        0.463918             0.518390       0.378283   \n",
              "..                ...             ...                  ...            ...   \n",
              "564          0.296055        0.571462             0.690358       0.336364   \n",
              "565          0.257714        0.337395             0.486630       0.349495   \n",
              "566          0.254340        0.216753             0.263519       0.267677   \n",
              "567          0.790197        0.823336             0.755467       0.675253   \n",
              "568          0.074351        0.000000             0.000000       0.266162   \n",
              "\n",
              "     fractal_dimension_mean  ...  radius_worst  texture_worst  \\\n",
              "0                  0.605518  ...      0.620776       0.141525   \n",
              "1                  0.141323  ...      0.606901       0.303571   \n",
              "2                  0.211247  ...      0.556386       0.360075   \n",
              "3                  1.000000  ...      0.248310       0.385928   \n",
              "4                  0.186816  ...      0.519744       0.123934   \n",
              "..                      ...  ...           ...            ...   \n",
              "564                0.132056  ...      0.623266       0.383262   \n",
              "565                0.113100  ...      0.560655       0.699094   \n",
              "566                0.137321  ...      0.393099       0.589019   \n",
              "567                0.425442  ...      0.633582       0.730277   \n",
              "568                0.187026  ...      0.054287       0.489072   \n",
              "\n",
              "     perimeter_worst  area_worst  smoothness_worst  compactness_worst  \\\n",
              "0           0.668310    0.450698          0.601136           0.619292   \n",
              "1           0.539818    0.435214          0.347553           0.154563   \n",
              "2           0.508442    0.374508          0.483590           0.385375   \n",
              "3           0.241347    0.094008          0.915472           0.814012   \n",
              "4           0.506948    0.341575          0.437364           0.172415   \n",
              "..               ...         ...               ...                ...   \n",
              "564         0.576174    0.452664          0.461137           0.178527   \n",
              "565         0.520892    0.379915          0.300007           0.159997   \n",
              "566         0.379949    0.230731          0.282177           0.273705   \n",
              "567         0.668310    0.402035          0.619626           0.815758   \n",
              "568         0.043578    0.020497          0.124084           0.036043   \n",
              "\n",
              "     concavity_worst  concave points_worst  symmetry_worst  \\\n",
              "0           0.568610              0.912027        0.598462   \n",
              "1           0.192971              0.639175        0.233590   \n",
              "2           0.359744              0.835052        0.403706   \n",
              "3           0.548642              0.884880        1.000000   \n",
              "4           0.319489              0.558419        0.157500   \n",
              "..               ...                   ...             ...   \n",
              "564         0.328035              0.761512        0.097575   \n",
              "565         0.256789              0.559450        0.198502   \n",
              "566         0.271805              0.487285        0.128721   \n",
              "567         0.749760              0.910653        0.497142   \n",
              "568         0.000000              0.000000        0.257441   \n",
              "\n",
              "     fractal_dimension_worst  \n",
              "0                   0.418864  \n",
              "1                   0.222878  \n",
              "2                   0.213433  \n",
              "3                   0.773711  \n",
              "4                   0.142595  \n",
              "..                       ...  \n",
              "564                 0.105667  \n",
              "565                 0.074315  \n",
              "566                 0.151909  \n",
              "567                 0.452315  \n",
              "568                 0.100682  \n",
              "\n",
              "[569 rows x 30 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-844fad87-b182-4472-af16-3ff22802b685\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>radius_mean</th>\n",
              "      <th>texture_mean</th>\n",
              "      <th>perimeter_mean</th>\n",
              "      <th>area_mean</th>\n",
              "      <th>smoothness_mean</th>\n",
              "      <th>compactness_mean</th>\n",
              "      <th>concavity_mean</th>\n",
              "      <th>concave points_mean</th>\n",
              "      <th>symmetry_mean</th>\n",
              "      <th>fractal_dimension_mean</th>\n",
              "      <th>...</th>\n",
              "      <th>radius_worst</th>\n",
              "      <th>texture_worst</th>\n",
              "      <th>perimeter_worst</th>\n",
              "      <th>area_worst</th>\n",
              "      <th>smoothness_worst</th>\n",
              "      <th>compactness_worst</th>\n",
              "      <th>concavity_worst</th>\n",
              "      <th>concave points_worst</th>\n",
              "      <th>symmetry_worst</th>\n",
              "      <th>fractal_dimension_worst</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.521037</td>\n",
              "      <td>0.022658</td>\n",
              "      <td>0.545989</td>\n",
              "      <td>0.363733</td>\n",
              "      <td>0.593753</td>\n",
              "      <td>0.792037</td>\n",
              "      <td>0.703140</td>\n",
              "      <td>0.731113</td>\n",
              "      <td>0.686364</td>\n",
              "      <td>0.605518</td>\n",
              "      <td>...</td>\n",
              "      <td>0.620776</td>\n",
              "      <td>0.141525</td>\n",
              "      <td>0.668310</td>\n",
              "      <td>0.450698</td>\n",
              "      <td>0.601136</td>\n",
              "      <td>0.619292</td>\n",
              "      <td>0.568610</td>\n",
              "      <td>0.912027</td>\n",
              "      <td>0.598462</td>\n",
              "      <td>0.418864</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.643144</td>\n",
              "      <td>0.272574</td>\n",
              "      <td>0.615783</td>\n",
              "      <td>0.501591</td>\n",
              "      <td>0.289880</td>\n",
              "      <td>0.181768</td>\n",
              "      <td>0.203608</td>\n",
              "      <td>0.348757</td>\n",
              "      <td>0.379798</td>\n",
              "      <td>0.141323</td>\n",
              "      <td>...</td>\n",
              "      <td>0.606901</td>\n",
              "      <td>0.303571</td>\n",
              "      <td>0.539818</td>\n",
              "      <td>0.435214</td>\n",
              "      <td>0.347553</td>\n",
              "      <td>0.154563</td>\n",
              "      <td>0.192971</td>\n",
              "      <td>0.639175</td>\n",
              "      <td>0.233590</td>\n",
              "      <td>0.222878</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.601496</td>\n",
              "      <td>0.390260</td>\n",
              "      <td>0.595743</td>\n",
              "      <td>0.449417</td>\n",
              "      <td>0.514309</td>\n",
              "      <td>0.431017</td>\n",
              "      <td>0.462512</td>\n",
              "      <td>0.635686</td>\n",
              "      <td>0.509596</td>\n",
              "      <td>0.211247</td>\n",
              "      <td>...</td>\n",
              "      <td>0.556386</td>\n",
              "      <td>0.360075</td>\n",
              "      <td>0.508442</td>\n",
              "      <td>0.374508</td>\n",
              "      <td>0.483590</td>\n",
              "      <td>0.385375</td>\n",
              "      <td>0.359744</td>\n",
              "      <td>0.835052</td>\n",
              "      <td>0.403706</td>\n",
              "      <td>0.213433</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.210090</td>\n",
              "      <td>0.360839</td>\n",
              "      <td>0.233501</td>\n",
              "      <td>0.102906</td>\n",
              "      <td>0.811321</td>\n",
              "      <td>0.811361</td>\n",
              "      <td>0.565604</td>\n",
              "      <td>0.522863</td>\n",
              "      <td>0.776263</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.248310</td>\n",
              "      <td>0.385928</td>\n",
              "      <td>0.241347</td>\n",
              "      <td>0.094008</td>\n",
              "      <td>0.915472</td>\n",
              "      <td>0.814012</td>\n",
              "      <td>0.548642</td>\n",
              "      <td>0.884880</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.773711</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.629893</td>\n",
              "      <td>0.156578</td>\n",
              "      <td>0.630986</td>\n",
              "      <td>0.489290</td>\n",
              "      <td>0.430351</td>\n",
              "      <td>0.347893</td>\n",
              "      <td>0.463918</td>\n",
              "      <td>0.518390</td>\n",
              "      <td>0.378283</td>\n",
              "      <td>0.186816</td>\n",
              "      <td>...</td>\n",
              "      <td>0.519744</td>\n",
              "      <td>0.123934</td>\n",
              "      <td>0.506948</td>\n",
              "      <td>0.341575</td>\n",
              "      <td>0.437364</td>\n",
              "      <td>0.172415</td>\n",
              "      <td>0.319489</td>\n",
              "      <td>0.558419</td>\n",
              "      <td>0.157500</td>\n",
              "      <td>0.142595</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>564</th>\n",
              "      <td>0.690000</td>\n",
              "      <td>0.428813</td>\n",
              "      <td>0.678668</td>\n",
              "      <td>0.566490</td>\n",
              "      <td>0.526948</td>\n",
              "      <td>0.296055</td>\n",
              "      <td>0.571462</td>\n",
              "      <td>0.690358</td>\n",
              "      <td>0.336364</td>\n",
              "      <td>0.132056</td>\n",
              "      <td>...</td>\n",
              "      <td>0.623266</td>\n",
              "      <td>0.383262</td>\n",
              "      <td>0.576174</td>\n",
              "      <td>0.452664</td>\n",
              "      <td>0.461137</td>\n",
              "      <td>0.178527</td>\n",
              "      <td>0.328035</td>\n",
              "      <td>0.761512</td>\n",
              "      <td>0.097575</td>\n",
              "      <td>0.105667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>565</th>\n",
              "      <td>0.622320</td>\n",
              "      <td>0.626987</td>\n",
              "      <td>0.604036</td>\n",
              "      <td>0.474019</td>\n",
              "      <td>0.407782</td>\n",
              "      <td>0.257714</td>\n",
              "      <td>0.337395</td>\n",
              "      <td>0.486630</td>\n",
              "      <td>0.349495</td>\n",
              "      <td>0.113100</td>\n",
              "      <td>...</td>\n",
              "      <td>0.560655</td>\n",
              "      <td>0.699094</td>\n",
              "      <td>0.520892</td>\n",
              "      <td>0.379915</td>\n",
              "      <td>0.300007</td>\n",
              "      <td>0.159997</td>\n",
              "      <td>0.256789</td>\n",
              "      <td>0.559450</td>\n",
              "      <td>0.198502</td>\n",
              "      <td>0.074315</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>566</th>\n",
              "      <td>0.455251</td>\n",
              "      <td>0.621238</td>\n",
              "      <td>0.445788</td>\n",
              "      <td>0.303118</td>\n",
              "      <td>0.288165</td>\n",
              "      <td>0.254340</td>\n",
              "      <td>0.216753</td>\n",
              "      <td>0.263519</td>\n",
              "      <td>0.267677</td>\n",
              "      <td>0.137321</td>\n",
              "      <td>...</td>\n",
              "      <td>0.393099</td>\n",
              "      <td>0.589019</td>\n",
              "      <td>0.379949</td>\n",
              "      <td>0.230731</td>\n",
              "      <td>0.282177</td>\n",
              "      <td>0.273705</td>\n",
              "      <td>0.271805</td>\n",
              "      <td>0.487285</td>\n",
              "      <td>0.128721</td>\n",
              "      <td>0.151909</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>567</th>\n",
              "      <td>0.644564</td>\n",
              "      <td>0.663510</td>\n",
              "      <td>0.665538</td>\n",
              "      <td>0.475716</td>\n",
              "      <td>0.588336</td>\n",
              "      <td>0.790197</td>\n",
              "      <td>0.823336</td>\n",
              "      <td>0.755467</td>\n",
              "      <td>0.675253</td>\n",
              "      <td>0.425442</td>\n",
              "      <td>...</td>\n",
              "      <td>0.633582</td>\n",
              "      <td>0.730277</td>\n",
              "      <td>0.668310</td>\n",
              "      <td>0.402035</td>\n",
              "      <td>0.619626</td>\n",
              "      <td>0.815758</td>\n",
              "      <td>0.749760</td>\n",
              "      <td>0.910653</td>\n",
              "      <td>0.497142</td>\n",
              "      <td>0.452315</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>568</th>\n",
              "      <td>0.036869</td>\n",
              "      <td>0.501522</td>\n",
              "      <td>0.028540</td>\n",
              "      <td>0.015907</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.074351</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.266162</td>\n",
              "      <td>0.187026</td>\n",
              "      <td>...</td>\n",
              "      <td>0.054287</td>\n",
              "      <td>0.489072</td>\n",
              "      <td>0.043578</td>\n",
              "      <td>0.020497</td>\n",
              "      <td>0.124084</td>\n",
              "      <td>0.036043</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.257441</td>\n",
              "      <td>0.100682</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>569 rows Ã— 30 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-844fad87-b182-4472-af16-3ff22802b685')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-844fad87-b182-4472-af16-3ff22802b685 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-844fad87-b182-4472-af16-3ff22802b685');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "X_data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6eZMK0ZsBA1W"
      },
      "source": [
        "**The Basics: Logistic Regression and Regularization**\n",
        "\n",
        "Logistic Regression is one of the most common machine learning algorithms used for classification. It is a statistical model that uses a logistic function to model a binary dependent variable. In essence, it predicts the probability of an observation belonging to a certain class or label. For instance, is this a cat photo or a dog photo?\n",
        "\n",
        "Ordinary Least Squares linear regression is powerful and versatile right out of the box, but there are certain circumstances where it fails.\n",
        "\n",
        "1. It is, expressly, a â€˜regressionâ€™ framework, which makes it hard to apply as a classifier.\n",
        "2. Unlike, say, a decision tree, linear regression models donâ€™t perform their implicit feature selection, meaning they are prone to overfit if too many features are included.\n",
        "\n",
        "Luckily, there are some extensions to the linear model that allow us to overcome these issues. Logistic regression turns the linear regression framework into a classifier and various types of `regularization` of which the `Ridge` and `Lasso` methods are most common, help avoid overfit in feature-rich instances."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nagHb5TbB0my"
      },
      "source": [
        "### **Hypothesis** \n",
        "We want our model to predict the probability of an observation belonging to a certain class or label. As such, we want a hypothesis $h$ that satisfies the following condition $0 <= h(x) <= 1$ , where $x$ is an observation.\n",
        "\n",
        "We define $h(x) = g(w^T * x)$ , where $g$ is a sigmoid function and $w$ are the trainable parameters or `weights`. As such, we have:\n",
        "$$h(x) = \\frac{1}{1+e^{-w^Tx}}$$\n",
        "\n",
        "### The cost for an observation \n",
        "Now that we can predict the probability for an observation, we want the result to have the minimum error. If the class label is $y$, the cost (error) associated with an observation $x$ is given by:\n",
        "\n",
        "![](https://miro.medium.com/max/525/1*vSGnYVz6I7sAObKuxuFAoQ.gif)\n",
        "\n",
        "### Cost Function\n",
        "Thus, the total cost for all the $`$ observations in a dataset is:\n",
        "![](https://miro.medium.com/max/368/0*vZnp94vCoN0vMDAj)\n",
        "\n",
        "We can rewrite the cost function J as:\n",
        "![](https://miro.medium.com/max/691/0*o57ug0iMGDJVI1qo)\n",
        "\n",
        "The objective of logistic regression is to find params `w` so that `J` is minimum. How can we do that?? We will use the gradient descent algorithm to update each of the weights gradually to minimize the cost `J`. \n",
        "\n",
        "We will update each of the params wáµ¢ using the following template:\n",
        "![](https://miro.medium.com/max/875/0*Q6ssvXABrvHUZrfy)\n",
        "![](https://miro.medium.com/max/496/0*7uVvuW-ZGauNWH_V)\n",
        "\n",
        "The above step will help us find a set of params wáµ¢, which will then help us to come up with $h(x)$ to solve our binary classification task.\n",
        "But there is also an undesirable outcome associated with the above gradient descent steps. In an attempt to find the best $h(x)$, the following things happen:\n",
        "\n",
        "**CASE I: For class label = 0**: $h(x)$ will try to produce results as close 0 as possible. As such, $w^T.x$ will be as small as possible\n",
        "=> Wi will tend to -infinity\n",
        "\n",
        "**CASE II: For class label = 1**: $h(x)$ will try to produce results as close 1 as possible. As such, $w^T.x$ will be as large as possible\n",
        "=> Wi will tend to +infinity\n",
        "\n",
        "\n",
        "## Regularization\n",
        "Regularization is a technique to solve the problem of overfitting in a machine learning algorithm by penalizing the cost function. It does so by using an additional penalty term in the cost function.\n",
        "There are two types of regularization techniques:\n",
        "1. Lasso or L1 Regularization\n",
        "2. Ridge or L2 Regularization (We will implement here)\n",
        "So, how can L2 Regularization help to prevent overfitting? Letâ€™s first look at our new cost function:\n",
        "\n",
        "![](https://miro.medium.com/max/628/0*Nc_ocecF0dHpUutK)\n",
        "\n",
        "\n",
        "The regularization term will heavily penalize large $w_i$. The effect will be less on smaller $w_i$â€™s. As such, the growth of $w$ is controlled. The $h(x)$ we obtain with these controlled params $w$ will be more generalizable.\n",
        "\n",
        "**NOTE:** $Î»$ is a hyper-parameter value. We have to find it using cross-validation. \n",
        "* Larger value $Î»$ of will make $w_i$ shrink closer to $0$, which might lead to underfitting. \n",
        "* $Î» = 0$, will have no regulariztion effect. \n",
        "\n",
        "When choosing $Î»$, we have to take proper care of bias vs variance trade-off.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NkuVzToYA9wm"
      },
      "outputs": [],
      "source": [
        "class LogisticRegression(object):\n",
        "    \"\"\"\n",
        "    Logistic Regression Classifier\n",
        "    Parameters\n",
        "    ----------\n",
        "    learning_rate : int or float, default=0.1\n",
        "        The tuning parameter for the optimization algorithm (here, Gradient Descent) \n",
        "        that determines the step size at each iteration while moving toward a minimum \n",
        "        of the cost function.\n",
        "    max_iter : int, default=100\n",
        "        Maximum number of iterations taken for the optimization algorithm to converge\n",
        "    \n",
        "    penalty : None or 'l2', default='l2'.\n",
        "        Option to perform L2 regularization.\n",
        "    C : float, default=0.1\n",
        "        Inverse of regularization strength; must be a positive float. \n",
        "        Smaller values specify stronger regularization. \n",
        "    tolerance : float, optional, default=1e-4\n",
        "        Value indicating the weight change between epochs in which\n",
        "        gradient descent should terminated. \n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, learning_rate=0.1, max_iter=100, regularization='l2', lambda_ = 10 , tolerance = 1e-4):\n",
        "        self.learning_rate  = learning_rate\n",
        "        self.max_iter       = max_iter\n",
        "        self.regularization = regularization\n",
        "        self.lambda_        = lambda_\n",
        "        self.tolerance      = tolerance\n",
        "        self.loss_log       = []\n",
        "    \n",
        "    def fit(self, X, y, verbose = False):\n",
        "        \"\"\"\n",
        "        Fit the model according to the given training data.\n",
        "        Parameters\n",
        "        Steps:\n",
        "        ------\n",
        "        1. Initialize all weights for each features as random\n",
        "        2. Add an extra feature for each sample at the beginning where the feature value is 1.\n",
        "        3. In each iteration calculate the predicted value of y. Then, calculate error and update the weight vector.\n",
        "        ----------\n",
        "        X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
        "            Training vector, where n_samples is the number of samples and\n",
        "            n_features is the number of features.\n",
        "        y : array-like of shape (n_samples,)\n",
        "            Target vector relative to X.\n",
        "        Returns\n",
        "        -------\n",
        "        self : object\n",
        "        \"\"\"\n",
        "        no_samples = X.shape[0]\n",
        "        no_features = X.shape[1]\n",
        "\n",
        "        self.W = np.random.rand(no_features + 1) # random initialization, +1 for bias\n",
        "        \n",
        "        extra_feature_with_value_1 = np.ones((no_samples, 1))\n",
        "        X = np.concatenate((extra_feature_with_value_1, X), axis = 1)  # match dimension with W. Optimizes the bias calculation\n",
        "        \n",
        "        self.loss_log = []\n",
        "\n",
        "        for iteration in range(self.max_iter):\n",
        "            Z = np.matmul(X,  self.W)\n",
        "\n",
        "            y_hat = self.__sigmoid(Z)\n",
        "            \n",
        "            errors = y_hat - y\n",
        "\n",
        "            if self.regularization:\n",
        "              cost = (-1.0/no_samples) * np.sum( y*np.log(y_hat) + (1.0 - y)*np.log(1.0-y_hat)) + (1.0/no_samples)* self.lambda_ * np.matmul(self.W, np.transpose(self.W))\n",
        "            else:\n",
        "              cost = (-1.0/no_samples) * np.sum( y*np.log(y_hat) + (1.0 - y)*np.log(1.0-y_hat))\n",
        "\n",
        "            self.loss_log.append(cost)\n",
        "            \n",
        "            if verbose:\n",
        "                print(f'Iteration {iteration} Loss: {cost}') # For printing loss of every epoch\n",
        "\n",
        "            if self.regularization is not None:\n",
        "                delta_grad = (1./no_samples) *(np.matmul(np.transpose(errors), X)+ self.lambda_ * self.W)\n",
        "            else:\n",
        "                delta_grad = (1./no_samples) *(np.matmul(np.transpose(errors), X))\n",
        "                \n",
        "            self.W -= self.learning_rate * delta_grad\n",
        "\n",
        "#             if np.all(abs(delta_grad) >= self.tolerance):\n",
        "#                 self.W -= self.learning_rate * delta_grad\n",
        "#             else:\n",
        "#                 break\n",
        "                \n",
        "        return self\n",
        "\n",
        "    def predict_proba(self, X):\n",
        "        \"\"\"\n",
        "        Probability estimates for samples in X.\n",
        "        Parameters\n",
        "        ----------\n",
        "        X : array-like of shape (n_samples, n_features)\n",
        "            Vector to be scored, where `n_samples` is the number of samples and\n",
        "            `n_features` is the number of features.h(x)=11+eâˆ’wTx\n",
        "        Returns\n",
        "        -------\n",
        "        probs : array-like of shape (n_samples,)\n",
        "            Returns the probability of each sample.\n",
        "        \"\"\"\n",
        "        no_samples = X.shape[0]\n",
        "        no_features = X.shape[1]\n",
        "\n",
        "        samples = np.reshape(X, (no_samples, no_features))\n",
        "        weights = np.reshape(self.W[1:], (no_features, 1))\n",
        "\n",
        "        samples = np.matrix(samples)\n",
        "        weights = np.matrix(weights)\n",
        "        \n",
        "        wtx = np.matmul(samples, weights)\n",
        "        \n",
        "        z = wtx + self.W[0]\n",
        "\n",
        "        probabilities = self.__sigmoid(z)\n",
        "        #return self.__sigmoid((X @ self.W[1:]) + self.W[0])\n",
        "        return probabilities\n",
        "    \n",
        "    def predict(self, X):\n",
        "        \"\"\"\n",
        "        Predict class labels for samples in X.\n",
        "        Parameters\n",
        "        ----------\n",
        "        X : array_like or sparse matrix, shape (n_samples, n_features)\n",
        "            Samples.\n",
        "        Returns\n",
        "        -------\n",
        "        labels : array, shape [n_samples]\n",
        "            Predicted class label per sample.\n",
        "        \"\"\"\n",
        "        return np.round(self.predict_proba(X))\n",
        "        \n",
        "    def __sigmoid(self, z):\n",
        "        \"\"\"\n",
        "        The sigmoid function.\n",
        "        Parameters\n",
        "        ------------\n",
        "        z : float\n",
        "            linear combinations of weights and sample features\n",
        "            z = w_0 + w_1*x_1 + ... + w_n*x_n\n",
        "        Returns\n",
        "        ---------\n",
        "        Value of logistic function at z\n",
        "        \"\"\"\n",
        "        return (1.0 / (1.0 + np.exp(-z)))\n",
        "\n",
        "    def get_params(self):\n",
        "        \"\"\"\n",
        "        Get method for models coeffients and intercept.\n",
        "        Returns\n",
        "        -------\n",
        "        params : dict\n",
        "        \"\"\"\n",
        "        try:\n",
        "            params = dict()\n",
        "            params['intercept'] = self.W[0]\n",
        "            params['coef'] = self.W[1:]\n",
        "            return params\n",
        "        except:\n",
        "            raise Exception('Fit the model first!')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3hqNbBtyC2Ot"
      },
      "source": [
        "**Train and Test Data Validation**\n",
        "\n",
        "Let us split the whole data into two portion. We take 80% data in the train set and then put rest of the data into the test set to check the performance of the trained model. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        },
        "id": "cGBONkO0Cy89",
        "outputId": "ec396c70-5d16-4bf3-ec25-fe6ebd3bd741"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>\n",
              "            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>\n",
              "                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-latest.min.js\"></script>    \n",
              "            <div id=\"9f421839-a527-43ef-88b9-6d93282d92b0\" class=\"plotly-graph-div\" style=\"height:400px; width:800px;\"></div>\n",
              "            <script type=\"text/javascript\">\n",
              "                \n",
              "                    window.PLOTLYENV=window.PLOTLYENV || {};\n",
              "                    \n",
              "                if (document.getElementById(\"9f421839-a527-43ef-88b9-6d93282d92b0\")) {\n",
              "                    Plotly.newPlot(\n",
              "                        '9f421839-a527-43ef-88b9-6d93282d92b0',\n",
              "                        [{\"marker\": {\"color\": \"crimson\"}, \"name\": \"Malignant\", \"type\": \"bar\", \"x\": [\"Train\", \"Test\"], \"y\": [169, 43]}, {\"base\": 0, \"marker\": {\"color\": \"lightgreen\"}, \"name\": \"Benign\", \"type\": \"bar\", \"x\": [\"Train\", \"Test\"], \"y\": [286, 71]}],\n",
              "                        {\"height\": 400, \"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}, \"title\": {\"text\": \"Count of Samples in Train and Test Split\", \"x\": 0.5}, \"width\": 800, \"xaxis\": {\"title\": {\"text\": \"Category\"}}, \"yaxis\": {\"title\": {\"text\": \"Sample Count\"}}},\n",
              "                        {\"responsive\": true}\n",
              "                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('9f421839-a527-43ef-88b9-6d93282d92b0');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })\n",
              "                };\n",
              "                \n",
              "            </script>\n",
              "        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_data, y_data, test_size=0.20, random_state=42)\n",
        "\n",
        "# Train and Test Data Summary\n",
        "import plotly.graph_objects as go\n",
        "split = ['Train','Test']\n",
        "\n",
        "fig = go.Figure()\n",
        "fig.add_trace(go.Bar(x=split, y=[np.sum(y_train), np.sum(y_test)],#                base=[-500,-600],\n",
        "                    marker_color='crimson',\n",
        "                    name='Malignant'))\n",
        "fig.add_trace(go.Bar(x=split, \n",
        "                     y=[len(y_train)- np.sum(y_train), len(y_test) - np.sum(y_test)],\n",
        "                    base=0,\n",
        "                    marker_color='lightgreen',\n",
        "                    name='Benign'                ))\n",
        "fig.update_layout(width = 800, height = 400)\n",
        "fig.update_layout(title = 'Count of Samples in Train and Test Split', title_x = 0.5, xaxis_title = \"Category\", yaxis_title = 'Sample Count')\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ot2b9mciDAJz"
      },
      "source": [
        "**Training Logistic Regression**\n",
        "\n",
        "Now we train the logistic regression with the training data for a maximum interation of 200. Other parameters are kept default. Feel free to fiddle around the other parameters to understand more of them. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_EEAdHzbDFUo",
        "outputId": "08bbfa74-c118-4f59-90db-e4aa3a5fdfb1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<__main__.LogisticRegression at 0x7fdaa2ffc150>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "MAX_ITER = 400\n",
        "LR_RATE = 1e-2\n",
        "\n",
        "clf_no_reg = LogisticRegression(max_iter = MAX_ITER, learning_rate= LR_RATE, regularization= None)\n",
        "clf_no_reg.fit(X_train, y_train, verbose = False)\n",
        "\n",
        "clf_reg_10 = LogisticRegression(max_iter = MAX_ITER, learning_rate= LR_RATE, lambda_ = 10, regularization= 'l2')\n",
        "clf_reg_10.fit(X_train, y_train, verbose = False)\n",
        "\n",
        "\n",
        "clf_reg_20 = LogisticRegression(max_iter = MAX_ITER, learning_rate= LR_RATE, lambda_ = 20, regularization= 'l2')\n",
        "clf_reg_20.fit(X_train, y_train, verbose = False)\n",
        "\n",
        "clf_reg_40 = LogisticRegression(max_iter = MAX_ITER, learning_rate= LR_RATE, lambda_ = 40, regularization= 'l2')\n",
        "clf_reg_40.fit(X_train, y_train, verbose = False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4s9F2_5hDKsa"
      },
      "source": [
        "**Plot Training Loss over Time**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 517
        },
        "id": "2vgX40VjDOzi",
        "outputId": "60cfe065-61db-4000-e6ec-9b53053cbf0a"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>\n",
              "            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>\n",
              "                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-latest.min.js\"></script>    \n",
              "            <div id=\"1f860384-a96a-4573-b0f6-5d7edfdefb63\" class=\"plotly-graph-div\" style=\"height:500px; width:800px;\"></div>\n",
              "            <script type=\"text/javascript\">\n",
              "                \n",
              "                    window.PLOTLYENV=window.PLOTLYENV || {};\n",
              "                    \n",
              "                if (document.getElementById(\"1f860384-a96a-4573-b0f6-5d7edfdefb63\")) {\n",
              "                    Plotly.newPlot(\n",
              "                        '1f860384-a96a-4573-b0f6-5d7edfdefb63',\n",
              "                        [{\"mode\": \"lines+markers\", \"name\": \"No Regularization\", \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399], \"y\": [1.6969331467634114, 1.6896017821314018, 1.6822885047700755, 1.6749934859742808, 1.6677168976201724, 1.6604589121402529, 1.6532197024977333, 1.645999442160206, 1.6387983050726342, 1.6316164656296483, 1.6244540986471563, 1.6173113793332565, 1.6101884832584636, 1.603085586325242, 1.5960028647368405, 1.5889404949654458, 1.5818986537196387, 1.5748775179111674, 1.5678772646210348, 1.5608980710649023, 1.5539401145578182, 1.547003572478272, 1.540088622231579, 1.5331954412126043, 1.526324206767827, 1.519475096156759, 1.512648286512717, 1.5058439548029658, 1.499062277788232, 1.4923034319816066, 1.4855675936068415, 1.4788549385560505, 1.4721656423468326, 1.4654998800788217, 1.4588578263896859, 1.452239655410579, 1.4456455407210687, 1.4390756553035546, 1.4325301714971874, 1.4260092609513122, 1.4195130945784522, 1.4130418425068496, 1.4065956740325862, 1.4001747575713006, 1.3937792606095216, 1.3874093496556503, 1.3810651901905948, 1.3747469466180984, 1.368454782214776, 1.3621888590798812, 1.355949338084839, 1.3497363788225605, 1.3435501395565679, 1.3373907771699676, 1.3312584471142794, 1.3251533033581728, 1.3190754983361226, 1.3130251828970207, 1.3070025062527773, 1.301007615926934, 1.29504065770333, 1.2891017755748477, 1.2831911116922683, 1.277308806313278, 1.2714549977516536, 1.265629822326655, 1.2598334143126757, 1.2540659058891668, 1.2483274270908835, 1.2426181057584806, 1.2369380674894979, 1.2312874355897663, 1.2256663310252762, 1.2200748723745365, 1.2145131757814667, 1.2089813549088575, 1.2034795208924283, 1.198007782295527, 1.1925662450645054, 1.1871550124848005, 1.1817741851377621, 1.1764238608582664, 1.171104134693136, 1.1658150988604186, 1.1605568427095456, 1.155329452682413, 1.1501330122754105, 1.1449676020024386, 1.1398332993589435, 1.1347301787870008, 1.129658311641478, 1.1246177661573138, 1.1196086074179337, 1.1146308973248376, 1.1096846945683863, 1.1047700545998145, 1.0998870296044958, 1.095035668476486, 1.0902160167943693, 1.0854281167984314, 1.0806720073691818, 1.0759477240072457, 1.0712552988146482, 1.0665947604775083, 1.06196613425016, 1.0573694419407207, 1.0528047018981184, 1.048271929000594, 1.0437711346456935, 1.0393023267417567, 1.034865509700919, 1.0304606844336304, 1.026087848344701, 1.0217469953308806, 1.0174381157799761, 1.013161196571507, 1.0089162210789069, 1.004703169173269, 1.0005220172286318, 0.9963727381288057, 0.9922553012757385, 0.9881696725994091, 0.9841158145692488, 0.9800936862070763, 0.9761032431015426, 0.9721444374240711, 0.9682172179462812, 0.9643215300588838, 0.9604573157920311, 0.9566245138371053, 0.9528230595699307, 0.9490528850753868, 0.9453139191734033, 0.9416060874463186, 0.9379293122675745, 0.9342835128317265, 0.9306686051857445, 0.927084502261576, 0.923531113909947, 0.9200083469353721, 0.9165161051323424, 0.9130542893226657, 0.9096227973939228, 0.9062215243390124, 0.9028503622967512, 0.8995092005934928, 0.896197925785736, 0.8929164217036846, 0.8896645694957237, 0.8864422476737792, 0.8832493321595204, 0.8800856963313705, 0.8769512110722893, 0.8738457448182881, 0.8707691636076383, 0.8677213311307395, 0.8647021087806027, 0.8617113557039161, 0.8587489288526488, 0.855814683036159, 0.8529084709737634, 0.8500301433477314, 0.847179548856664, 0.8443565342692212, 0.8415609444781552, 0.8387926225546143, 0.836051409802679, 0.8333371458140908, 0.830649668523139, 0.8279888142616648, 0.8253544178141498, 0.8227463124728494, 0.8201643300929378, 0.8176083011476284, 0.8150780547832338, 0.812573418874133, 0.8100942200776122, 0.8076402838885444, 0.8052114346938778, 0.8028074958269008, 0.8004282896212525, 0.7980736374646482, 0.7957433598522929, 0.7934372764399499, 0.7911552060966425, 0.7888969669569579, 0.7866623764729275, 0.7844512514654595, 0.7822634081753017, 0.7800986623135036, 0.7779568291113652, 0.7758377233698421, 0.7737411595083912, 0.7716669516132357, 0.7696149134850291, 0.7675848586859013, 0.7655766005858705, 0.7635899524086014, 0.7616247272764972, 0.7596807382551107, 0.7577577983968578, 0.7558557207840233, 0.7539743185710481, 0.7521134050260816, 0.7502727935717958, 0.7484522978254458, 0.7466517316381717, 0.7448709091335333, 0.743109644745269, 0.7413677532542761, 0.7396450498248034, 0.7379413500398542, 0.7362564699357945, 0.7345902260361636, 0.7329424353846856, 0.7313129155774769, 0.7297014847944543, 0.7281079618299364, 0.7265321661224454, 0.7249739177837039, 0.7234330376268343, 0.7219093471937575, 0.7204026687817963, 0.7189128254694872, 0.7174396411416035, 0.7159829405133921, 0.7145425491540329, 0.7131182935093225, 0.7117100009235883, 0.7103174996608417, 0.7089406189251739, 0.707579188880402, 0.7062330406689751, 0.7049020064301426, 0.7035859193174002, 0.7022846135152144, 0.70099792425504, 0.6997256878306347, 0.6984677416126851, 0.6972239240627478, 0.6959940747465203, 0.6947780343464482, 0.6935756446736806, 0.6923867486793825, 0.6912111904654169, 0.6900488152944028, 0.6888994695991656, 0.6877630009915864, 0.6866392582708616, 0.6855280914311859, 0.6844293516688683, 0.6833428913888914, 0.6822685642109276, 0.6812062249748208, 0.6801557297455473, 0.6791169358176656, 0.6780897017192666, 0.6770738872154357, 0.6760693533112384, 0.6750759622542414, 0.6740935775365767, 0.6731220638965656, 0.6721612873199092, 0.6712111150404578, 0.6702714155405713, 0.6693420585510809, 0.6684229150508609, 0.6675138572660256, 0.666614758668758, 0.6657254939757832, 0.6648459391464964, 0.6639759713807547, 0.6631154691163457, 0.6622643120261396, 0.6614223810149381, 0.6605895582160266, 0.6597657269874442, 0.6589507719079748, 0.6581445787728739, 0.6573470345893404, 0.6565580275717369, 0.6557774471365757, 0.6550051838972725, 0.6542411296586806, 0.653485177411414, 0.6527372213259631, 0.6519971567466201, 0.6512648801852128, 0.650540289314662, 0.6498232829623658, 0.6491137611034217, 0.6484116248536909, 0.6477167764627149, 0.6470291193064903, 0.6463485578801088, 0.6456749977902696, 0.6450083457476713, 0.6443485095592887, 0.6436953981205424, 0.6430489214073674, 0.6424089904681838, 0.6417755174157814, 0.6411484154191185, 0.6405275986950427, 0.6399129824999403, 0.6393044831213188, 0.6387020178693256, 0.6381055050682137, 0.6375148640477516, 0.6369300151345897, 0.6363508796435825, 0.6357773798690747, 0.6352094390761526, 0.6346469814918676, 0.6340899322964356, 0.6335382176144142, 0.6329917645058638, 0.632450500957497, 0.6319143558738167, 0.6313832590682495, 0.6308571412542778, 0.6303359340365698, 0.6298195699021184, 0.6293079822113828, 0.6288011051894438, 0.6282988739171702, 0.6278012243224026, 0.6273080931711552, 0.626819418058839, 0.6263351374015083, 0.625855190427134, 0.6253795171669055, 0.6249080584465624, 0.6244407558777588, 0.6239775518494638, 0.6235183895193969, 0.6230632128055037, 0.6226119663774701, 0.6221645956482796, 0.6217210467658152, 0.6212812666045037, 0.6208452027570097, 0.6204128035259755, 0.6199840179158115, 0.6195587956245372, 0.6191370870356727, 0.6187188432101859, 0.6183040158784908, 0.6178925574325032, 0.6174844209177502, 0.617079560025539, 0.6166779290851814, 0.6162794830562789, 0.6158841775210641, 0.6154919686768054, 0.6151028133282701, 0.6147166688802489, 0.6143334933301435, 0.6139532452606141, 0.6135758838322922, 0.6132013687765543, 0.6128296603883595, 0.6124607195191527, 0.6120945075698287, 0.6117309864837631, 0.6113701187399074, 0.6110118673459474, 0.6106561958315274, 0.6103030682415408, 0.6099524491294827, 0.60960430355087, 0.6092585970567269, 0.6089152956871331, 0.6085743659648395, 0.6082357748889488, 0.60789948992866, 0.6075654790170785, 0.6072337105450911, 0.6069041533553058, 0.6065767767360554, 0.6062515504154667, 0.6059284445555924, 0.6056074297466086, 0.6052884770010745, 0.6049715577482552, 0.6046566438285114, 0.604343707487746, 0.6040327213719193, 0.6037236585216219, 0.6034164923667125, 0.6031111967210158, 0.6028077457770825, 0.6025061141010103, 0.6022062766273243, 0.6019082086539191, 0.6016118858370596, 0.6013172841864423, 0.6010243800603141, 0.6007331501606515, 0.6004435715283963]}, {\"mode\": \"lines+markers\", \"name\": \"Regulrization W=10\", \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399], \"y\": [2.4693248845368294, 2.459593826741427, 2.449878227941947, 2.4401781888908745, 2.4304938113032644, 2.420825197858634, 2.411172452202632, 2.401535678948508, 2.391914983678366, 2.3823104729441873, 2.3727222542686324, 2.363150436145603, 2.353595128040558, 2.344056440390594, 2.3345344846042577, 2.3250293730611036, 2.315541219110983, 2.3060701370730556, 2.296616242234525, 2.2871796508490783, 2.277760480135041, 2.2683588482732193, 2.2589748744044407, 2.249608678626781, 2.240260381992457, 2.2309301065044047, 2.221617975112513, 2.2123241117095147, 2.2030486411265273, 2.193791689128237, 2.1845533824077226, 2.1753338485808977, 2.1661332161805857, 2.1569516146502066, 2.1477891743370647, 2.1386460264852487, 2.1295223032281188, 2.1204181375803803, 2.111333663429745, 2.1022690155281603, 2.093224329482609, 2.084199741745466, 2.0751953896044157, 2.0662114111719143, 2.0572479453741908, 2.048305131939791, 2.039383111387644, 2.0304820250146562, 2.0216020148828235, 2.0127432238058542, 2.0039057953352986, 1.995089873746182, 1.9862956040221313, 1.9775231318399962, 1.9687726035539517, 1.9600441661790877, 1.9513379673744748, 1.9426541554256986, 1.93399287922687, 1.9253542882620942, 1.9167385325864101, 1.908145762806178, 1.8995761300589307, 1.8910297859926755, 1.8825068827446434, 1.8740075729194936, 1.8655320095669559, 1.8570803461589263, 1.8486527365659997, 1.84024933503345, 1.8318702961566513, 1.82351577485594, 1.8151859263509225, 1.8068809061342215, 1.798600869944671, 1.7903459737399534, 1.7821163736686862, 1.7739122260419542, 1.765733687304301, 1.7575809140041652, 1.749454062763784, 1.7413532902485562, 1.7332787531358702, 1.7252306080834034, 1.7172090116969043, 1.7092141204974496, 1.7012460908881955, 1.693305079120622, 1.6853912412602825, 1.677504733152061, 1.6696457103849514, 1.6618143282563649, 1.6540107417359704, 1.6462351054290856, 1.6384875735396247, 1.6307682998326138, 1.6230774375962855, 1.6154151396037664, 1.6077815580743653, 1.6001768446344835, 1.592601150278151, 1.5850546253272084, 1.5775374193911487, 1.5700496813266342, 1.562591559196699, 1.555163200229662, 1.5477647507777597, 1.5403963562755212, 1.5330581611978968, 1.525750309018165, 1.5184729421656329, 1.5112262019831502, 1.5040102286844548, 1.4968251613113734, 1.489671137690892, 1.482548294392126, 1.4754567666831988, 1.4683966884880675, 1.4613681923432973, 1.454371409354826, 1.4474064691547315, 1.4404734998580264, 1.4335726280195067, 1.4267039785906719, 1.419867674876755, 1.4130638384938625, 1.4062925893262808, 1.3995540454839432, 1.3928483232601034, 1.3861755370892341, 1.379535799505173, 1.3729292210995505, 1.3663559104805159, 1.3598159742317923, 1.3533095168720888, 1.3468366408148922, 1.3403974463286645, 1.3339920314974745, 1.32762049218209, 1.3212829219815536, 1.314979412195271, 1.308710051785636, 1.3024749273412213, 1.2962741230405541, 1.2901077206165104, 1.2839757993213452, 1.277878435892393, 1.2718157045184504, 1.2657876768068779, 1.2597944217514407, 1.2538360057009064, 1.247912492328433, 1.2420239426017616, 1.236170414754244, 1.2303519642567187, 1.2245686437902654, 1.2188205032198534, 1.2131075895689067, 1.2074299469948058, 1.2017876167653436, 1.1961806372361596, 1.1906090438291614, 1.1850728690119618, 1.179572142278338, 1.1741068901297393, 1.1686771360578472, 1.1632829005282128, 1.1579242009649806, 1.1526010517367105, 1.147313464143314, 1.1420614464041132, 1.1368450036470341, 1.1316641378989438, 1.1265188480771433, 1.121409129982016, 1.1163349762908508, 1.1112963765528352, 1.1062933171852292, 1.101325781470725, 1.0963937495559928, 1.0914971984514175, 1.0866361020320274, 1.081810431039617, 1.0770201530860588, 1.0722652326578115, 1.067545631121613, 1.0628613067313624, 1.058212214636184, 1.0535983068896686, 1.049019532460285, 1.0444758372429608, 1.0399671640718156, 1.0354934527340476, 1.0310546399849563, 1.0266506595640963, 1.0222814422125508, 1.0179469156913075, 1.0136470048007318, 1.009381631401117, 1.0051507144343028, 1.0009541699463411, 0.9967919111111974, 0.9926638482554704, 0.9885698888841105, 0.9845099377071205, 0.9804838966672196, 0.9764916649684513, 0.9725331391057143, 0.968608212895195, 0.9647167775056846, 0.9608587214907506, 0.9570339308217511, 0.9532422889216586, 0.9494836766996768, 0.9457579725866223, 0.942065052571051, 0.9384047902361009, 0.9347770567970263, 0.9311817211394018, 0.9276186498579658, 0.9240877072960789, 0.9205887555857741, 0.9171216546883658, 0.9136862624355974, 0.9102824345712963, 0.9069100247935119, 0.9035688847971071, 0.9002588643167775, 0.8969798111704705, 0.8937315713031798, 0.8905139888310799, 0.8873269060859847, 0.8841701636600927, 0.8810436004509978, 0.8779470537069369, 0.8748803590722459, 0.871843350633, 0.868835860962809, 0.8658577211687435, 0.8629087609373648, 0.8599888085808309, 0.8570976910830578, 0.8542352341459036, 0.8514012622353577, 0.8485955986277051, 0.8458180654556438, 0.8430684837543305, 0.8403466735073329, 0.8376524536924606, 0.834985642327458, 0.8323460565155325, 0.8297335124906979, 0.8271478256629112, 0.8245888106629807, 0.8220562813872272, 0.819550051041877, 0.817069932187167, 0.8146157367811436, 0.812187276223137, 0.8097843613968914, 0.8074068027133374, 0.8050544101529854, 0.8027269933079273, 0.80042436142343, 0.7981463234391017, 0.7958926880296248, 0.7936632636450326, 0.7914578585505221, 0.7892762808657883, 0.7871183386038655, 0.7849838397094698, 0.7828725920968254, 0.7807844036869671, 0.7787190824445095, 0.7766764364138721, 0.7746562737549527, 0.772658402778239, 0.7706826319793535, 0.7687287700730205, 0.7667966260264539, 0.7648860090921537, 0.7629967288401103, 0.7611285951894092, 0.7592814184392325, 0.7574550092992521, 0.7556491789194123, 0.7538637389190976, 0.7520985014156845, 0.7503532790524724, 0.7486278850259971, 0.7469221331127183, 0.7452358376950885, 0.7435688137869957, 0.7419208770585849, 0.7402918438604564, 0.7386815312472442, 0.7370897570005703, 0.7355163396513857, 0.7339610985016896, 0.732423853645638, 0.730904425990039, 0.7294026372742399, 0.7279183100894093, 0.7264512678972174, 0.7250013350479197, 0.7235683367978464, 0.7221520993263028, 0.7207524497518873, 0.7193692161482291, 0.718002227559153, 0.716651314013275, 0.7153163065380369, 0.7139970371731844, 0.7126933389836932, 0.711405046072153, 0.7101319935906124, 0.7088740177518955, 0.7076309558403906, 0.706402646222326, 0.7051889283555326, 0.7039896427987063, 0.7028046312201727, 0.7016337364061651, 0.700476802268624, 0.6993336738525187, 0.6982041973427107, 0.6970882200703534, 0.6959855905188473, 0.6948961583293511, 0.6938197743058604, 0.6927562904198604, 0.6917055598145622, 0.6906674368087273, 0.6896417769000946, 0.6886284367684109, 0.6876272742780775, 0.6866381484804197, 0.6856609196155884, 0.6846954491140992, 0.6837415995980196, 0.6827992348818115, 0.6818682199728368, 0.6809484210715344, 0.6800397055712764, 0.679141942057911, 0.6782550003090003, 0.6773787512927616, 0.6765130671667191, 0.6756578212760718, 0.6748128881517891, 0.6739781435084399, 0.6731534642417609, 0.6723387284259738, 0.6715338153108575, 0.6707386053185848, 0.6699529800403254, 0.6691768222326302, 0.6684100158135957, 0.6676524458588213, 0.6669039985971643, 0.6661645614062975, 0.6654340228080805, 0.6647122724637452, 0.6639992011689083, 0.6632947008484127, 0.6625986645510048, 0.6619109864438556, 0.6612315618069299, 0.6605602870272098, 0.6598970595927809, 0.65924177808678, 0.6585943421812195, 0.657954652630687, 0.6573226112659267, 0.656698120987311, 0.6560810857582033, 0.6554714105982219, 0.6548690015764036, 0.6542737658042789, 0.6536856114288588, 0.6531044476255397, 0.6525301845909302, 0.6519627335356063, 0.6514020066767962, 0.6508479172310014, 0.650300379406558, 0.6497593083961416, 0.6492246203692195, 0.6486962324644556, 0.6481740627820711, 0.6476580303761632, 0.6471480552469883, 0.64664405833321, 0.6461459615041201, 0.6456536875518281, 0.6451671601834318, 0.6446863040131652, 0.6442110445545298, 0.6437413082124114, 0.6432770222751856]}, {\"mode\": \"lines+markers\", \"name\": \"Regulrization W=20\", \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399], \"y\": [2.2957431407937126, 2.285480275757344, 2.275247596676033, 2.2650452432007606, 2.254873355597649, 2.2447320747276374, 2.2346215420255606, 2.2245418994786434, 2.2144932896043863, 2.20447585542786, 2.194489740458392, 2.184535088665643, 2.1746120444550887, 2.164720752642877, 2.1548613584300815, 2.1450340073763456, 2.1352388453729048, 2.1254760186150055, 2.115745673573706, 2.106047956967067, 2.0963830157307277, 2.0867509969878797, 2.0771520480186245, 2.067586316228733, 2.0580539491177974, 2.0485550942467876, 2.03908989920501, 2.02965851157648, 2.0202610789057003, 2.01089774866287, 2.0015686682085074, 1.9922739847575164, 1.9830138453426824, 1.973788396777621, 1.9645977856191776, 1.9554421581292947, 1.946321660236348, 1.937236437495968, 1.9281866350513552, 1.919172397593096, 1.9101938693184997, 1.9012511938904597, 1.8923445143958588, 1.8834739733035266, 1.8746397124217675, 1.8658418728554729, 1.8570805949628264, 1.8483560183116325, 1.839668281635269, 1.8310175227882906, 1.8224038787016978, 1.8138274853378906, 1.8052884776453222, 1.7967869895128805, 1.788323153724005, 1.779897101910572, 1.7715089645065631, 1.7631588707015353, 1.754846948393924, 1.746573324144193, 1.7383381231278618, 1.7301414690884265, 1.721983484290204, 1.7138642894711247, 1.705784003795495, 1.6977427448067548, 1.6897406283802625, 1.6817777686761275, 1.6738542780921168, 1.66597026721667, 1.6581258447820413, 1.6503211176176, 1.642556190603322, 1.6348311666234925, 1.627146146520652, 1.61950122904982, 1.6118965108330143, 1.6043320863141062, 1.59680804771403, 1.5893244849863901, 1.5818814857734793, 1.574479135362751, 1.5671175166437679, 1.5597967100656578, 1.55251679359511, 1.545277842674934, 1.5380799301832204, 1.5309231263931216, 1.5238074989332926, 1.5167331127490127, 1.5097000300640184, 1.5027083103430825, 1.495758010255356, 1.488849183638512, 1.4819818814637096, 1.4751561518014147, 1.4683720397880942, 1.461629587593816, 1.4549288343907811, 1.4482698163228092, 1.4416525664758044, 1.4350771148492256, 1.428543488328585, 1.4220517106589963, 1.415601802419797, 1.4091937810002624, 1.402827660576438, 1.3965034520891035, 1.3902211632228951, 1.3839807983865953, 1.3777823586946183, 1.3716258419497003, 1.3655112426268115, 1.3594385518583079, 1.3534077574203363, 1.3474188437205012, 1.3414717917868126, 1.335566579257919, 1.329703180374645, 1.3238815659728296, 1.318101703477488, 1.312363556898292, 1.306667086826382, 1.3010122504325157, 1.295399001466552, 1.2898272902582806, 1.2842970637195916, 1.2788082653479935, 1.273360835231474, 1.267954710054703, 1.2625898231065777, 1.2572661042891053, 1.2519834801276164, 1.2467418737823093, 1.24154120506111, 1.2363813904338492, 1.2312623430477414, 1.226183972744158, 1.221146186076685, 1.2161488863304513, 1.2111919735427168, 1.2062753445247034, 1.2013988928846595, 1.1965625090521352, 1.1917660803034587, 1.1870094907883906, 1.1822926215579403, 1.1776153505933271, 1.1729775528360609, 1.1683791002191248, 1.1638198616992388, 1.15929970329018, 1.1548184880971348, 1.1503760763520636, 1.1459723254500502, 1.1416070899866089, 1.1372802217959284, 1.1329915699900213, 1.128740980998756, 1.1245282986107394, 1.1203533640150245, 1.1162160158436156, 1.11211609021474, 1.1080534207768582, 1.1040278387533793, 1.1000391729880585, 1.0960872499910406, 1.092171893985519, 1.0882929269549833, 1.0844501686910202, 1.0806434368416404, 1.0768725469600957, 1.0731373125541603, 1.069437545135838, 1.065773054271471, 1.0621436476322135, 1.0585491310448425, 1.0549893085428703, 1.05146398241793, 1.0479729532714037, 1.04451602006626, 1.0410929801790718, 1.0377036294521815, 1.0343477622459876, 1.031025171491316, 1.027735648741855, 1.0244789842266138, 1.0212549669023876, 1.018063384506187, 1.014904023607618, 1.0117766696611707, 1.0086811070583999, 1.005617119179965, 1.0025844884475035, 0.9995829963753136, 0.996612423621819, 0.9936725500407914, 0.9907631547323053, 0.987884016093405, 0.9850349118684538, 0.9822156191991489, 0.9794259146741765, 0.976665574378488, 0.973934373942174, 0.9712320885889163, 0.9685584931840011, 0.96591336228187, 0.963296470173194, 0.9607075909314527, 0.9581464984589987, 0.9556129665325939, 0.9531067688484017, 0.9506276790664185, 0.9481754708543337, 0.9457499179307974, 0.9433507941080926, 0.9409778733341925, 0.9386309297341942, 0.9363097376511142, 0.9340140716860442, 0.931743706737646, 0.9294984180409844, 0.9272779812056902, 0.9250821722534377, 0.9229107676547392, 0.9207635443650456, 0.9186402798601438, 0.9165407521708542, 0.9144647399170165, 0.9124120223407601, 0.9103823793390633, 0.9083755914955857, 0.9063914401117852, 0.9044297072373064, 0.902490175699646, 0.9005726291330916, 0.8986768520069359, 0.8968026296529628, 0.89494974829221, 0.8931179950610074, 0.891307158036294, 0.8895170262602126, 0.8877473897639903, 0.8859980395911013, 0.8842687678197216, 0.8825593675844732, 0.8808696330974676, 0.8791993596686505, 0.8775483437254508, 0.8759163828317424, 0.8743032757061243, 0.8727088222395192, 0.8711328235121063, 0.8695750818095849, 0.868035400638784, 0.8665135847426166, 0.8650094401143942, 0.863522774011501, 0.8620533949684437, 0.8606011128092759, 0.8591657386594127, 0.8577470849568389, 0.8563449654627218, 0.8549591952714348, 0.853589590820005, 0.8522359698969864, 0.850898151650775, 0.8495759565973693, 0.8482692066275908, 0.846977725013766, 0.8457013364158888, 0.8444398668872644, 0.8431931438796488, 0.8419609962478909, 0.8407432542540911, 0.8395397495712799, 0.8383503152866287, 0.8371747859042064, 0.8360129973472841, 0.8348647869602042, 0.8337299935098177, 0.8326084571865053, 0.8315000196047879, 0.8304045238035351, 0.829321814245787, 0.828251736818191, 0.8271941388300708, 0.8261488690121295, 0.8251157775148039, 0.8240947159062724, 0.8230855371701291, 0.8220880957027343, 0.8211022473102476, 0.8201278492053534, 0.8191647600036905, 0.8182128397199897, 0.8172719497639322, 0.8163419529357374, 0.8154227134214822, 0.8145140967881725, 0.8136159699785612, 0.8127282013057318, 0.8118506604474504, 0.8109832184402942, 0.8101257476735682, 0.8092781218830111, 0.8084402161443058, 0.8076119068663963, 0.80679307178462, 0.8059835899536655, 0.8051833417403566, 0.8043922088162778, 0.8036100741502409, 0.8028368220006037, 0.8020723379074467, 0.8013165086846129, 0.8005692224116189, 0.7998303684254425, 0.7990998373121935, 0.7983775208986736, 0.7976633122438308, 0.7969571056301149, 0.7962587965547395, 0.7955682817208554, 0.7948854590286413, 0.7942102275663186, 0.7935424876010923, 0.7928821405700243, 0.7922290890708477, 0.7915832368527191, 0.790944488806922, 0.7903127509575201, 0.7896879304519677, 0.7890699355516795, 0.7884586756225676, 0.7878540611255439, 0.7872560036070002, 0.7866644156892612, 0.7860792110610189, 0.7855003044677535, 0.7849276117021399, 0.7843610495944463, 0.7838005360029284, 0.7832459898042201, 0.7826973308837271, 0.7821544801260224, 0.781617359405252, 0.7810858915755485, 0.7805600004614585, 0.7800396108483849, 0.779524648473048, 0.7790150400139686, 0.77851071308197, 0.7780115962107109, 0.7775176188472424, 0.7770287113425957, 0.776544804942402, 0.7760658317775475, 0.7755917248548632, 0.7751224180478511, 0.7746578460874534, 0.7741979445528608, 0.7737426498623647, 0.7732918992642522, 0.7728456308277513, 0.7724037834340178, 0.7719662967671769, 0.7715331113054116, 0.7711041683121026, 0.7706794098270237, 0.7702587786575872, 0.7698422183701478, 0.76942967328136, 0.7690210884495935, 0.7686164096664065, 0.7682155834480772, 0.7678185570271951, 0.7674252783443131, 0.76703569603966, 0.7666497594449145, 0.7662674185750427, 0.7658886241201971, 0.7655133274376805, 0.7651414805439719, 0.7647730361068199, 0.7644079474373973, 0.7640461684825245, 0.7636876538169548, 0.7633323586357301, 0.762980238746598, 0.7626312505624993, 0.7622853510941193, 0.7619424979425085, 0.7616026492917676, 0.7612657639018019, 0.7609318011011419, 0.7606007207798307, 0.7602724833823797, 0.7599470499007914, 0.7596243818676487]}, {\"mode\": \"lines+markers\", \"name\": \"Regulrization W=40\", \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399], \"y\": [3.9118396665300503, 3.8942326202069717, 3.876673564144867, 3.859162506640597, 3.841699457198353, 3.824284426536666, 3.8069174265953056, 3.789598470542094, 3.7723275727795755, 3.7551047489516, 3.737930015949754, 3.7208033919196724, 3.7037248962672162, 3.6866945496644905, 3.6697123740557216, 3.6527783926629693, 3.6358926299916803, 3.619055111836055, 3.6022658652842448, 3.5855249187233555, 3.5688323018442523, 3.5521880456461727, 3.535592182441097, 3.519044745857941, 3.502545770846478, 3.4860952936810463, 3.469693351964011, 3.453339984628953, 3.4370352319436153, 3.4207791355125536, 3.404571738279527, 3.388413084529575, 3.3723032198908074, 3.3562421913358778, 3.3402300471831277, 3.324266837097416, 3.3083526120905886, 3.292487424521611, 3.276671328096327, 3.2609043778668503, 3.2451866302305703, 3.2295181429287685, 3.2138989750448204, 3.1983291870019865, 3.1828088405607806, 3.1673379988158867, 3.15191672619264, 3.136545088443036, 3.1212231526412735, 3.1059509871788094, 3.090728661758919, 3.0755562473907476, 3.0604338163828455, 3.04536144233617, 3.0303392001365417, 3.0153671659465555, 3.000445417196912, 2.985574032577179, 2.970753092025965, 2.955982676720482, 2.9412628690655014, 2.92659375268168, 2.911975412393255, 2.897407934215079, 2.8828914053390067, 2.8684259141196033, 2.854011550059165, 2.839648403792057, 2.825336567068329, 2.8110761327366314, 2.7968671947263886, 2.7827098480292456, 2.7686041886797508, 2.754550313735299, 2.740548321255285, 2.7265983102794924, 2.7127003808056838, 2.6988546337663992, 2.6850611710049437, 2.671320095250557, 2.657631510092764, 2.6439955199548866, 2.630412230066719, 2.6168817464363565, 2.6034041758211606, 2.589979625697878, 2.5766082042318765, 2.563290020245522, 2.550025183185665, 2.536813803090257, 2.5236559905540683, 2.510551856693527, 2.4975015131106577, 2.484505071856124, 2.471562645391383, 2.4586743465499303, 2.445840288497654, 2.4330605846922864, 2.420335348841964, 2.4076646948628824, 2.395048736836067, 2.382487588963247, 2.3699813655218485, 2.357530180819098, 2.345134149145264, 2.33279338472601, 2.3205080016739017, 2.308278113939053, 2.2961038352589243, 2.283985279107289, 2.2719225586423777, 2.259915786654204, 2.2479650755110923, 2.2360705371054235, 2.224232282798601, 2.2124504233652686, 2.2007250689367854, 2.1890563289439764, 2.177444312059186, 2.1658891261376434, 2.1543908781581704, 2.1429496741632406, 2.13156561919843, 2.1202388172512667, 2.1089693711895166, 2.097757382698919, 2.0866029522204177, 2.0755061788868905, 2.0644671604594302, 2.0534859932631937, 2.04256277212285, 2.0316975902976693, 2.0208905394162744, 2.010141709411097, 1.99945118845257, 1.9888190628830935, 1.9782454171508104, 1.9677303337432315, 1.9572738931207443, 1.9468761736500535, 1.9365372515375852, 1.9262572007628984, 1.916036093012154, 1.9058739976116699, 1.8957709814616166, 1.8857271089698988, 1.875742441986255, 1.8658170397366347, 1.855950958757898, 1.8461442528328713, 1.836396972925824, 1.8267091671183984, 1.817080880546053, 1.8075121553350604, 1.79800303054011, 1.7885535420825645, 1.7791637226894226, 1.7698336018330287, 1.7605632056715916, 1.7513525569905481, 1.7422016751448317, 1.7331105760020846, 1.724079271886879, 1.715107771525977, 1.7061960799946894, 1.6973441986643807, 1.6885521251511637, 1.6798198532658388, 1.6711473729651125, 1.6625346703041561, 1.653981727390537, 1.6454885223395794, 1.6370550292311847, 1.6286812180681711, 1.6203670547361606, 1.6121125009650608, 1.6039175142921858, 1.5957820480270453, 1.5877060512178511, 1.5796894686197689, 1.5717322406649568, 1.5638343034344226, 1.555995588631732, 1.5482160235586004, 1.540495531092399, 1.5328340296656016, 1.5252314332472003, 1.5176876513261153, 1.5102025888966213, 1.502776146445813, 1.495408219943132, 1.4880987008319677, 1.4808474760233543, 1.4736544278917754, 1.4665194342730903, 1.4594423684645927, 1.4524230992272058, 1.4454614907898313, 1.438557402855845, 1.4317106906117514, 1.4249212047379916, 1.4181887914219056, 1.41151329237285, 1.4048945448394552, 1.3983323816290285, 1.391826631129081, 1.385377117330976, 1.3789836598556806, 1.3726460739816073, 1.3663641706745273, 1.3601377566195372, 1.3539666342550558, 1.3478506018088308, 1.341789453335927, 1.3357829787586721, 1.3298309639085304, 1.3239331905698708, 1.3180894365256044, 1.3122994756046467, 1.3065630777311819, 1.300880008975678, 1.2952500316076279, 1.2896729041499628, 1.2841483814351098, 1.2786762146626356, 1.2732561514584466, 1.267887935935489, 1.2625713087559065, 1.2573060071946065, 1.2520917652041874, 1.2469283134811715, 1.2418153795335007, 1.236752687749234, 1.2317399594664011, 1.226776913043956, 1.2218632639337712, 1.2169987247536291, 1.2121830053611442, 1.2074158129285653, 1.2026968520184032, 1.1980258246598214, 1.193402430425739, 1.1888263665105863, 1.1842973278086564, 1.1798150069929947, 1.1753790945947729, 1.1709892790830825, 1.166645246945106, 1.1623466827665903, 1.1580932693125816, 1.1538846876083602, 1.1497206170205176, 1.1456007353381266, 1.1415247188539446, 1.1374922424456009, 1.1335029796567133, 1.1295566027778803, 1.1256527829275007, 1.1217911901323676, 1.1179714934079878, 1.1141933608385777, 1.1104564596566895, 1.106760456322416, 1.1031050166021372, 1.0994898056467528, 1.0959144880693676, 1.092378728022379, 1.0888821892739324, 1.0854245352836984, 1.082005429277939, 1.0786245343238192, 1.0752815134029325, 1.0719760294840048, 1.068707745594738, 1.0654763248927726, 1.0622814307357227, 1.059122726750268, 1.0559998769002654, 1.0529125455538597, 1.049860397549562, 1.0468430982612764, 1.04386031366225, 1.0409117103879257, 1.0379969557976763, 1.0351157180354034, 1.0322676660889831, 1.02945246984854, 1.0266698001635384, 1.0239193288986763, 1.0212007289885676, 1.0185136744912056, 1.015857840640194, 1.0132329038957426, 1.0106385419944126, 1.0080744339976144, 1.0055402603388468, 1.0030357028696761, 1.000560444904452, 0.9981141712637606, 0.9956965683166127, 0.993307324021367, 0.9909461279653909, 0.9886126714034655, 0.9863066472949278, 0.9840277503395691, 0.9817756770122812, 0.9795501255964669, 0.9773507962162155, 0.9751773908672547, 0.973029613446688, 0.970907169781521, 0.9688097676559966, 0.9667371168377417, 0.96468892910274, 0.962664918259144, 0.9606648001699363, 0.9586882927744554, 0.9567351161088007, 0.9548049923251257, 0.9528976457098419, 0.9510128027007425, 0.949150191903064, 0.9473095441045003, 0.9454905922891892, 0.9436930716506811, 0.9419167196039158, 0.9401612757962144, 0.9384264821173164, 0.9367120827084641, 0.9350178239705675, 0.9333434545714574, 0.9316887254522496, 0.9300533898328364, 0.9284372032165262, 0.9268399233938474, 0.9252613104455365, 0.9237011267447284, 0.922159136958369, 0.920635108047867, 0.9191288092690038, 0.9176400121711217, 0.9161684905956085, 0.9147140206736947, 0.9132763808235858, 0.9118553517469453, 0.910450716424746, 0.9090622601125116, 0.9076897703349625, 0.9063330368800877, 0.9049918517926542, 0.9036660093671803, 0.9023553061403826, 0.9010595408831183, 0.8997785145918384, 0.8985120304795673, 0.8972598939664292, 0.896021912669734, 0.8947978963936403, 0.8935876571184125, 0.8923910089892861, 0.8912077683049573, 0.8900377535057128, 0.888880785161214, 0.887736685957951, 0.8866052806863796, 0.8854863962277587, 0.8843798615406977, 0.8832855076474302, 0.8822031676198292, 0.8811326765651729, 0.8800738716116759, 0.8790265918938005, 0.8779906785373572, 0.8769659746444092, 0.8759523252779884, 0.8749495774466425, 0.8739575800888157, 0.8729761840570796, 0.8720052421022226, 0.8710446088572114, 0.8700941408210281, 0.8691536963424031, 0.8682231356034433, 0.8673023206031717, 0.8663911151409852, 0.8654893848000391, 0.8645969969305696, 0.8637138206331583, 0.8628397267419525, 0.8619745878078439, 0.8611182780816165, 0.8602706734970718, 0.8594316516541358, 0.8586010918019571, 0.8577788748220011, 0.8569648832111503, 0.8561590010648119, 0.8553611140600432, 0.8545711094386992, 0.853788875990608]}],\n",
              "                        {\"height\": 500, \"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}, \"title\": {\"text\": \"Error Plot over Iterations\", \"x\": 0.5}, \"width\": 800, \"xaxis\": {\"title\": {\"text\": \"Iteration\"}}, \"yaxis\": {\"title\": {\"text\": \"Log Loss\"}}},\n",
              "                        {\"responsive\": true}\n",
              "                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('1f860384-a96a-4573-b0f6-5d7edfdefb63');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })\n",
              "                };\n",
              "                \n",
              "            </script>\n",
              "        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "import plotly.graph_objects as go\n",
        "import numpy as np\n",
        "\n",
        "y = clf_no_reg.loss_log \n",
        "\n",
        "# fig = go.Figure(data=go.Scatter(x= np.arange(start =1, stop = len(y)), \n",
        "#                                 y=y,\n",
        "#                                 mode = 'lines+markers'))\n",
        "\n",
        "\n",
        "# Create traces\n",
        "fig = go.Figure()\n",
        "fig.add_trace(go.Scatter(x=np.arange(start =1, stop = len(y)), y=clf_no_reg.loss_log ,\n",
        "                    mode='lines+markers',\n",
        "                    name='No Regularization'))\n",
        "\n",
        "fig.add_trace(go.Scatter(x=np.arange(start =1, stop = len(y)), y=clf_reg_10.loss_log ,\n",
        "                    mode='lines+markers',\n",
        "                    name='Regulrization W=10'))\n",
        "\n",
        "fig.add_trace(go.Scatter(x=np.arange(start =1, stop = len(y)), y=clf_reg_20.loss_log ,\n",
        "                    mode='lines+markers',\n",
        "                    name='Regulrization W=20'))\n",
        "\n",
        "fig.add_trace(go.Scatter(x=np.arange(start =1, stop = len(y)), y=clf_reg_40.loss_log ,\n",
        "                    mode='lines+markers',\n",
        "                    name='Regulrization W=40'))\n",
        "\n",
        "\n",
        "fig.update_layout(title = \"Error Plot over Iterations\", title_x = 0.5,\n",
        "                  xaxis_title = 'Iteration',\n",
        "                  yaxis_title = 'Log Loss',\n",
        "                  width = 800,\n",
        "                  height = 500)\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sj7r2frVDiM3"
      },
      "source": [
        "**Accuracy Calculation**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z0DOZ2VQD3iK",
        "outputId": "937fa827-7ea3-4392-987a-9f1663548d4e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy 86.8421052631579%\n",
            "Accuracy 82.45614035087719%\n",
            "Accuracy 92.98245614035088%\n",
            "Accuracy 79.82456140350878%\n"
          ]
        }
      ],
      "source": [
        "from sklearn import metrics\n",
        "print(f'Accuracy {metrics.accuracy_score(y_test, clf_no_reg.predict(X_test))*100}%')\n",
        "print(f'Accuracy {metrics.accuracy_score(y_test, clf_reg_10.predict(X_test))*100}%')\n",
        "print(f'Accuracy {metrics.accuracy_score(y_test, clf_reg_20.predict(X_test))*100}%')\n",
        "print(f'Accuracy {metrics.accuracy_score(y_test, clf_reg_40.predict(X_test))*100}%')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N8MK4yf1D8BS"
      },
      "source": [
        "**Plot Confusion Matrix**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        },
        "id": "COJpVSpjD5iy",
        "outputId": "5b1a5314-a62e-421d-a8ca-8af07f295b8c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[62  9]\n",
            " [ 6 37]]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fda97464550>"
            ]
          },
          "metadata": {},
          "execution_count": 15
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVoAAAD4CAYAAACt8i4nAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAARaElEQVR4nO3de5CddX3H8fc3u4mEa4hADAkI5VoQAYsoFRVJy6VowakiXqYZG92xVoeLDlC8MHgZsa1cymglk4ALckmIIFQ7Ik1BvBEIAoLGQAxGE0ICCgjhttnz7R97ittc9pwl+9vn5Mn7lXlm99x+5/tH5jPf+T6/59nITCRJ5YypugBJqjuDVpIKM2glqTCDVpIKM2glqbDu0l/Q9/hStzVoPbvudXzVJagDPfbU4tjUNYaTOWN3+rNN/r522NFKUmHFO1pJGlWN/qorWI9BK6le+tdWXcF6DFpJtZLZqLqE9TijlVQvjUb7RwsRMSEi5kXEryJiUUQcERETI+KWiHio+XPHVusYtJLqJRvtH61dDHwvM/cHDgYWAWcD8zNzH2B+8/GQDFpJ9dLob/8YQkTsALwFmA2QmS9m5pPAiUBv8229wEmtSjJoJdXLMDraiOiJiIWDjp5BK+0JPAZcHhH3RMSsiNgGmJSZK5vveRSY1KokT4ZJqpUcxq6DzJwJzNzIy93A64CPZ+aCiLiYdcYEmZkR0fICCTtaSfUycifDlgPLM3NB8/E8BoJ3VURMBmj+XN1qIYNWUr2M0MmwzHwU+F1E7Nd8ahrwS+AmYHrzuenAja1KcnQgqV5G9sqwjwNXRcQ4YCnwQQYa1LkRMQNYBpzcahGDVlK9jOAFC5l5L3DYBl6aNpx1DFpJ9eIluJJUWBtXfI02g1ZSrWR69y5JKqsDbypj0EqqF0cHklSYHa0kFdbfV3UF6zFoJdWLowNJKszRgSQVZkcrSYUZtJJUVnoyTJIKc0YrSYU5OpCkwuxoJakwO1pJKsyOVpIKW+uNvyWpLDtaSSrMGa0kFWZHK0mF2dFKUmF2tJJUmLsOJKmwzKorWI9BK6lenNFKUmEGrSQV5skwSSqsv7/qCtZj0EqqF0cHklTYCAZtRPwGeBroB9Zm5mERMRGYA+wB/AY4OTOfGGqdMSNWkSR1gmy0f7TnbZl5SGYe1nx8NjA/M/cB5jcfD8mglVQr2ci2j5fpRKC3+XsvcFKrDxi0kuql0Wj7iIieiFg46OhZZ7UEvh8Rdw96bVJmrmz+/igwqVVJzmgl1cswdh1k5kxg5hBvOTIzV0TELsAtEfGrdT6fEdGyNTZoJdXLCJ4My8wVzZ+rI+IG4HBgVURMzsyVETEZWN1qHUcHkuplGKODoUTENhGx3f/9DhwDPADcBExvvm06cGOrkuxoC/rj089w7vkXsWTpMojg8+eczn/f9mN+8OMFdI/tZrcpk/nCOWew/XbbVl2qKtLzkb/nA9PfTUTwzd7ruPQ/elt/SEMbuZvKTAJuiAgYyMqrM/N7EXEXMDciZgDLgJNbLWTQFnT+RV/nTW84jAu/+Gn6+vp47vkXOOL1h3LaRz5Id3cXF3xtNrOunMMZH51RdamqwP5/vg8fmP5ujj363bz4Yh9zrp/F92++lYeX/rbq0jZvIzQ6yMylwMEbeP73wLThrOXooJCnn1nD3fc9wN+941gAxo4dy/bbbcub3vAXdHd3AfDaA/dn1erHqyxTFdp3v7342d0/57nnnqe/v5+f/OguTnjHMVWXtflrZPvHKGnZ0UbE/gzsG5vSfGoFcFNmLipZ2OZuxSOPsuOEHfj0Fy9g8ZKlHLDfPpx92kfYevxWL73nhu9+n+OmvbXCKlWlRb98kHM+cxo77jiB559/nr865i3cd88DVZe1+evAex0M2dFGxFnAtUAAdzaPAK6JiI1eDTF4b9qsK64ZyXo3G2v7+1n04BLe884TmPeNrzJ+/FbMvnLuS69f2nsNXV1dvP2Yt1VYpar00INLueSiWVz37dnM+dYsHrj/V/T3d951+pubbDTaPkZLq452BnBgZvYNfjIiLgB+AZy/oQ8N3pvW9/jSzrvd+Sh41S47MWnnnXjtgfsDcMxRRzLrmwNB++3v3sLtP76TWf/+JZqDdm2hrrpyHlddOQ+AT332dB55ZFXFFdXAKI4E2tVqRtsAdt3A85Obr2kjdnrlRF61y848vGw5AHfcfS977bE7P7pjIZddfR2XfPlcxm+1VYtVVHc77TQRgClTJ3PCO47hW9f9Z8UV1cDI3+tgk7XqaE8D5kfEQ8Dvms/tDuwNfKxkYXVwzun/yFnn/Qt9a/vYbdfJfP6c0znlQ6fyYl8fHz7tU8DACbFzz/x4xZWqKpdfeQk7TpxAX99azvrkefzxqaerLmnz14EdbWSLPWcRMYaBqyEGnwy7KzPbmjhvqaMDDW3XvY6vugR1oMeeWrzJs7Q1nz2l7czZ5nPXjsrsruWug8xsAHeMQi2StOn8UzaSVFgHjg4MWkm1Mprbttpl0EqqFztaSSrMoJWkwjrwElyDVlKtbMLfAivGoJVULwatJBXmrgNJKsyOVpIKM2glqazswHv6GrSS6sWOVpLKcnuXJJVm0EpSYZ03ojVoJdVLru28pDVoJdVL5+WsQSupXjwZJkml2dFKUll2tJJUmh2tJJWVa6uuYH1jqi5AkkZSNto/2hERXRFxT0R8p/l4z4hYEBFLImJORIxrtYZBK6leGsM42nMqsGjQ4y8DF2bm3sATwIxWCxi0kmplJDvaiJgKnADMaj4O4GhgXvMtvcBJrdYxaCXVynCCNiJ6ImLhoKNnneUuAs7kT/3vK4EnM1+aBC8HprSqyZNhkmol+6P992bOBGZu6LWIeDuwOjPvjoijNqUmg1ZSrbR7kqsNbwL+NiL+BtgK2B64GJgQEd3NrnYqsKLVQo4OJNVKNqLtY8h1Mv85M6dm5h7AKcD/ZOb7gVuBdzXfNh24sVVNBq2kWhnp7V0bcBZwRkQsYWBmO7vVBxwdSKqVzPZntO2vmbcBtzV/XwocPpzPG7SSamUEZ7QjxqCVVCuNYew6GC0GraRaaXWSqwoGraRaMWglqbDsvNvRGrSS6sWOVpIKK7G9a1MZtJJqpd9dB5JUlh2tJBXmjFaSCnPXgSQVZkcrSYX1NzrvpoQGraRacXQgSYU13HUgSWW5vUuSCtsiRwfjd31z6a/QZmjxvq+pugTVlKMDSSrMXQeSVFgHTg4MWkn14uhAkgpz14EkFdaBfwTXoJVUL4kdrSQVtdbRgSSVZUcrSYU5o5WkwuxoJamwTuxoO+9aNUnaBP1E28dQImKriLgzIu6LiF9ExHnN5/eMiAURsSQi5kTEuFY1GbSSaqUR7R8tvAAcnZkHA4cAx0XEG4EvAxdm5t7AE8CMVgsZtJJqpUG0fQwlBzzTfDi2eSRwNDCv+XwvcFKrmgxaSbWSwzhaiYiuiLgXWA3cAvwaeDIz1zbfshyY0modg1ZSrTSGcURET0QsHHT0DF4rM/sz8xBgKnA4sP/LqcldB5JqpRHtb+/KzJnAzDbe92RE3AocAUyIiO5mVzsVWNHq83a0kmqlfxjHUCJi54iY0Px9PPDXwCLgVuBdzbdNB25sVZMdraRaaWM3QbsmA70R0cVAUzo3M78TEb8Ero2ILwD3ALNbLWTQSqqVVrsJ2pWZPwcO3cDzSxmY17bNoJVUK/4pG0kqbARHByPGoJVUK514rwODVlKt9NvRSlJZdrSSVJhBK0mFdeCfDDNoJdWLHa0kFdbq0toqGLSSasV9tJJUmKMDSSrMoJWkwrzXgSQV5oxWkgpz14EkFdbowOGBQSupVjwZJkmFdV4/a9BKqhk7WkkqbG10Xk9r0Eqqlc6LWYNWUs04OpCkwtzeJUmFdV7MGrSSasbRgSQV1t+BPa1BK6lW7GglqbC0o5Wksuxot2A77LA9My/9Nw48cD8ykw9/+BPcseDuqsvSKItxY9m19yvEuLFEVxfP3PJDnvjqleza+xXGbDMegK6JE3jh/sU8eup5FVe7eXJ71xbswgs+x80338p7Tulh7NixbL31+KpLUgXyxT4e+Yczyeeeh+4uplxxAc/+8C4emf6Jl94z6cLPsObWn1ZY5eZtpGI2InYDrgAmNZedmZkXR8REYA6wB/Ab4OTMfGKotcaMUE0awvbbb8ebj3wDl11+DQB9fX089dQfK65KVcnnngcguruJ7i7IP0VDbLM14w8/mDXzf1JVeZu9tWTbR8ul4BOZeQDwRuCfIuIA4GxgfmbuA8xvPh6SQTsK9txzdx5//PfMnnUhd915M5d+/V/taLdkY8Ywdd7X2OP2OTz703t44f7FL720zbS/5LkF95Jrnq2wwM1bDuPfkOtkrszMnzV/fxpYBEwBTgR6m2/rBU5qVdPLDtqI+OAQr/VExMKIWNhorHm5X1Eb3V1dHHroQVx66RW8/vBjWbPmWc4682NVl6WqNBosf9dHWTbt/Wx10H6M2/vVL7203fFH8cx/3VZdbTXQGMYxOKuaR8+G1oyIPYBDgQXApMxc2XzpUQZGC0PalI52o5P6zJyZmYdl5mFjxmyzCV9RD8tXrGT58pXcedc9AFx//Xc59JCDKq5KVWs8vYbn7ryP8Ue+HoAxE7bnFQftx7O3L6i4ss3bcDrawVnVPGauu15EbAt8CzgtM//fzC8zkzbGwkOeDIuIn2/sJdpIcQ1Yteoxli9/hH333YsHH/w1Rx99JIsWPVh1WarAmB13gLVraTy9hnjFOMYf8TqevGwuANse82ae/cEC8sW+iqvcvI3k9q6IGMtAyF6Vmdc3n14VEZMzc2VETAZWt1qn1a6DScCxwLpn1AJwWj8Mp57+Ga7ovYRx48by8MO/ZcaHzqi6JFWge+eJ7PLFT0LXGCLG8MzNt/PsDwY62G2PfytPzJpbcYWbv/4cmX0HERHAbGBRZl4w6KWbgOnA+c2fN7ZcK4coKiJmA5dn5o828NrVmfm+Vl/QPW5K521qU+UW7/uaqktQB9rrgZtjU9d436vf2XbmXL3sho1+X0QcCfwQuJ8/NcrnMDCnnQvsDixjYHvXH4b6niE72sycMcRrLUNWkkbbSF2C22wwNxbE04azlhcsSKoVL8GVpMK8BFeSCvPuXZJU2EjtOhhJBq2kWnF0IEmFeTJMkgpzRitJhTk6kKTChrratSoGraRa8c+NS1Jhjg4kqTBHB5JUmB2tJBXm9i5JKsxLcCWpMEcHklSYQStJhbnrQJIKs6OVpMLcdSBJhfVn590o0aCVVCvOaCWpMGe0klSYM1pJKqzh6ECSyrKjlaTC3HUgSYU5OpCkwhwdSFJhndjRjqm6AEkaSTmMf61ExGURsToiHhj03MSIuCUiHmr+3LHVOgatpFrpz/62jzZ8AzhunefOBuZn5j7A/ObjIRm0kmolM9s+2ljrduAP6zx9ItDb/L0XOKnVOgatpFppkG0fEdETEQsHHT1tfMWkzFzZ/P1RYFKrD3gyTFKtDOemMpk5E5i5Cd+VEdHyCw1aSbUyCrsOVkXE5MxcGRGTgdWtPuDoQFKtjOSug424CZje/H06cGOrD9jRSqqVkbwENyKuAY4CdoqI5cC5wPnA3IiYASwDTm61jkErqVZG8sbfmfnejbw0bTjrGLSSaqUTrwwzaCXVin/KRpIK80/ZSFJhdrSSVJg3/pakwjwZJkmFOTqQpML8CwuSVJgdrSQV1okz2ujE9K+riOhp3pZNeon/L+rPu3eNrnZuKqwtj/8vas6glaTCDFpJKsygHV3O4bQh/r+oOU+GSVJhdrSSVJhBK0mFGbSjJCKOi4jFEbEkIs6uuh5VLyIui4jVEfFA1bWoLIN2FEREF/BV4HjgAOC9EXFAtVWpA3wDOK7qIlSeQTs6DgeWZObSzHwRuBY4seKaVLHMvB34Q9V1qDyDdnRMAX436PHy5nOStgAGrSQVZtCOjhXAboMeT20+J2kLYNCOjruAfSJiz4gYB5wC3FRxTZJGiUE7CjJzLfAx4GZgETA3M39RbVWqWkRcA/wU2C8ilkfEjKprUhlegitJhdnRSlJhBq0kFWbQSlJhBq0kFWbQSlJhBq0kFWbQSlJh/wu/r/4257xRZQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix\n",
        "print(confusion_matrix(y_test, clf_no_reg.predict(X_test)))\n",
        "sns.heatmap(confusion_matrix(y_test, clf_no_reg.predict(X_test)), annot=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZOVXDsGugEa6"
      },
      "source": [
        "**Task**<br>\n",
        "Apply logistic regression on MNIST dataset. \n",
        "The MNIST database of handwritten digits, available from this [page](http://yann.lecun.com/exdb/mnist/), has a training set of 60,000 examples, and a test set of 10,000 examples. It is a subset of a larger set available from NIST. The digits have been size-normalized and centered in a fixed-size image.\n",
        "\n",
        "You can use [scikit-learn's `LogisticRegression` class](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html). The images in MNIST dataset are of shape (28 x 28) pixels. So, there are 784 pixels in total. You can consider each pixel as a feature. In summary, a sample from your training or test set will be of shape (1 x 784). "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6S81TGIugvMB"
      },
      "source": [
        "Loading data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6uGuohg3gzhl"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import fetch_openml\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.utils import check_random_state\n",
        "\n",
        "X, y = fetch_openml(\"mnist_784\", version=1, return_X_y=True, as_frame=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JTZ0cN7ri_mW"
      },
      "source": [
        "1. Plot one image from each class e.g., (0, 1, 2, 3, ...)\n",
        "\n",
        "Hint: You can create a function `view_image(img)` that will take a numpy array of shape (1, 784) as input and reshape it to (28,28) numpy array. Then it will plot this numpy array in grayscale using `matplotlib.pyplot`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 240
        },
        "id": "KvlZivdKi0rR",
        "outputId": "cac4d4f9-3f04-4b24-9e2f-602309878dce"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 10 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "# Your code goes here\n",
        "images = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
        "for i in range (0,len(X)):\n",
        "    images[int(y[i])] = X[i]\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "for i in range (0, len(images)):\n",
        "    plt.subplot(2, 5, i+1)\n",
        "    image = np.reshape(images[i], (28, 28))\n",
        "    plt. imshow(image, cmap='gray')\n",
        "    plt.title(f'Label: {i}')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8uNKn4kIjiH4"
      },
      "source": [
        "2. Print one sample and decide whether you need to normalize the images. If yes, then do so."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mpE4_lNZis5U",
        "outputId": "37aa73be-d0e1-489e-ae52-f015c794a3e8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
            "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
            "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
            "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
            "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
            "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
            "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
            "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
            "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
            "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
            "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   3.  18.\n",
            "  18.  18. 126. 136. 175.  26. 166. 255. 247. 127.   0.   0.   0.   0.\n",
            "   0.   0.   0.   0.   0.   0.   0.   0.  30.  36.  94. 154. 170. 253.\n",
            " 253. 253. 253. 253. 225. 172. 253. 242. 195.  64.   0.   0.   0.   0.\n",
            "   0.   0.   0.   0.   0.   0.   0.  49. 238. 253. 253. 253. 253. 253.\n",
            " 253. 253. 253. 251.  93.  82.  82.  56.  39.   0.   0.   0.   0.   0.\n",
            "   0.   0.   0.   0.   0.   0.   0.  18. 219. 253. 253. 253. 253. 253.\n",
            " 198. 182. 247. 241.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
            "   0.   0.   0.   0.   0.   0.   0.   0.  80. 156. 107. 253. 253. 205.\n",
            "  11.   0.  43. 154.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
            "   0.   0.   0.   0.   0.   0.   0.   0.   0.  14.   1. 154. 253.  90.\n",
            "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
            "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0. 139. 253. 190.\n",
            "   2.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
            "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  11. 190. 253.\n",
            "  70.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
            "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  35. 241.\n",
            " 225. 160. 108.   1.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
            "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  81.\n",
            " 240. 253. 253. 119.  25.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
            "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
            "  45. 186. 253. 253. 150.  27.   0.   0.   0.   0.   0.   0.   0.   0.\n",
            "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
            "   0.  16.  93. 252. 253. 187.   0.   0.   0.   0.   0.   0.   0.   0.\n",
            "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
            "   0.   0.   0. 249. 253. 249.  64.   0.   0.   0.   0.   0.   0.   0.\n",
            "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
            "  46. 130. 183. 253. 253. 207.   2.   0.   0.   0.   0.   0.   0.   0.\n",
            "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  39. 148.\n",
            " 229. 253. 253. 253. 250. 182.   0.   0.   0.   0.   0.   0.   0.   0.\n",
            "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  24. 114. 221. 253.\n",
            " 253. 253. 253. 201.  78.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
            "   0.   0.   0.   0.   0.   0.   0.   0.  23.  66. 213. 253. 253. 253.\n",
            " 253. 198.  81.   2.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
            "   0.   0.   0.   0.   0.   0.  18. 171. 219. 253. 253. 253. 253. 195.\n",
            "  80.   9.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
            "   0.   0.   0.   0.  55. 172. 226. 253. 253. 253. 253. 244. 133.  11.\n",
            "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
            "   0.   0.   0.   0. 136. 253. 253. 253. 212. 135. 132.  16.   0.   0.\n",
            "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
            "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
            "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
            "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
            "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
            "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
            "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.]\n",
            "-------------------\n",
            "[0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.01176471 0.07058824 0.07058824 0.07058824\n",
            " 0.49411765 0.53333333 0.68627451 0.10196078 0.65098039 1.\n",
            " 0.96862745 0.49803922 0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.11764706 0.14117647 0.36862745 0.60392157\n",
            " 0.66666667 0.99215686 0.99215686 0.99215686 0.99215686 0.99215686\n",
            " 0.88235294 0.6745098  0.99215686 0.94901961 0.76470588 0.25098039\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.19215686\n",
            " 0.93333333 0.99215686 0.99215686 0.99215686 0.99215686 0.99215686\n",
            " 0.99215686 0.99215686 0.99215686 0.98431373 0.36470588 0.32156863\n",
            " 0.32156863 0.21960784 0.15294118 0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.07058824 0.85882353 0.99215686\n",
            " 0.99215686 0.99215686 0.99215686 0.99215686 0.77647059 0.71372549\n",
            " 0.96862745 0.94509804 0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.31372549 0.61176471 0.41960784 0.99215686\n",
            " 0.99215686 0.80392157 0.04313725 0.         0.16862745 0.60392157\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.05490196 0.00392157 0.60392157 0.99215686 0.35294118\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.54509804 0.99215686 0.74509804 0.00784314 0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.04313725\n",
            " 0.74509804 0.99215686 0.2745098  0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.1372549  0.94509804\n",
            " 0.88235294 0.62745098 0.42352941 0.00392157 0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.31764706 0.94117647 0.99215686\n",
            " 0.99215686 0.46666667 0.09803922 0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.17647059 0.72941176 0.99215686 0.99215686\n",
            " 0.58823529 0.10588235 0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.0627451  0.36470588 0.98823529 0.99215686 0.73333333\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.97647059 0.99215686 0.97647059 0.25098039 0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.18039216 0.50980392 0.71764706 0.99215686\n",
            " 0.99215686 0.81176471 0.00784314 0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.15294118 0.58039216\n",
            " 0.89803922 0.99215686 0.99215686 0.99215686 0.98039216 0.71372549\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.09411765 0.44705882 0.86666667 0.99215686 0.99215686 0.99215686\n",
            " 0.99215686 0.78823529 0.30588235 0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.09019608 0.25882353 0.83529412 0.99215686\n",
            " 0.99215686 0.99215686 0.99215686 0.77647059 0.31764706 0.00784314\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.07058824 0.67058824\n",
            " 0.85882353 0.99215686 0.99215686 0.99215686 0.99215686 0.76470588\n",
            " 0.31372549 0.03529412 0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.21568627 0.6745098  0.88627451 0.99215686 0.99215686 0.99215686\n",
            " 0.99215686 0.95686275 0.52156863 0.04313725 0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.53333333 0.99215686\n",
            " 0.99215686 0.99215686 0.83137255 0.52941176 0.51764706 0.0627451\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.        ]\n"
          ]
        }
      ],
      "source": [
        "# Your code goes here\n",
        "print(X[0])\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "scalar = MinMaxScaler()\n",
        "X = scalar.fit_transform(X)\n",
        "print(\"-------------------\")\n",
        "print(X[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9nsWXqTijxN0"
      },
      "source": [
        "3. Split your dataset into training and test set. Use `random_state = 7`. 80% of your whole data should be in training set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qpZqWkcwi_EG"
      },
      "outputs": [],
      "source": [
        "# Your code goes here\n",
        "# for i in range (0, len(y)):\n",
        "#     y[i] = int(y[i])\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=7)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V9El0QKfn7gR"
      },
      "source": [
        "4. Train the model for maximum 100 iterations without any regularization. Evaluate your trained model on test set. \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3InmC1jXivpP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "87e1dc0f-c31f-424a-894e-d2e02d4d5d1b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy 92.67142857142858%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Your code goes here\n",
        "from sklearn import metrics\n",
        "MAX_ITER = 100\n",
        "clf_no_reg = LogisticRegression(max_iter = MAX_ITER, penalty='none', solver='lbfgs')\n",
        "clf_no_reg.fit(X_train, y_train)\n",
        "print(f'Accuracy {metrics.accuracy_score(y_test, clf_no_reg.predict(X_test))*100}%')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3TtvYOg4o87s"
      },
      "source": [
        "5.   Show the effect of different `penalty/regularization` ('l1', 'l2') method."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bi7vO_NcpDjE",
        "outputId": "ba7355a8-d248-4ac8-a3f3-279a086dc505"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning:\n",
            "\n",
            "The max_iter was reached which means the coef_ did not converge\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy 92.70714285714286%\n"
          ]
        }
      ],
      "source": [
        "# Your code goes here\n",
        "clf_l2_reg = LogisticRegression(max_iter = MAX_ITER, penalty='l2', solver='saga')\n",
        "clf_l2_reg.fit(X_train, y_train)\n",
        "print(f'Accuracy {metrics.accuracy_score(y_test, clf_l2_reg.predict(X_test))*100}%')\n",
        "\n",
        "clf_l1_reg = LogisticRegression(max_iter = MAX_ITER, penalty='l1', solver='saga')\n",
        "clf_l1_reg.fit(X_train, y_train)\n",
        "print(f'Accuracy {metrics.accuracy_score(y_test, clf_l2_reg.predict(X_test))*100}%')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cu-YCTvcpHWR"
      },
      "source": [
        "6. Show the effect of different `regularization strength` (1/C while using scikit-learn)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "xk9mlNAWpMpR"
      },
      "outputs": [],
      "source": [
        "# Your code goes here\n",
        "clf_l2_reg_10 = LogisticRegression(max_iter = MAX_ITER, penalty='l2', C=0.1)\n",
        "clf_l2_reg.fit(X_train, y_train)\n",
        "print(f'Accuracy {metrics.accuracy_score(y_test, clf_l2_reg.predict(X_test))*100}%')\n",
        "\n",
        "clf_l2_reg_100 = LogisticRegression(max_iter = MAX_ITER, penalty='l2', C=0.01)\n",
        "clf_l2_reg.fit(X_train, y_train)\n",
        "print(f'Accuracy {metrics.accuracy_score(y_test, clf_l2_reg.predict(X_test))*100}%')\n",
        "\n",
        "clf_l2_reg_1000 = LogisticRegression(max_iter = MAX_ITER, penalty='l2', C=0.001)\n",
        "clf_l2_reg.fit(X_train, y_train)\n",
        "print(f'Accuracy {metrics.accuracy_score(y_test, clf_l2_reg.predict(X_test))*100}%')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uo0lNE6QqArD"
      },
      "source": [
        "7. Plot `5` misclassified samples, their `actual label`, and `predicted label` using the output from your best performing model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "id": "Sen_rfJ7qIyW",
        "outputId": "c31aa39e-1517-4520-94bb-7d08def75b1f"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 5 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "# Your code goes here\n",
        "y_pred = clf_no_reg.predict(X_test)\n",
        "cnt = 0\n",
        "plt.xticks([])\n",
        "for i in range(0, len(y_test)):\n",
        "    if(y_test[i]!=y_pred[i]):\n",
        "        plt.subplot(1,5,cnt+1)\n",
        "        plt.imshow(np.reshape(X_test[i],(28, 28)), cmap='gray')\n",
        "        plt.title(f'{y_test[i]}, {y_pred[i]}', loc='left')\n",
        "        cnt = cnt+1\n",
        "    if(cnt==5):\n",
        "        break\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y6dcWt5dFeXB"
      },
      "source": [
        "\n",
        "8. Plot the confusion matrix of the test set of best performing setup. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 456
        },
        "id": "ivybcHSnFuOd",
        "outputId": "5e7bb319-053f-4d55-88c9-bf61f03219ee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1343    0    7    4    2    6    8    1    9    5]\n",
            " [   0 1526    7    6    0    5    0    6   11    2]\n",
            " [   9   18 1258   25   18    6   18   13   23    5]\n",
            " [   6    4   27 1336    3   38    1   10   20   13]\n",
            " [   6    6    8    2 1261    2    7    1    7   39]\n",
            " [  10    7    7   40   20 1064   29    8   46    8]\n",
            " [  14    5    4    1   11   18 1295    1    3    0]\n",
            " [   2    2   17    3   10    3    1 1406    3   44]\n",
            " [  10   33   18   36    4   43    9    4 1203   20]\n",
            " [  10    7    1   10   23    7    0   52    8 1282]]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fda96c02b50>"
            ]
          },
          "metadata": {},
          "execution_count": 22
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWcAAAD4CAYAAAAw/yevAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOydd3wU1fqHn7O7IcmG3gQSLqgUBaVIIIAUKdIkgEpRiiAWBBTLBdQrioCFSxHhp0iR3osSCIQiXQSSAAm9hWJIIIQaShrJnt8fuwkLKbtJdpZ173n4zIfNmZnzzpmZfffMmfe8XyGlRKFQKBSuhe5RH4BCoVAosqKcs0KhULggyjkrFAqFC6Kcs0KhULggyjkrFAqFC2LQ2kDStl+dEg5SpO1IZ5gBQDjNErhrLI0zz6GzcOa1ctd7MC01tsBNu3f1rN2H7FH6CZe9FVXPWaFQKFwQzXvOCoVC4VRM6Y/6CByCcs4KhcK9SE971EfgEJRzVigUboWUpkd9CA5BOWeFQuFemJRzVigUCtfDTXrODonWqF69+uzq1avHV69e/Uh267dFnqbbmDl0/2YuPb+bT0RUTIFtJtxNYsCPywn8ciYDflyOztISo1GPn683fhW88a3gjZdnzk1s2+YFjh7ZyYljuxg+bHCBjyknqlV7kn3hmzKXa1dPMOSDtzWzp9PpCA/byOpV8zSz4edXgc2bVnDo4DYORm7lg/ff0swWQLFiRVm6dAaHD+/g0KHtNAyop5mtD4e8Q2TkViIitrBgwc94enpqYmfmjIlcjDlIZMQWTeq35oP33yIiYguRkVs1vfcAok7tJeLAZvaFb2LvnhBNbWWLKd3+xYVxVCjdXKBdTisDnqrE8hH9WD6iH1+/0Y5RCzbaXXH4yWi+nJv1As/eEErAU5UIHvMOAU9VonixQgAkJaUTE5tEzMUkrlxJoUxpr2zr1el0TJn8LR0De/Ns7Rb06NGFp5+uavdx5YVTp87gX78N/vXb0CCgHYmJSQStXq+JLYAhH7zNiROnNasfIC0tjWHDR1GrdguebxLIwIH9NDt/AJN+GM2mjdt49tnm1Kv3Isc1al+FCuUYPLg/DRt2oG7dVuj1enp076yJrfnzl/NSx16a1G1NzZrV6f9WTxo3fol69V6kQ4fWPPlkZU1ttn6xG/7129CwUQdN7WSLNNm/uDAOcc4nT57cCVzPab3RqxBCmGO9k1LvIazCvuduCqPn9wvoNmYOU4N32W1z+6EoAhvVBCCwUU18jOYRGusMqCKX1jWoX5czZ85z7lw09+7dY/ny1XQKbGu3/fzSsmUTzp79m+joWE3q9/UtT4f2rZg9e4km9WcQFxdPRKT5QenOnbucOHEa3wrlNLFVtGgRmjQJYPYcc5vu3btHQsItTWwBGAwGvL290Ov1GL29uXgpThM7f+4K5fqNm5rUbc1TT1UlPCyCpKRk0tPT2fnnXrp0aa+53UeFTE+ze3FlbDpnIcRTQohPhRBTLMunQoin82poa8QpuoycxQc//c7Xb5g72buPnSM6/gaLPuvNsi/6cTz6MvtPX7Crvmu3EilTrDAApYv6oNff9/g+Rj0VfY2Uf8yb+KvJ2e5fwbccF2IuZv4dE3uJCho5F2t6dO/MsmVBmtX/w8RRfPb5N5ic+FKkUiU/6tR+htCwCE3qf/zxf3H16jVm/TqJ8LCNTJ82HqPRWxNbFy/GMWnSNM6eCeNCdAS3bt1i8+admthyFkePnuD5JgGULFkCb28v2rdrSUW/CprZk1KyPmQJoXvX8/Zb2j8ZZMFksn9xYXJ1zkKIT4GlmGeLhlkWASwRQnyWy37vCiH2CSH2zVprvrFb1q1G0Ki3mDSwC1PXmHvIe4+dZ8+x8/T4dh6vfTeP83HXiY6/AUDvsQvp/s1cRi/cyI5DZ+j+zVy6fzOX3UfPZWfvgb/vJqZzITaRuPgkSpYoZPfJ0BoPDw86dmzDyt/WalL/Sx1aEx9/lQMRhzWpPzt8fIwsXzaTT4aO5PbtO5rYMOj11K37LNOnz6d+g7bcvZvI8OHva2KrePFiBAa2pWq1hvyr0nMYfYz07PmKJracxYkTUUwY/zPrQxazbu0iDh48Snq6do6peYuXaRDQjo6BvRk4sB9NmwRoZitb3GRYw1a0xltATSnlPetCIcQPwFFgbHY7SSlnADMga26NelUrEnM1gRt3EpHAW+0C6NqsTpY6Fn7WGzCPOa/Zc4Qx/R4cuypV1MiVhDuUKVaYKwl3SE/POp0+OdmEh0GHTpf1R/JibNwDvQc/3/JcvKjN42sG7dq1ICLiMPHxVzWpv3FjfwI7tqF9u5Z4eXlStGgR5s2dQt9+QzSxZzAYWLFsJkuWrCIoSLsx9JjYS8TEXCIs3Nwz/+33dQwfpo1zbtWqKefPR3P1qnmULihoPY0a+rN48e+a2HMWc+YuZc7cpQCMGfMZsTGXNLOV8T26cuUaq1evp379Ovy5K1Qze1lw8Rd99mJrWMMEZPf8U96yzi6i42+QIYd1PPoyqffSKe7jTaMalQnafYTE5FQALt+4zfVbd+2qs3mtKgTvOQpA8J6j3E00jx8ZDPd70YUK6RAi+6eX8H2RVKnyOJUrV8TDw4Pu3TsTvHaTvU3KFz16dNF0SOOLEWOp/IQ/Vao1pFfvQWzb9pdmjhnM0QbHT0Tx4+QZmtkAuHz5CjExF6lW7UnAPG5//PgpTWxdiI6lQcBzeHubXyS3bNFE85erzqBMmVIAVKxYgS5d2rNk6SpN7BiN3hQu7JP5+cXWzTl69KQmtnLkf6Tn/BGwRQhxGsgYDP4XUAXI7LpUr159CfACULp69eoxwEjAAyBy2jC2RJwieO9RDHodXh4Gxr0TiBCCxjUe59yl67wxbhEARk8Pvu3/EiXxsXng/dsGMHzmGlb9dYgKpYpyM8Hs4Av7GChS2ICU5peDl+OzH3NOT0/nw49GELJuMXqdjrnzlnHsmDZfeDDfqK1bNWPQoE81s+FMnm9cnz69u3Lo8DH2hZt/1L78cizrN2zVxN5HH3/J/Hn/R6FCHpw9F83bb3+iiZ2w8Ah+/30dYWEbSUtL42DkUWb+ukgTWwsX/EzzZo0oXbok58/uY9ToCZm9W0ezfNlMSpYqQdq9NIYM+UKzF6qPPVaGlStmAWAw6Fm6NIiNm7ZrYitHXPxFn70IWwKvQggd0ADwtRTFAuFSSrueHVTK0IKhUob+c1ApQwuOI1KGphzaaPche9Zqm6s9IcRsoCMQL6V85qF1/wYmAGWklFeF+eXXZKADkAj0k1IesGzbFxhh2fUbKaXNSQg2ZwhK80T1vba2UygUClfAzn6jvcwFfgLmWxcKISoCbYBoq+L2QFXLEgD8AgQIIUpiHk3wx/xbt18IsUZKeSM3wyqfs0KhcC8cOOYspcxpDsckYDgPPlh0BuZLM3uB4kKI8kBb4A8p5XWLQ/6DXCbtZaCcs0KhcC/yEOdsHfZrWd61Vb0QojMQK6U8+NAqX+6/mwOIsZTlVJ4rKvGRQqFwL/IQhWEd9msPQggj8B/MQxqaopyzQqFwL9Lv2d4m/zwJPA4ctEx+8wMOCCEaYA6WqGi1rZ+lLBZzNJt1+XZbhtSwhkKhcC80nL4tpTwspSwrpawspayMeYjiOSllHLAGeEOYaQgkSCkvARuBNkKIEkKIEph73Tazv2nec3ZWiFvSxT+dYgfAWKGp02y5a8iUO4YIumN44D8SB04uEUJkzuEQQsQAI6WUs3LYPARzGF0U5lC6NwGklNeFEGOAcMt2o6WUOSaKy0ANaygUCvfCgQmNpJSv21hf2eqzBLJNDC+lnA3Mzott5ZwVCoV74eLZ5uxFOWeFQuFWSG1fCDoN5ZwVCoV74eIJjexFOWeFQuFeqGENhUKhcEHcpOfscnHOthSxy5T2pPK/jFT0zV6mKOzAIRq2eZVX+w7m1b6D+WV2wdM9pqam8u8vv6d99/68/s5HmTmjPQvp8LWofPtW8MZo1Ge7v7PVt52lVO0s9XJwrqKzM9ul5bWaOWMisTEHibBS93711Y5ERm4lJfkC9Z6r5TBbGThblT1b3ESmyqV6zhmK2O06vE5MzCX27gkheO0mjh+/n+z89p17JNy6x2Nlcparf672M0wdPyrP9mMvXeaLbycy96dxD5T/vnYTRYsUZv3y2YRs3s6esCPEX0kh9Z6J2ItJAOj1Aj9fb/6OTsxSb4b6dkYb/z6/X1P17Qyl6tdeexcPDw9N9PbsuVaOpvWL3bh2LddEXgXG2e3S8lrNm7+cqVPnMHvO5Myyo0dP0L37O0z9OVsRowKTocoeEXmEwoV9CAvdwOYtOzW9L7Kges6Oxx5F7ORkEyZT/qYwBG/cymtvf8irfQczatwU0tPtSy249c89dO7QGoA2LzTF2zsbpW9h38QKrdW3naVU/ajUy7XGme3S+lrtykbd+8SJKE6dOuMwGw/jTFX2HElLs39xYVzKOTtKEfvgkeO80ncQ7/37S6LO/g3AmfPRbNiygwXTJvLbvJ/R6XSs3bTNrvrir1yjXNnSgFndwWSS6CxnztNTh5+vN36+Rq5eTbFZl9bq285Sqna2ermzFJ2d2S5nqoo/CrRWZc8RN5GpyrdzFkK8mcu6zDR8JpN9moCOokb1J/njt3n8Pm8qPV8NZMjnowEI3RfJsRNRvPaWueccui+SGIsQ5ZDPR/Nq38EMHPolR0+czhyvXrXOtqZgSoqJmNgkYi8mUrx4IUQuc3i1Vt8G5ypVO5NHruisAe56rcA5quw5osacGQXMyW6FdRo+QyFfu8cgHKGIXdjnvv5gs8YN+Gbiz9y4mYCUkk7tW/PxwKy/KVO+/wrIecy5bJlSxMVfpVzZMqSlpaPTiSzX9d49iTRJPDx0pKZmf9G1Vt8G5ylVO1u93FmKzs5slzNVxZ2Js1TZc8TFe8T2kmvPWQhxKIflMPCYow/GEYrYV69dz1T6PnzsJCYpKV6sKA396/DH9l1cs4zBJdy6zcW4y3bV2aJJQ1aHbAZg0/Y/SUrKqvRtMAg8PHSkpeV8Y2itvg3OU6p2pnq5MxWdndkuZ6qKOxNnqbLnyP9Iz/kxzBIrD78iF8BuRx+MPYrYZct44u2lR68XVKpo5PqNVISAZavW0ePll9i0bRfLVq1Db9DjVagQ40d9hhCCJx+vxAfvvMG7H32BSZrwMBj44pNBVChn+zfmlY5t+XzMeNp370+xokW4fsOs9O3lpad4MY/MF4NXr6XkeL2dqb7tDKVqZ6qXO1PR2dmq7FpeqwVW6t7nzu5j9OgJXL9xkx8nfUOZMiVZvXo+Bw8e5aWOjhvDd7Yqe7a4Sc85V/VtIcQsYI6Uclc26xZLKXvaMpCXYY2C4K4pQ52JO6bxdCbumjL0n6a+nbR8tN2H7N39K5e9bLn2nKWUOUaQ2+OYFQqFwunk0uH8J+FSk1AUCoWiwLj4WLK9KOesUCjcC+WcFQqFwgVxkxeCyjkrFAr3ws60DK6O5s7ZWa9CjRWaotM5Zzb6rQXvOsUOQIm+OWlJOh7pxPfyJic9ejrrngDILfLJ0YjcpqI6mPR/2jDBP+14c8ClcmsUBGd+CRUKhQvjwEkoQojZQoh4IcQRq7LxQogTlgl5q4QQxa3WfS6EiBJCnBRCtLUqb2cpixJCfGZPM5RHUygU7oVjEx/NBdo9VPYH8IyUshZwCvgcQAhRA3gNqGnZZ6oQQi+E0AM/A+2BGsDrlm1zRTlnhULhVkiTtHuxWZeUO4HrD5VtklJm5BvdC/hZPncGlkopU6SU54AooIFliZJSnpVSpgJLLdvminLOCoXCvcjDsIZ1Bk3LktcXSv2BjOxOvsAFq3UxlrKcynNFRWsoFAr3Ig/RGtYZNPOKEOILIA0ouBZeNijnrFAo3AsnRGsIIfoBHYFW8n6YTixQ0WozP0sZuZTniBrWUCgU7oXGKUOFEO2A4UAnKaW1aOga4DUhhKcQ4nGgKhAGhANVhRCPCyEKYX5puMaWHZdzzh+8/xYREVuIjNzqcIXq6dMncCE6ggP7N2eW1apVg507VhMWuoHdf63D379O5rpSpQpR0c+bCuW9sq1v2/EYuv0cQvepIfSctoGIv+MLfIwJiSkMmLuVwB/XMGDu1kw5LG9vHeXLe1K+vCflynni6Wle4edXno0blxIRsYUDBzYzeHB/AEaM+JgzZ8IIDV1PaOh62rZtUeBjg7yfQ0ehpUq1M9s0Y/oEYi5EEnHgvq2vRw5l/74/CA/byLp1iyhfvuCp0s33xTIiI7YQcWAz71vui5Ejh7IvfBNhoRtYt9Yxth7GmUrp2SKl/YsNhBBLgD1AdSFEjBDiLeAnoAjwhxAiUggxzWxWHgWWA8eADcBgKWW65eXh+8BG4Diw3LJt7ra1Dpz3yEPK0Jo1q7Nw4VQaN36J1NR7rFu7iMHvf8aZM+dt7mtPnHOTJgHcuXOX2bN+5Ll6ZsHWdWsXMWXKTDZu2k67ti345N8DadOmO2DWB5RSUrqUJxcvJWfWc3Oe+UcjMeUe3oUMCCE4FXeD4cv/ImhIR7vaGn7uMmsizjLmlUYPlE/aGEEx70L0b1aT2TuPMua3fdy8mWYWkLWcSQ8PQZkyhbh4MYVy5cpSrlxZIi1qx3v2rKNbt3fo2rUjd+7c5ccf7R9Os2cSSl7PYU7kdRLK7Fk/smtXKLPnLMlUqbZHDFWL+yIn7PkuZdiaM/tH6j5ntlWkSOFMKafBg/vz9NNVef/9z3Otx9YklIfvi717Quja7W1iYy/dtzXoTbOtD/6Ta115nYQSdWovAY3a50sp3REpQxN/eMdun2P8ZKbLpgx1qZ7zU09VJTwsgqSkZNLT09n55166dGnvsPp37QrlxkNqxFJKihQtAkDRYkW5dOm+OkpKiglTLu8WjJ4emV+SpNS0B2ZDzt11jJ7TNtDt5xCmbj1k9zFuPxFDYN0nAAis+wRGo95ynPe3sf5ixsXFE/mA2nEUvr7aCa3m9Rw6AmeoVDurTdnZstbY8zF6O2SmYU73hbUto4/RXbJrPohJ2r+4MDZfCAohnsIc9hEqpbxjVd5OSrnBkQdz9OgJRo/+lJIlS5CUlET7di3Zv/+gI01kYejQrwleu5CxY0egEzpeaNElT/tvPXaBKZsPcv1uMv/XqzkAu6MuEX3tNosGtEVK+HDxDvafj6de5bI267t2N5kyRcwKzKULe6HX33fE3t46SpTwQKcTxMenZtm3UiU/6tSpSVhYBI0a+TNwYF969XqVAwcO8emn33DzZkKe2mYvBT2HtrBWqa5VqwYHDhzi40++IjExyaF2rNG6TQ8zetRwevXqyq1bt3jRRg89r1Sq5Edty30BMGrUcHr1epVbCbdp09axtuC+UrqUkpkzF/LrLE2CGXLGTXJr2NIQHAKsBj4AjgghrAOnv8tlv3ypb584EcWE8T+zPmQx69Yu4uDBo6Sna/vm9d13+zBs2CiqVAlg2PBRTJ82Pk/7t6xRkaAhHZn0erPMHvLeqEvsORNHj1/W89q09Zy/eovoa7cB6D19I92nhjB6dSg7TsbSfap5zHr36YtZ6hZCPNCzSUoycfFiCleupFK8+IO/qz4+RpYsmc7QoaO4ffsOM2Ys4Omnm9KgQTvi4uL5739H5PHM2E9Bz6EtHoVKtdZtepivRo7jySoNWLJkFYOyESHOLz4+RpYumc7QoV9n9ppHjhxHlSoBLFm6ioED+znMVgaPWildmkx2L66MrWGNd4B6UsouwAvAl0KIDy3rchyrkVLOkFL6Syn9dTqfnDbLljlzlxLQsD0tW73KjZsJnD59Nk/755XevbtmKgT/9tvafL/4qVe5LDE37nDjbjISeKtpDZYP6sDyQR0I/qgTL9czi3guHNCW5YM68FXnAJpX983cpnFVs+JzKR8vrtw29wiv3E7ClM2jV0qKCYNBZL4sNBgMLF06naVLV7F6tflhJj7+KiaTCSkls2cv0eQlXQaOOoc5kZ1Kdd06zzrUxsNo3aacWLJ0FS+/7JihPIPBwLKlM1i6NCjzvrBm6dJVvNylg0NsWZOdUrpTcZNhDVvOWZcxlCGlPI/ZQbcXQvyARgnnypQpBUDFihXo0qU9S5au0sJMJpcuXaZZs4YAtGjxPFFR5+zeN/ra7czxweMXr5OaZqK40ZNGVcoTdOAsiSn3ALh8K5Hrd5JzqyqT5k/5ERxh/kEKjjhLYqL5Ec1a6btQIYEQIjMSaPr08Zw4EcWUKb9mblOu3P0hlE6d2mqmVg0FO4f28ChUqrVukzVVqjye+TkwsC0nT55xSL3m++I0k6fMvG/rycr3bXVsw8mTUQ6xlYEzldJzxLG5NR4ZtsacLwsh6kgpIwGklHeEEB2B2YAmXZfly2ZSslQJ0u6lMWTIFw598TN//k80a9qQ0qVLciYqjDHfTGTgoE+ZOOFrDAYDyckpDBp8P2FU6dKF8PLUo9eDn68XNxPuIRCsCD9Nt/pV2XLsAsGR5zDoBV4GPeO6P48QgsZVynPuSgJvzDSrDxsLGfi2a2NKkn1InjX9m9Zg+LJdrDpwhgrFfbh1yzyF32jU4+Nz/+Xg1avmMefGjevTq9erHD58nNBQc0/vq6/G0aNHZ2rVqoGUkr//jrH59l+rc+gotFSpdmabFsz/iWYWReyzZ8IZPWYi7du1pFq1JzCZJNHRMQx2wLVq3Lg+vXt15fDh44SFmnvNX331X/r1e41q1Z7EZDIRHR1jM1IjrzhTKT1HXLxHbC+21Lf9gDQpZVw2656XUv5ly0BeQukKgjNThmaE0jkDlc+5YKh8zgXHmfmcHRFKd/er1+y+ED6jl7psKJ0t9e2YXNbZdMwKhULhdFx8uMJeVG4NhULhXrjJsIZyzgqFwq1w9RA5e1HOWaFQuBeq56xQKBQuiHLOroUz3yg7M4LixjrtZvY9TJH2o5xmy9Pg4RQ7KWn3nGIHnKc0D86N1tA50ZZDcJPp227jnBUKhQKwSxvwn4ByzgqFwr1QzlmhUChcEBWtoVAoFC6I6jkrFAqFC6Kcs0KhULgeUuMc8M7CpWSqQFshz+zQ6XSEh21k9ap5Dq03J+HVBQt+zhRdPXnyr8xMcqVKeeDn50X58p7Z1rftYBTdvplH9+/m03PsQiKickx7YjcJd5MYMGUFgSNnMWDKisz80EajHj9fb/wqeONbwRsvz6y3iaenJ3v+Wsv+fX9wMHIrI7/6d4GP5+H6d+wMYu/e9YTv28QXIz4G4IUXGvPX7rXs2RvCH5tX8MQTlRxqd+aMiVyMOUhkxBaH1mtdf2zMQSKs6i9RojjrQ5Zw7Ogu1ocsoXjxYgW2k5PAa4kSxQlZt4ijR3YSsm6RQ2w5S7TWbhyYz1kIMVsIES+EOGJVVlII8YcQ4rTl/xKWciGEmCKEiBJCHBJCPGe1T1/L9qeFEH3taYZLCbxC/oU889uKjz58l3r1alG0SBE6v2zXOcOg09vcJifh1RMnTmduM3bsCG7dus13303OFJMtVaoQly6lZG6TEeecmJyKt0Wz8FTMFYbPCiZoZH+7jjf81AXW7D3KmDfaPVA+6fcdFPPxon/bAGZvDGXUvK1cv5H6gJhsIQ8dj5X14kJsYpZ6fXyM3L2biMFgYOf2VXz8yUhCww7YdUz2xDlb1795y0qGDR3FzF8n0qP7O5w8eYZ33u2Nf706DBgwNMc68hrn3DRDgHXOZOrUbZWnfe2JBm7SJIC7d+4ye85k6lrq//77L7h+/Sbjx//MsGGDKVGiGP/5T45CQ4DtbHs5Cby+0acb12/cZMKEqQwdOogSxYvxxYjvc63Llo9wlGgtQGpKTIGDqhPebG23Oyg2Z3Ou9oQQzYA7wHwp5TOWsnHAdSnlWCHEZ0AJKeWnQogOmFWjOgABwGQpZYAQoiSwD/DH7Kr2YxYxyVUB16V6zloLeT6Mr295OrRvxezZSxxetz3Cq127dmTZstWAWd0kt9h5o1chKzFZc17pDOb+EU7PsQvp9s08pq61P1ng9kNnCGxYE4DAhjXxMZpHuR4Qk83lDrl71+ywPTwMGDw8HJ4y07p+Dw8DEvmA8GqxokW5FOdYMdk/d4Vy/SEBVkeyK5v6AwPbsmDBCgAWLFhBp07tsts1T+R0/wUGtmHhwpUALFy4kk6d2hbYlrNEa+3GgT1nKeVO4PpDxZ2BjEfteUAXq/L50sxeoLgQojzQFvhDSnnd4pD/AGxeZHsEXhuYj1GGCyFqWCo9IaUMsdmyPOJsIc8fJo7is8+/oUiRwprUn4G18GoGTZo04PLlq5w5c97uerZGnmbK6j+5fjuJ/xv0MgC7j50nOv4Giz7tZRaTnRbE/tMx1KvqZ7O+a7cTKVPM3PbSRX0eEJP1MeopWcITvV5w6XL251+n0xEWuoEqT1bml2lzM2WkHIVOp+Ov3Wt54olKzJi+gH3hkQwe9Bm//z6H5ORkbt26Q4sXXnaozUfBY2VLExcXD5id6mNlSzu0fmuB17IP2SrrYFvWaClamyt5GHIWQrwLvGtVNENKOcPGbo9JKS9ZPscBGWM2vsAFq+1iLGU5leeKLYHXkcAU4BchxPfAT4AP8JkQ4otc9suXwKszhTxf6tCa+PirHIg4rEn9GTwsvJpB9+6dWb58dZ7qalmnKkEj+zNpQGemBpt7yHuPn2fP8b/p8f0CXhu7gPOXrxMdb35a6j1uEd2/m8/oRZvYcegM3b+bT/fv5rP72PksdT88HfhuYjoXYhOJi0+iZIlC2R6PyWTCv34bKj3uT33/utSsWT1P7bGFyWSiUcMOVKvaiHr+talRoxrvf/AWr7zyJtWqNmLhghWM1VC49lHhyF5mdgKvWtl6GK1Ea20h00z2L1Z6p5bFlmN+0Jb5BGpyEm31nLsCdQBPzL8QflLKW0KICUAo8G12O1kaOAPyNuacnZDn8GHaOOfGjf0J7NiG9u1a4uXlSdGiRZg3dwp9+w1xmI3shFcB9Ho9nTu3o3Hjl/JVb72qfsRcTeDGnUSzmGzbBnRtWjvLdguH9wJyHnMuVcTIlYQ7lClWmCsJd0hPz3qpkpNNeBh06HQ5x/YnJNxi+46/aNvmBU304hISbrFz5x7atHmBZ7mQ8S4AACAASURBVJ99mn3hkQCsXLmWoNWOfZH7KLgcf5Vy5coSFxdPuXJlib9yzSH1ZifwGv+QrSsOspUbS5auYs3q+YweM1FzW0Cees755LIQoryU8pJl2CLeUh4LVLTazs9SFotZf9W6fLstI7bGnNOklOlSykTgjJTyFoCUMgkNToEzhTy/GDGWyk/4U6VaQ3r1HsS2bX851DFD9sKrYG7XqVNniI3Nov6VI9HxN+6LyUZfJjUtneI+3jR6ujJBe46QmGzWFLx88zbXb2d9eZcdzWs9SfDeowAE7z3K3USzXuGDYrI6hMjqmEuXLkmxYkUB8PLyonWrZg4TJs1avyctWzbhxMkoihYtkimI2rJVE4cLlD4K1gZvok+fbgD06dON4OCNDqk3O4HXtWv/oHfvroBZYTw4eJNDbD2MVqK19iBN0u4ln6wBMqIH+gKrrcrfsERtNAQSLMMfG4E2QogSlsiONpayXLHVc04VQhgtzjkzpk0IUQyNfp+0FPJ0JjkJr27cuI3u3TuxbNmaB7YvXdoDT4uYrK+vFwkJ5iiDFTsP0q1ZbbZEniY49BgGvQ4vDwPj3nrJLCZbozLn4q7zxgTzS02jpwff9utAySJGm8fYv00Dhs9ay6rdR6hQsig3E8wOvrCPgSKFDUhpfjl4OT6rcnj58o8xe9aP6PU6dDodK1cGsy5kc5bt8ku5cmWZMXMiep25/t9+X8eG9Vt5//3PWbz4F0wmyY2bCQx8b5jDbAIsXPAzzS0CrOfP7mPU6AnMmbvUYfUvsKr/3Nl9jB49gXHjf2bJ4mm82e91oqNjeL3newW2k5PA6/gJP7N40S+82e81oqNj6NlrUIFtOUu01m4c6JmEEEsw93pLCyFigJHAWGC5EOIt4G8gY0A9BHOkRhSQCLwJIKW8LoQYA4RbthstpXz4JWNW2zYEXj2llCnZlJcGykspbQ7YOkvg1ZlzguwJpXMUKmVowXDXlKHuKlzriFC66y83t/uAS67a4bL5UG0JvGZxzJbyq8BVTY5IoVAoCoJ7TBBU07cVCoV7IdMe9RE4BuWcFQqFWyFVz1mhUChcEOWcFQqFwvVQPWeFQqFwQZRzdjGcGQ+TbnKeuq8zw9tuL3jX9kYOokifPM2SzTfOvC+cGc5pcqIUUyEnhT06CpnustFxecJtnLNCoVCA6jkrFAqFSyJNquesUCgULofqOSsUCoULIqXqOSsUCoXLoXrOCoVC4YKY3CRaw6U0BMG56tvOtPXhkHeIjNxKRMQWFiz4GU/P7FW2C4qfXwU2b1rBoYPbOBi5lQ/ef+uB9WVKe1L5X0Yq+npnu/+24zF0+zmE7lND6DltAxF/x2e7XV5ISExhwNytBP64hgFzt3IryZya1B6Vb3va5EiqVXuSfeGbMpdrV08w5IO3NbGltdJ3Blq3KSel9ObNG/HX7rWEh29kxoyJ6PXOyeYoTcLuxZVxG/Xt/OAsWxUqlGP7tlXUqt2C5ORkFi+exob1W5m/YLnNffN6dcqVK0v5cmWJsKguh4Vu4NWu/Tl+3Kz67eWlw2SCx8p4ciH2QW3A2wveJTHlHt6FDGaV77gbDF/+F0FDOtplO/zcZdZEnGXMK40eKJ+0MYJi3oXo36wms3ce5VZyKl8uCLdb5dtWm3KjIF8/nU7H3+f383yTjkRHx9rcPq/XSmul7+zIa5vAvjjnh5XSPx0+mvkLfuKlDr2IijrHiC8/Jjo6lvnzcr/n7yaeL7DHPF/nRbsvReXIP1zWQ7tUz9mZ6tvOVvo2GAx4e3uh1+sxentz8ZL9Kih5IS4unogHVJdP41vhvup3crIJUy4KEEZPDyuV77QHnMDcXcfoOW0D3X4OYerWQ3Yf0/YTMQTWfQKAwLpPsO14DGC/yretNmlFy5ZNOHv2b7udWF7RWuk7O7Rq08NK6ekmE6mp94iKOgfA1i276NKlvUNt5kSGSIQ9iyuTZ+cshJivxYHAg+rb4WEbmT5tPEZj9o/f/yRbFy/GMWnSNM6eCeNCdAS3bt1i8+admtiyplIlP+rUfobQsLypYm89doEuU9bywaIdfN0lAIDdUZeIvnabRQPasmxge45fvM7+8/YNeVy7m0yZIuZzW7qwF9fu3ldW8THqqehrpPxj3sRfzaq44qg25Yce3TuzbFmQ5naciVZt0ul07Nkbwvm/97N1yy72hUdiMOip+9yzALz8cgf8fMs73G52uMuwhi317TUPLcHAKxl/57Kfy6tvO9NW8eLFCAxsS9VqDflXpecw+hjp2fMVTWxl4ONjZPmymXwydGS2qsu50bJGRYKGdGTS680ye8h7oy6x50wcPX5Zz2vT1nP+6i2ir90GoPf0jXSfGsLo1aHsOBlL96nmMevdpy9mqVsI8UBv3B6Vb0e0Ka94eHjQsWMbVv62VlM7zkTLNmWnlN73jSH8979fsmNnELfv3CHdSVPOpRR2L66MrWgNP+AY8CvmITUB+AO5yuj+E9S3nWmrVaumnD8fzdWrZtmwoKD1NGroz+LFv2tiz2AwsGLZTJYsWUVQ0Pp811Ovcllibtzhxt1ks8p30xp0rV81y3YLB7QFch5zLuXjxZXbSZQp4s2V20mU9PHKUoctlW9Htcle2rVrQUTEYeLj3UfwxxltylBKf/HF5kyePJM2L5rl9Vq1avqA6KuWpP+PRGv4A/uBLzAryW4HkqSUO6SUOxx9MM5U33amrQvRsTQIeA5vb7NTatmiCSdO2H6ZlV9mzpjI8RNR/Dg578mFoq/dvq/yffE6qWkmihs9aVSlPEEHzpKYYtbku3wrket3bA9DADR/yo/giLMABEec5YWn/AD7VL4d0ab80KNHF/cb0tCoTdkppZ88dYYyZUoBUKhQIT755D1m/brI4bazw116znZFawgh/IBJwGWgk5TyX/YayGu0Ru3aNZk+bfwD6ts3bybkpQqXtPXVV/+mW7dOpKWlcTDyKO8OGEpqaqrN/fL6zuL5xvXZsT2IQ4ePZb74+/LLsazfsBWAsmU88fbSo9cL0tMl12+kYnn/R+zU/sz58xjBkecw6AVeBj0ft61L3UplAVi05wSr9psl7o2FDHzbtTEVSxbJtJ1Tz/lmYgrDl+3iUsJdKhT3YVz3JvgNmEfxYh4PqHxfu55CckpW72yrTbmRn6+f0ejN2TPhVKveiFu3btu9X16vlbXS9+XLV/Ok9J3XduW3TWA7WuOZZ57KopQ+9vspfPvt57Rr3wqdTvDrzEX8/PNsm7YcEa1xoloHuy/FU6dCcrUnhPgYeBvz5T2MWVG7PLAUKIW589pHSpkqhPAE5gP1gGtADynl+fy0AfIYSieEeAl4Xkr5H3v3cZb6trvizJOnUoYWDGdeK2e2y5kpQx3hnI9Xtd85P306Z+cshPAFdgE1pJRJQojlQAjQAfhdSrlUCDENOCil/EUIMQioJaV8TwjxGvCylLJHftuRp2gNKeW6vDhmhUKhcDYOjtYwAN5CCANgBC4BLYGVlvXzgC6Wz50tf2NZ30pkxKXmA5eKc1YoFIqCkm7S2b1YR5ZZlszHRyllLDABiMbslBMwD2PclDJT4zsG8LV89gUuWPZNs2xfKr/tULk1FAqFW5GXySXWkWUPI4Qogbk3/DhwE1gBtCv4EdqHcs4KhcKtMDkuCqM1cE5KeQVACPE78DxQXAhhsPSO/YCM6ZaxQEUgxjIMUgzzi8F8oYY1FAqFW+HAULpooKEQwmgZO26Fed7HNqCrZZu+wGrL5zWWv7Gs3yoLkLxI9ZwVCoVb4aicGVLKUCHESuAAkAZEYB4CWQcsFUJ8YymbZdllFrBACBEFXAdeK4h9l8tKp3gQZ4YxpTlRVfzqe3WcYqfMtINOsQPOVWX3NOQ+1d2RpKTZjsd3FPdSYws8JrHPr4vdPsc/JshlZ6KonrNCoXAr0k3uMVqrnLNCoXAr3OVRXTlnhULhVjgwWuORopyzQqFwK1w9oZG9KOesUCjcCjcR31bOWaFQuBfSqWmhtOORv9acOWMisTEHibBSIC5RojjrQ5Zw7Ogu1ocsoXjxYg6360yVZWfY0ul07N6zjpW/mUMuK1XyY/uOIA4d3s68+T/h4VHwkDw/v/Js3LiMyIgtRBzYzPuD+wPm6xWybhFHj+wkZN2izOs1ffoELkRHcGD/5uyPuawfxo/GU3jC73i0eLnAxweA3oBX3+H4fDEd48cTqFTJnDva3782oaHrCQ1dT1jYBjp1avtQu5YSEbGFAwc2M9jSrmeffZrt21exb98mfvttNkWKFHbMMVqhtSq7Tqfjrz1rWfHbr5llI78eSsTBrew/8AcDB/ZzqD1wntJ8TqRJYffiyjxy5zxv/nI6duz1QNnw4YPZum0XNWo2Yeu2XQwfPtjhdk+dOoN//Tb4129Dg4B2JCYmEbRaG4UNZ9gaPPhNTp6Iyvx7zDef8dP/zaLWsy9w82YCffvlO3NhJmlp6Xz66Rjq1G1F02adee+9vjz1VFWGDR3E1m1/UfOZZmzd9hfDhg4CYMGCFQR26pNjfTLxNsm/zSB166o8H4soWRbv97/LUu7RsA0y8Q53vx1A6vbVfPPN5wAcPXqSxo07EhDQnk6d3uCnn75Hr9dbtesb6tZtRbNmnXnvvTd46qmq/PLLOL78ciz+/m1Ys2YDn3wyIM/HmRsVKpRj8OD+NGzYgbp1W6HX6+nRvbNDbQx66L7o3acrvr7lea5OK+o99yIrVwY71J4z2mQLibB7cWUeuXPelY0CcWBgWxYsWAGYv+CdOmmba0RrlWWtbVXwLUe7di2Za5WovXnzxqxaFQLAooW/EdixTYHtxMXFE/mACnYUvr7lCAxsw8KF5gyKCxeuzOyV7toVyo1c1KXlnQRMF06DKS3LOkO9FzB+PBHjsMl4dh+cuzy39X7PBnAv3PwUlnbwL1q0eB6ApKRk0tPNk0S8vDyxnnyVU7uqVn2cP/8MBWDLlj/p0qWDXceQF7RUZTffFy2YN3dZZtnb7/Rm7PdTMtt/5Uq+Uz/kiLOU5nPClIfFlcmTcxZCNBFCfCKEKPg3PRceK1uauDizsnNcXDyPlS2tpTmnqixrYWvcuK/4YsT3mSohpUqVICHhVqYzio29RIUKjznUZqVKftSuU5OwsAjKPnS9yhbweuke88OjblMSJw8ncfyHYDJh8G9u176iWCnkDYtGnsnErVu3KVWqBAD169fhwIHN7Nu3iQ8++E/m+Xm4XXUs7Tp27BSBgeZb/ZVXXsLPz7Hq0Vqrso8b9xUjRozFZKX99fjj/+LVrh3ZuWs1vwfN4cknKzvMHjw6pXlr/id6zkKIMKvP7wA/AUWAkUKIz3LZL1/q2zmh5RRzZ6osa2GrXfuWXLlyjciIIw6r0xY+PkaWLpnO0KFfZ6uCXdDrpa9aG13FJzH++weMwyZjqFYLXalyAHj1/w/GYZPxfnck+opVMA6bbN6mQSub9YaHR/Lcc615/vlAhg0bnGUs1MfHyJIl0xk6dBS3b99hwIBhDBjwBrt3r6NIkcKkpt4rULseRktVdvN9cTXLfeHpWYjk5BSaNenM3DlL+WXaOIfYy+BRKM0/jLv0nG1Fa1i/RXoXeFFKeUUIMQHYC4zNbqf8qm9ncDn+KuXKlSUuLp5y5coSr8GjVwbOVFnWwlajhv689FJr2rZtgZeXJ0WKFGb8+JEUK1YUvV5Peno6vr7luXjxskPsGQwGli2dwdKlQaxevQGA+IeuV4EflYXgXvhWUtfOz7IqebZ5nFmULItXz49I+ulBYR6ZcA1RojQy4RrodBQtWoRr1248sM3Jk1HcvXuXmjWrc+DAocx2LV06naVLV2W269SpM3Ts2BuAKlUep127lgVr10NoqcresGE9OrzUmjZW98WvsyZxMTaONZb2rVm90eHO2dlK89mR7uI9YnuxNayhE0KUEEKUwpwk6QqAlPIu5ixNmrA2eBN9+nQDoE+fbgQHb9TKlFNVlrWwNXLkOKpVbUSNp5vQ940P2LFjN/37f8TOnXt4+WXzGGmv3q+ydt0mh9ibPn08J06cZvKUmZlla9f+Qe/e5gyKvXt3JTi4YLbSTx3Eo/bziMKWKB1jYUSJMnbtm3YkFI/65l60ofbzbN++G4DKlStmvgD81798qVatCn//feGhdkUxZcr9qIYM9WghBJ9/PoRff11YoHY9jJaq7F+PHE/1qo2p+XRT+lnui7ff+pjg4E00a24W4G3aNICoqHMOsZeBs5Xms8Mk7F9cGVs952KYZVkEIIUQ5aWUl4QQhXGQxuQCKwXic2f3MXr0BMaN/5kli6fxZr/XiY6O4fWe7znCVBaMRm9at2rGoEGfalL/o7IF8OWIscyb/398NfLfHDx4lHlzlxe4zsaN69O7V1cOHz5OWKi59/XVV/9l/ISfWbzoF97s9xrR0TH07GWO1pg//yeaNW1I6dIlORMVxphvJuKRmWXvCKJIcYz/noTwMoI0Uah5J+5+PwjT5QukhCzAe+BoEALS00leOQ1544rNY7y39w+8en+CzxfTkYl3+LJd/8xjHzp0EPfu3cNkMvHhh19k9qgbN65Pr16vcvjwcUJD11vaNY4qVR7nvffeACAoaAPz5hX8HFoTFh7B77+vIyxsY6Yq+8xfFznUxsP8MPEXZs35kfff78+du4kMHvS5Q+t/FG16GJOb9JzzlTJUCGEEHpNS2vzZVSlDC4ZKGVowVMrQgvNPSxkaVK6n3T6nS9xil/Xk+ZohKKVMBBz7PKRQKBQOwNVf9NmLmr6tUCjcCpNw2c5wnlDOWaFQuBXOG1zSFuWcFQqFW+HqURj28sinbysUCoUjMSHsXmwhhCguhFgphDghhDguhGgkhCgphPhDCHHa8n8Jy7ZCCDFFCBElhDgkhHiuIO3QvOcsnDj+Y9JYrPZRkJLm2FlpueHMDkfpaZFOsXNz+YdOsQNQpOskp9lKdmIExT8NB3uBycAGKWVXIUQhwAj8B9gipRxrmSn9GfAp0B6oalkCgF8s/+cLt+k5u6NjVigUecdRk1CEEMWAZsAsACllqpTyJtAZmGfZbB7QxfK5MzBfmtkLFBdC5Dshi9s4Z4VCoYC85dawzgNkWd61qupx4AowRwgRIYT4VQjhg3mOxyXLNnFARlYxX+CC1f4xlrJ8oV4IKhQKtyI9D+Nz1nmAssEAPAd8IKUMFUJMxjyEYb2/FEJo8tiues4KhcKtcGBWuhggRkoZavl7JWZnfTljuMLyf7xlfSxQ0Wp/P0tZvlDOWaFQuBWOcs5SyjjgghCiuqWoFXAMWAP0tZT1BVZbPq8B3rBEbTQEEqyGP/KMGtZQKBRuhYOlAT8AFlkiNc4Cb2Lu1C4XQrwF/A10t2wbAnQAooBEy7b5RjlnhULhVjgyt4aUMhLwz2ZVFnUHac4i5zDB00c+rDFj+gRiLkQScSCrQvNHH71LakpMpsyQo4k6tZeIA5vZF76JvXtCNLGRgU6nIzxsI6tXzbO9cQGYOWMiF2MOEmmlZu7Iuh9WSn/11Y5ERm4lJfkC9Z6r5TBb2Sl316pVg507VhMWuoHdf63D3/9+ZrtSpQpR0c+bCuW9sq1v25HzdJv4G91/+I2ek1cRca7gunYJickMmBFC4H+XMWBGCDrLt8lo1OPn641fBW98K3jj5Zn910zLa2WNp6cne/5ay/59f3Awcisjv/q3pvbatnmBo0d2cuLYLoYPc7w4sy3S87C4Mo/cOc9fsIKOgb2zlPv5lad162b8/XeMpvZbv9gN//ptaNjI8eKd1gz54G2nJB2fP385Lz2kZu4oslNKP3r0BN27v8Off+51qK3slLu//+4Lvv12Eg0C2jF69AS+++6+CsqdO2lcjk/Osb6Aqr4s/+QVln/yKl93a8aoFfbr2oWfuciXS7dnKZ+99SABVSoQ/GkPAqpUoHgxcxrPpKR0YmKTiLmYxJUrKZQpnf0PhpbXypqUlBRat+lOPf8XqeffhrZtXiCgQYEmr+WITqdjyuRv6RjYm2drt6BHjy48/XRVTWzlhLsk23/kzjknheYJ47/mP59/q6l+oLPw9S1Ph/atmD17iea2/sxGzdxRZKeUfuJEFKdOndHE1sP3hZSSIkWLAFC0WFEuXbovvZWSYiK3dMpGT4/M2apJqWkPzFydu/0gPSevotvE35i6cb/dx7j92N8E+lcDINC/Gj5Gg+U472+Tm2i4ltfqYe7eTQTAw8OAwcNDs+9Vg/p1OXPmPOfORXPv3j2WL19Np8C2mtjKif8JDUEhRABwXEp5SwjhjTnG7znMbyy/k1ImaHFQgYFtiL0Yx6HDx7WoPhMpJetDliClZObMhfw6SxvFhh8mjuKzz7+hSJHCmtT/v8LQoV8TvHYhY8eOQCd0vNCii+2drNh6+BxT1odz/U4y/9ff7DB2n4wh+uotFg3pgpTw4dyN7D97iXpP2J7Yde12EmWKGgEoXcQbvf6+w/cx6ilZwhO9XnDpclKejlMLdDodYaEbqPJkZX6ZNpew8AhN7FTwLceFmIuZf8fEXqJB/bqa2MoJV3e69mLrheBsoLbl82TMbyD/i3kwfA6QrayuZZbNuwB6fXF0eh+7D8jb24tPh39Ah5d62r1Pfmne4mUuXoyjTJlSbFi/lJMno/hzV6jtHfPASx1aEx9/lQMRh2nerJFD6/5f4913+zBs2CiCgtbz6qsdmT5tPO072H+ftHz2cVo++zj7z15i6sZ9TB/wEntPxbDnVAw9JpkFSJNS04i+mkC9J8rTe0oQqWnpJKWmkZCYQvcffgPgo5ca0Lh6xQfqfjiHzN3EdO4mJuLlpaNkiUJcist5yMUZmEwm/Ou3oVixovy2YhY1a1bn6NGTj/SYtOKf/6xtxpZz1kkpM4Rc/aWUGQNVu4QQOWausZ51U8jTL0/n6sknKlO5ckX2hZtFQv38yhO6dwPPN+nI5cu2NeTywsWL5pdCV65cY/Xq9dSvX8fhzrlxY38CO7ahfbuWeHl5UrRoEebNnULffkMcaud/gd69u/LJv0cC8Ntva5n2S/6Uo+s9UZ6Y67e5cTcZCbzVog5dGz2dZbuFQ8w98/AzF1kTfooxr73wwPpSRby5ciuRMkWNXLmVSHp61ls9OdmEh0GHTgcmF+jSJSTcYvuOv8wv7TRwzhdj46joVyHzbz/f8pnfM2fh6mPJ9mJrzPmIECIjVu+gEMIfQAhRDdAkXdqRoyfwq1iHatUbUa16I2JiLhHQsJ3DHbPR6E3hwj6Zn19s3VyTm/WLEWOp/IQ/Vao1pFfvQWzb9pdyzPnk0qXLNGvWEIAWLZ7Pk3J09NWEzHHW4zFXSU1Lp7jRk0bV/AgKP0liivl2vpxwl+t37BuGaF6jEsH7TgEQvO8UdxPN/RiD4b53KFRIhxCP1jGXLl2SYsWKAuDl5UXrVs04edLx7wkAwvdFUqXK41SuXBEPDw+6d+9M8FrHKL/bi7tEa9jqOb8NTBZCjACuAnuEEBcwJ/d42xEHsGD+TzSzqG+fPRPO6DETmTt3qSOqzpXHHivDyhWzADAY9CxdGsTGTds1t6s1C63UzM+f3ceo0ROY46DzmZ1S+vUbN/lx0jeUKVOS1avnc/DgUYdEIGSn3D1w0KdMnPA1BoOB5OQUBg2+n+agdOlCeHnq0evBz9eLmwn3EAhW7DlGt0Y12HL4HMH7T2PQ6fDyMDCudyuEEDSu7se5+Ju88ZN5kpexkAffvt6CkoW9bR5j/xa1Gb5wC6vCT1KheGFuJpjTeBb2MVCksAEpzS8Hc4oi0fJaWVO+/GPMnvUjer0OnU7HypXBrAvJGrrqCNLT0/nwoxGErFuMXqdj7rxlHDt2ShNbOWFyk4ENu9S3hRBFMWdoMmCea37Zxi6Z5HVYI7+olKEFx5lPgzqdcwKF3DWfs7uS5gD17TGVetntDL78e5HLDoLYNUNQSnkLcJ7GvEKhUOQTd+mmqenbCoXCrXCB964OQTlnhULhVqRpk17Z6SjnrFAo3Ar3cM3KOSsUCjdDDWvYiTtGUeiUoniBSXdS4K8zIyju7P3FabYKNxzoNFtehkJOs+UI3CWUTvWcFQqFW+Eerlk5Z4VC4WaoYQ2FQqFwQdLdpO+snLNCoXArVM9ZoVAoXBDpJj3nR66EolAoFI7E0UooQgi9ECJCCLHW8vfjQohQIUSUEGKZRZkbIYSn5e8oy/rKBWmHSzlnP78KbN60gkMHt3EwcisfvP/WP9ZWdsK1ixZOJTxsI+FhGzl1cg/hYRsdahO0F/PMTuS1RInirA9ZwrGju1gfsoTixYs51KYzBUrtEV0tU9qTyv8yUtE398x1R85c4Llen/JH6KECH1fCnUQGfDuDwI//y4BvZ+RJTNZZ50+n0/HXnrWs+O3XB8rHTxhJXPwRTWxmhwlp92InHwLWskz/BSZJKasAN4AM5/EWcMNSPsmyXb5xKeeclpbGsOGjqFW7Bc83CWTgwH6aiUNqbSs74dpevQdRv0Fb6jdoy6qgEIKC1jvMXgZai3lmJ/I6fPhgtm7bRY2aTdi6bRfDhztWcdmZAqX2iK7evnOPizaUTdJNJn5cvI5GtarlyX74sTN8+UvWtKGzV2+lwTNVCJ70KQ2eqZInMVlnnb9Bg9/k5ImoB8rqPvesw3+sbSHzsNhCCOEHvAT8avlbAC2BlZZN5gEZemmdLX9jWd9KPCyRkwdcyjnHxcUTEWn+hb1z5y4nTpzGt0K5f6StnIRrM+j6aiDLlq92mD1rtBTzzE7kNTCwLQsWrADMqtmdOrVzmL0MnCVQao/oanKyCZMpd/tLNvxF64BnKVn0QYm2ucHb6fnFZLoOn8jUFfY/OW3bf4xOzfwB6NTMP89islqfvwq+5WjXrgXz5i7LLNPpdHz77eeMGPG9Q23ZIg1p9yKEeFcIsc9qefeh6n4EhnN/FKQUcNNKISoG8LV89sWc6x7L+gTL9vki9nbzdgAAHKRJREFUV+cshBgihKiY2zZaUamSH3VqP0NomDZClI/KFkCTJgHEx1/Jk5JHXtDpdOwL38Sl2ENs2bJTMzHPDB4rW5q4uHjA/KP3WNnSDrfh7DYVhMvXE9gafoTurR/UjNx96CTRcVdZ9M0Qlo/9mGPnYtl//KxddV5PuE2ZEmY1k9LFi2QRk63oa6T8Y97EX82+R6/1+Rs37itGjBiLyWrm53vvvcG6dZu5HOdYFSNbyLz8k3KGlNLfapmRUY8QoiMQL6W0X5LdgdiK1hgDfCaEOAMsAVZIKW2eaWuBV6Evhk5nv8ArgI+PkeXLZvLJ0JHcvn0nT/vmFWfayqBHj86a9Zrh0Yt5atGrfdRtygvj56/ho54dsggK7Dl0ij2HTtHjc/OU8sTkVP6Ou0q9p5+g14gp3EtLIzE5lYQ7iXT/7AcAPnz9JZ6vXf2BevIjJqvl+WvXviVXrlwlMuIITZsGAFCufFm6vNKB9m1fd4iNvODAULrngU5CiA6AF1AUs9B1cSGEwdI79gNiLdvHAhWBGCGEASgGXMuvcVvO+SxQD2gN9ABGCSH2Y3bUv0spb2e3k7XAq6GQb56+qQaDgRXLZrJkySpNxmQfla0M9Ho9XTq3p2GjDprb0lrMM4PL8VcpV64scXHxlCtXlvgr+b4fbeKsNhWEo2cv8OmURQDcuH2XPyNPoNfpkBL6d25Bt9ZZVdgXfWPWlQw/doY1O8IZM/C1B9aXLFaEKzduUaZEUa7cuJVvMVktzl/DhvXo8FJr2rRtgZeXJ0WKFCZ83yZSU1M5dGQ7YNbpPHh4G7WfbeEQm7nhqFA6KeXnwOcAQogXgKFSyl5CiBVAV2Ap0BfI6Gmtsfy9x7J+qyxAT8XWmLOUUpqklJuklG8BFYCpQDvMjtvhzJwxkeMnovhx8gzbG/+DbGXQqlVTTp48Q2zsJU3qd6aYZwZrgzfRp083APr06UZwsGOjUB5FmwrC+in/Yf3/mZcXA57li/6v0LL+MzSuXY2g7eEkJqcA5uGPawn2Pa29UK8Ga3buA2DNzn15EpPV+vx9PXI81as2pubTTen3xgfs2LGbir51ePLxBtR8uik1n25KYmKSUxwzOD6ULhs+BT4RQkRhHlOeZSmfBZSylH8CfJbD/nZhq+f8wPOTlPIe5l+HNUIIY0EMZ8fzjevTp3dXDh0+xr5ws2Lvl1+OZf2GrY42pbmtnIRru3frxLLlQQ6xkR1ai3lmJ/I6bvzPLFk8jTf7vU50dAyv93zPYfbAuQKl9oiuli3jibeXHr1eUKmikes3UhEClv+xh+4vZu0VZ9C4VnXOxcbT56ufADB6FeK7wa9Tqlhhm8fVv1MLhk1eSND2cMqXLp4nMVlnnj9XIF2DYTUp5XZgu+XzWaBBNtskA90cZTNXgVchRDUpZYGkc/M6rPFPwF1ThjpT6dLtbgpUylBHcCfxXIFvw56VXrb79lr896p/psBrQR2zQqFQOBt3mb6tcmsoFAq3QiU+UigUChdEKaEoFAqFC6KGNRQKhcIF0SJa41GgnLNCoXAr1LCGnTgrTsWgd97vjEk675WDpxPblZJ2z2m2nBWelZKW6hQ74NzwtltTujrNVomPfneaLUegXggqFAqFC6LGnBUKhcIFUcMaCoVC4YJolevb2SjnrFAo3Ip01XNWKBQK10MNaygUCoUL4i7DGo9cQ9CZas6enp78+edqQkPXs3//H4wY8TEAv/wyjtDQ9YSFbWDx4l/w8Sl4NtTp0ydwITqCA/vvp2asVasGO3esJix0A7v/Woe/f50C2/H09GTHziD27l1P+L5NfGFpE8DIr4cSeXAr+w9sZuDAfgW2lR06nY7wsI2sXjXP9sb5rN9a0fnnX8ayZ28Ie0PXs3DRVIdcq4f54P23iIjYQmTkVoZ88LbD67cmt/NnS+U75PhFui/YRbf5u+i7dC8nr9wq8PGkppn4dF0knWbvpM+SPVxMMGsPFiqko0J5r8zF6K3P3MfPrzwbNy4jMmILEQc28/7g/oD5exyybhFHj+wkZN0ipwm9aqC+/Uh45M7ZmWrOKSkptGv3OgEB7QkIaE+bNs1p0KAuw4ePJiCgPQ0atOPChYsMHNi3wLYWLFhBYKc+D5R9/90XfPvtJBoEtGP06Al8991/CmwnJSWFDu170rBhexo17MCLLzanfv269OnTDT/f8tSt04p6z7Vm5crgAtvKjv9v78zDoyjSP/55c5CDcMkhpyAERpH1AJQI4QwgIAFcEVyILl6goODuAroe67K4P1zxwptDQIRwSwiIyi2CQBJIFEIOAmLIAeHQRI4ASer3R0/iBAKZJN2TONbneeZJp2emvl1dM+9Uv11V3/HPPE5i4kFLyoYrHZ2fn/wqdwcNIKhTf44eTWfMkw+bqnfLLTYefWwEnTvfS4cOfRgwoDetWrUwVcORa52/0ly+G9fyY84DnVj+cDBPdGrFqxvjndbNyD7H48t3X7E/Ij6NGj7eRD7ajZHtWzBju7Ew5aVLBWRk5pKRmcvxrFzq1v1tnHpeXj7PPTeV2+8IoWu3wTz55F+56abWTJo4ls1bdnBLu25s3rKDSRPHOn18FaEsHoJVmUoPzq52cy7mQuxluBA7egf6+vqYcllUkvu2UooaNWsAULNWTTIzj1dYB4rXydvbC4Xi8SdGMm3au0V1OWGBdVSTJo0Y0D+EuXMXm142lOzo7NhWfn6+pl/C3nRTa6KjYjl/Ppf8/Hy2fbuLIUP6m6pRSGnnrzSX79sb16GmrzcAtzaqzfFffwvkXyRkEBa+k+ELd/Dqxv3kl+IWXsjWQ8cJbdsYgN6trycq1fjcFHP5vmw982PHsogr5mSfQpMmDQkN7cvChSsAWLhwBYMG3ePUMVSUfKWcflRlSnPfriYiD4tIb/v/I0TkfREZJyLeVh2UlW7OHh4e7Nq1jtTUvWze/C3R0XEAzJw5nSNHYrDZAvnww/mm6TkyceK/mTbtRVJSdvPatJd4+eXXTCnXw8ODnbvWceSnPWzetJ2Y6DhuvLE59w8dyLfbI1kVMd+S3t9bb07h+X++Wsxx2UxKcnQG+Gjm6xz+MZo2bVrx8UfmplPi4xPpEtyJ666rg5+fL/379aJZ08amahRi5vmL2J9GlxvrA3D41BnWJ2Uyb3gnloZ1wUOEdYkZTpWTdeYCDWsYaRQvDw8CfLwo9Kl1TG2cOlXyzMvmzZty2+23EBUVS4PLvscNLHBlL4k/SlpjHnAvMEFEPsOwYNkN3AnMudqbRGS0iMSISExBwdkKH6SZvaOCggKCggYQGBhEx46307ZtGwDGjJlEy5Z3kZiYwtChoabpOTJ69ENMmjSFwMBOTJo8hZkfTzel3IKCAu4OGkCb1nfToeNttG3bBh+falzIvUDX4EHMm7eYjz5+3RStQu4d0JusrJPsjd1narmFODo6X85TYyYT2KoTSUkp3D90oKm6iYkpvDH9A75cF84Xaxfx/ffx5Oeb/+Nj5vmLPnqKiPg0JgQbn+Woo6c4kJVD2GKj5xx19BTp9tzx3yP3MnzhDp6O2MOB4zkMX7iD4Qt3sDo+rVSdixeN1EZmZi61anldsTRD9er+LFk8k4kT/12ik72rbtT9UYLzn5RSw4H7gL7AUKXUZ8AjwB1Xe5NSapZSqqNSqqOHR/UyH1ShmzNgmZtzdnYO33zzHX379ijaV1BQwPLlkZZdxoaFDS1y+V65cq0pNwQdyc7OYdu2nfTp05309GOsXv0VAJGrv6Zdu5tM1ercuSOhA/uSkryLRQs/pGfPLnw6/13Tyi90dI5P+Jb5C96je/fOzPnk7aLnCwoKWLF8LYOHmJfyKmTe/CV0CupPr5D7+fmXbA4eNN/L2Kzzl3ziV/6zYT9vD2pPbT8jD6wUhLZtzNKwLiwN60LEqG48eXdrAN4a1J6lYV14f0gH2l5fs+g1g29pCkCDAB+O/XoegLyCAs5cyLvCMPZSnqJAgXe138KHl5cXS5fMYsmSiKLPXdZl32MrUmsloZRy+nEtRKSZiGwRkQMiEi8iE+z7rxORDSJy0P63jn2/iMi7IpIiIj+ISPuK1KO04OwhItWAGoA/UHi71QewLK1hlZtzcRdiH0JCupKcfIiWLZsXvWbgwD4kJ1vj7JyZeZxu3YIA6NmzCykpP1a4zMvr1KtXMEnJh1i7Zj3duxtmo127Bpmi5ciLL71Gi5YdCWwTxMiwsWzZsoO/jhpvWvklOTo//tjfirXVgHt7k5xkfuCsX78uAM2aNWbIkP4sXrLKdA0zzl9mznkmrollar9baV7nt07QXTfUZePB45w+Z7h8Z+deJCPnvFNldm/ZgDUHjBTIxoPHubOZcS4cXb49PQVvLyEv77eoPXPmdBITDzLj3dlF+9au3UBYmLFAU1jYUNasWV+m+pUXE3vOecA/lFJtgSBgnIi0xXDV3qSUag1s4jeX7f5Aa/tjNFAhU8nSxjl/AiQCnsCLwHIROWw/0CXXeqOzuNLNuWHDBsye/VaRC/HKlWv58svNbNq0gho1AhAR9u1LYPz4FyustWDB+3TrGkS9etdxKCWKqa++yVNjn+PNN/6Nl5cXubkXGDuuQs7pRXWaNftNPD3sdfr8C776cjM7v4th7rx3ePrpxzhz9hzjxlZcq7IREWbOfoOaDm317ISXTddZtnQ219WtQ96lPMaPf5Hs7IoPUSsPV3P5LmTW7kP8knuRaZsPAOApQvjIzrSqG8C4zq156vMYlFJ4eXjwfK+2NK5Z8pA8R4a0a8pLX/3AoLnbqOnrzWsDbmP2xsP4+HjQoL7RH1MKTp++VNSj7tz5TsJGDmXfvgSidhu95n/9639Mf+MDwhd9xCOjHiQ1NY0RI103WsOUcpTKBDLt27+KSALQBBgM9LC/7FMMV+7n7PsXKKNLvktEaotII3s5Zeaa7tsAItLYfnAZIlIb6A2kKqWinBHwdpH7trsuGerl4Vn6i0xCLxlaMVyZwXTXJUMv5B6t8CrD7RsFO90Uscd2jMHo5RYySyk16/LXiUgLYBvQDiP+1bbvF+BnpVRtEVkLvKaU2m5/bhPwnFIqpjz1KDWiKaUyHLZ/AVaUR0ij0WhcQVluPNoD8RXB2BERCQBWAs8qpXIchxIqpZSIWPK7rKdvazQat8LMURj2IcMrgUVKqcJLiOOF6QoRaQRk2fenA80c3t7Uvq9cVPokFI1GozETs2YI2lMWnwAJSqm3HJ6KBAqnEf8VWO2w/2H7qI0gILu8+WbQPWeNRuNmFJg3nroL8BCwT0Ti7PteAF4DlonIY8BPwDD7c+uAAUAKcA5jyHG50cFZo9G4FSaO1tjO1W1QQ0p4vQLMWQgIHZw1Go2bke/C0VRW4jbBOS8/z2VarhwyZdW6FSXh6eG6WxCuGuLmyrby9/ZxmVat8a4bNJWz9BmXaZmBiWmNSsVtgrNGo9GAdt/WaDSaKonuOWs0Gk0VRPecNRqNpgqSr/Ir+xBMQQdnjUbjVriLwasOzhqNxq2o6ovoO0ulT992pfu2I23atCImen3R49TJRMuclmfPepOMtO+Jc6ij2eW74hxezWX5lVcmEhO9nqjdX/HF2kU0anR9hbUccWVbAdzTtwfx+7eReGA7kyeZNqegiH0HtrEz6ku271zL1m+Nmb9T//s8MXs38N3udSxa/BG1atUwVXPC+CeIi9tMbOwmPvvsA3x8ig/7q1/Ph+Y3+NP0Kk7fW+J/4oF3Ihg2YzUj3osk9kjF/S+zz11gzJyvCZ2+gjFzvibHvv60zWYbbLPZfrDZbHE2my3GZrMFl6Vcsxbbr2xKXTK0opS2ZGhwcCfOnjnL3HkzuOMOY9LNtGkvcvr0L0yf/gGTJo2jTp1avPDC/1l2jB4eHvx0ZA9dggeSmlr6OiVlPWNdgztx5sxZ5s2bwe13XDGx6Jo4s36iWefQo5Rxzg0bNqBhwwbExe0nIKA6u3auY+gDj5OenllkSzRu7CPcfHNrnn7m2s7i5R2/bXVbeXh4kBD/Lf0G/IW0tEx27VxH2ENjSUgo3WHc2XHO+w5so3vXwZw+9XPRvl4hwXyzdSf5+flMmfocAK+8/L+rlnH+0gWntAAaN27I1i2ruPW2nuTm5hIe/jFffbmZBZ8tK3qNr68HBQXGGtJp6cUX5s9Z+gznLlzCr5oXIkJy5mkmh28l4h9/dko/+lAmkXtSmDqsa7H9b6+Lppa/D4/2uJW5W38g5/wF/jlrpdhstgDgbFJSkrLZbLcCy5KSkpy28mlUu63TzZ75y4EKL1FqFZXec3a1+3ZJ9OoVzOHDPzn1ZS8P35ZQRzNx1Tm8msuyo1+cf3V/rPy9t7qt7rrzDg4dOsKPP6Zy6dIlli1bzaBQ612jN2/aTn6+cSMrOiqWJk0amlq+l5cXfn6+eHp64u/nR0bmsWLPl+b07e/jXeS6ff5iXrFOw/xv9jHi/TU88E4EH26IdfqYth5IJbR9IACh7QPZEp8KQFJS0pmkpKTCg6lOGX9jzVr4qLIpNecsIi2BP2MshZcPJAPhSinL7CGsdN8uieHDBrN0aYSlGq7G6nPo6LIMMGXKZEaOvJ+c7F/pe8+wUt5dfqxuq8ZNGnI07Ten6rT0TO6686p2meVCKUVE5KcopZj3yWLmzytuKvTQww/w+cq1pullZBzj7bc/5vChKM6fz2Xjxm/YuHFbmcvZvP8n3v16D6fPnOe9UX0A+C45ndRTOSwaNxClYMKCjew5fIwOLUv/cTl1Jpf6Nf0BqFfDj1Nncoues9ls9wHTgAYYJtNO4y7Tt6/ZcxaR8cDHgC+G47YPRpDeJSI9rvG+Kuu+fTne3t4MHNiXFSZ+GaoiZp7DklyWX3nldQIDO7F4ySqeemqUaVqOuEtb3dN7GN26DOL++x7liTEP0bnLnUXPTZw0lry8PJYuWX2NEspG7dq1CA29h9ZtgriheXv8q/szYoRzKQlHerVrTsQ//szbD4Xw4Ya9AOw6mM7O5AyGvxvJg+9FcuRENqmnjH5b2AdrGDZjNf/5fAffJKQybMZqhs1YzXfJV171iEix3nhSUtIqeypjCDC1LMfpLjnn0nrOTwC3K6XyReQtYJ1SqoeIzMRYw7TELoWju0B5bKoK3bePHcuyzH27kH79ehIbu4+srJOWaVQGVp3DklyWHVmyZBWrIxYwdepbJby7YriirTLSj9GsaeOi/5s2aURGxrFrvKPsZGYaN9NOnjjF2sj1dOh4G9/tiGZE2P3069+L0HvDTNULCenKkSOpnDx5GoCIiC+5O6gj4eHls5/q0LIhaSt+5eezuSgFj/X8E0M7XZkSXjguFLh6zrlugC8ncs5Rv6Y/J3LOcV2A7xVlJCUlbbPZbC1tNlu9pKQkpxreXWYIOpNzLgzgPkAAgFIqld+h+3ZJDB8+xO1SGmDdOSzJZTmwVYui7dCBfUlKSjFF63Jc0VbRMXEEBt5IixbN8Pb2ZtiwwaxZa55rtL+/HwEB1Yu2e4UEk3Agmd59uvHss6MZPmw058/nllJK2Tiams5dndrj52cEv149g0lMLP0GpyOpJ3OKepoJ6Se5mFdAbX8f7m7ThIiYg5y7YPhPHs8+y+kzTjp9t72BNXuNz8qavSn0aHsDADabLdBms4l9uz1G7HG6d/FH6TnPAaJFZDfQFfgfgIjUB06bcQCudN++HH9/P3qHdGPs2OcsKb+QhQ51PHI4hin/eYN5800xLwdcdw6v5rI8atSDtGnTioKCAlJT00odqVEeXNVW+fn5THj2JdZ9EY6nhwfzP13KgQPJppXfoEE9Fi35GAAvT0+WL4tk44ZtxP2wmWo+1Vi9ZgEA0VFx/G3CS6ZoRkXH8vnnXxAV9TV5eXl8HxfP7DmLih9XfR987U7fNzTz5+efLxYbKrRp/xHW7D2El6cHvt6evD6iByJC5zZN+DHrFx7+0Eg1+ft489/h3bguoHSn70e7/4nJ4VtZFZ1M4zoBvD6iZ+FT9wMP22y2S8B5YLjDDcJScZdxzs64b98C3AzsV0olllXAVe7brsSVFXLlOJ/ShtKZiauWQnXXJUPLMpSuorhyyVC/+56v8Ee+ZvWWTjd7ztnDVXYonTPu2/FAvAuORaPRaCqMu4zW0NO3NRqNW+EuNwR1cNZoNG5FVb/R5yyVPkNQo9FozMTMGYIi0k9EkkQkRUSed8HhF6F7zhqNxq0wq+csIp7AB0AfIA1j5FqkUuqAKQKloIOzRqNxK0zMOd8FpCilDgOIyBJgMOAewfnSxfRyDVURkdH2mYaW4iodrfX70nLHOrmzliN5ZYg5IjIaGO2wa5bDMTcBjjo8lwZ0qvgROkdVzjmPLv0lvysdrfX70nLHOrmzVrlQSs1SSnV0eLj8x+RqVOXgrNFoNJVJOsZCb4U0te9zCTo4azQaTclEA61F5EYRqQY8CES6Srwq3xB01eWFKy9jtNbvR8sd6+TOWqajlMoTkaeBrwFPYK59xrRLsNymSqPRaDRlR6c1NBqNpgqig7NGo9FUQapccHbVdEkRmSsiWSKy3yoNB61mIrJFRA6ISLyITLBQy1dEokTke7vWFKu07HqeIhIrIpZ6R4nIERHZJyJxIhJjsVZtEVkhIokikiAid1ukY7PXp/CRIyLPWqT1N/vnYb+ILBaRK21HzNOaYNeJt6o+fwjK4hpg9QMj6X4IaAlUA74H2lqk1Q1oj7FOtdX1agS0t2/XwDDJtapeAgTYt72B3UCQhXX7OxAOrLX4HB4B6lndVnatT4HH7dvVgNou0PQEjgHNLSi7CfAj4Gf/fxkwyqJ6tAP2A/4YAw42AoGuaDd3e1S1nnPRdEml1EWgcLqk6SiltmGSm4sTWplKqb327V+BBIwvjBVaSil1xv6vt/1hyV1fEWmK4Yw8x4ryKwMRqYXxw/0JgFLqolLqFxdIhwCHlFI/WVS+F+AnIl4YgTOjlNeXl5uB3Uqpc0qpPOAboOxuspoqF5xLmi5pSRCrLESkBYYx7m4LNTxFJA7IAjYopazSegeYDLhidXMFrBeRPfYpt1ZxI3ACmGdP18wRkeoW6hXyILDYioKVUunAG0AqkAlkK6XMM0Yszn6gq4jUFRF/YADFJ3JonKSqBWe3RkQCgJXAs0qpHKt0lFL5SqnbMWY03SUi7czWEJGBQJZSao/ZZV+FYKVUe6A/ME5Eulmk44WR7vpIKXUHcBawdKlI+wSHQcByi8qvg3EFeiPQGKguIuZafNtRSiVgeI2uB74C4oB8K7TcnaoWnCt1uqSViIg3RmBepJQqnyd9GbFfjm8B+llQfBdgkIgcwUg/9RKRhRboAEW9P5RSWcAqjBSYFaQBaQ5XGyswgrWV9Af2KqWOW1R+b+BHpdQJpdQl4HOgs0VaKKU+UUp1UEp1A37GuMeiKSNVLThX6nRJqxARwchhJiil3rJYq76I1LZv+2GsRVtmY97SUEr9UynVVCnVAqOdNiulLOmNiUh1EalRuA30xbh8Nh2l1DHgqIjY7LtCsH6JyL9gUUrDTioQJCL+9s9iCMZ9D0sQkQb2vzdg5JvDrdJyZ6rU9G3lwumSIrIY6AHUE5E04BWl1CdWaGH0Mh8C9tlzwQAvKKXWWaDVCPjUvlC4B7BMKWXpMDcXcD2wyogreAHhSqmvLNR7Blhk7yAcBh6xSsj+Y9MHGGOVhlJqt4isAPYCeUAs1k6tXikidYFLwDgX3VB1O/T0bY1Go6mCVLW0hkaj0WjQwVmj0WiqJDo4azQaTRVEB2eNRqOpgujgrNFoNFUQHZw1Go2mCqKDs0aj0VRB/h/AMRhHl/D0tgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "# Your code goes here\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix\n",
        "print(confusion_matrix(y_test, clf_no_reg.predict(X_test)))\n",
        "sns.heatmap(confusion_matrix(y_test, clf_no_reg.predict(X_test)), annot=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "9EIz2EqTw5cf"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "n6IdWGLDynwu"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}